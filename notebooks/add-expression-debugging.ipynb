{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from planter.database.utils.duckdb_utils import (\n",
    "    extract_representative_sequences, \n",
    "    create_duckdb,\n",
    "    merge_duckdbs,\n",
    "    validate_duckdb_schema,\n",
    "    update_clusters\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sample SRR12068547\n",
      "Cleaning up any existing tables...\n",
      "Created sra_metadata table\n",
      "Created sequences table\n",
      "Created gene_protein_map table\n",
      "Created expression table\n",
      "Created annotations table\n",
      "Created go_terms table\n",
      "Created ec_numbers table\n",
      "Created clusters table\n",
      "Created cluster_members table\n",
      "Created kegg_info table\n",
      "Starting to process sample SRR12068547\n",
      "Sample paths: SamplePaths(sequences=PosixPath('/mnt/data4/recombia.planter/SRR12068547/transdecoder/SRR12068547.pep'), annotations=PosixPath('/mnt/data4/recombia.planter/SRR12068547/eggnog/SRR12068547.emapper.annotations'), expression=PosixPath('/mnt/data4/recombia.planter/SRR12068547/quants/SRR12068547.quant.json'))\n",
      "Fetching metadata for SRR12068547\n",
      "Fetching metadata for SRR12068547\n",
      "Fetching metadata for SRR12068547\n",
      "Inserting metadata for SRR12068547\n",
      "Successfully inserted metadata for SRR12068547\n",
      "Loading sequences for SRR12068547\n",
      "Loading sequences from /mnt/data4/recombia.planter/SRR12068547/transdecoder/SRR12068547.pep\n",
      "Inserted 398 sequences\n",
      "Inserted 398 new gene-protein mappings\n",
      "Loaded 398 new sequences for SRR12068547\n",
      "Loaded 398 sequences for SRR12068547\n",
      "Verified sequence loading: 398 sequences in database\n",
      "Loading annotations for SRR12068547\n",
      "Loading annotations from /mnt/data4/recombia.planter/SRR12068547/eggnog/SRR12068547.emapper.annotations\n",
      "Created kegg_info table\n",
      "Added KEGG information for SRR12068547\n",
      "Loaded 251 annotations for SRR12068547\n",
      "Loading expression data for SRR12068547\n",
      "Loading expression data from /mnt/data4/recombia.planter/SRR12068547/quants/SRR12068547.quant.json\n",
      "Verified JSON file format: 3894 records\n",
      "First entry structure: ['Name', 'Length', 'EffectiveLength', 'TPM', 'NumReads', 'sample']\n",
      "Creating gene-to-protein mapping table\n",
      "Filtering expression data to match genes in sequences\n",
      "Filtered expression data: 365 of 3894 entries match genes\n",
      "Found 398 total gene-protein mappings\n",
      "Preparing to insert expression data\n",
      "Inserting 365 new expression records\n",
      "Loaded 365 expression records for SRR12068547\n",
      "Loaded 365 expression records for SRR12068547\n",
      "Sample processing complete: SRR12068547\n",
      "Processed SRR12068547: 398 sequences, 251 annotations, 0 duplicates\n",
      "Build results:      sample_id   status  sequences_loaded  annotations_loaded  duplicates  \\\n",
      "0  SRR12068547  success               398                 251           0   \n",
      "\n",
      "  error  \n",
      "0  None  \n",
      "Database summary:    total_sequences  total_samples  representative_sequences  \\\n",
      "0              398              1                         0   \n",
      "\n",
      "   annotated_sequences  sequences_with_go  sequences_with_ec  \\\n",
      "0                  251                 28                102   \n",
      "\n",
      "   sequences_with_expression  total_clusters  avg_sequence_length  \\\n",
      "0                        398               0                136.3   \n",
      "\n",
      "   min_sequence_length  max_sequence_length  \n",
      "0                  100                  523  \n",
      "Processing sample SRR12068548\n",
      "Cleaning up any existing tables...\n",
      "Created sra_metadata table\n",
      "Created sequences table\n",
      "Created gene_protein_map table\n",
      "Created expression table\n",
      "Created annotations table\n",
      "Created go_terms table\n",
      "Created ec_numbers table\n",
      "Created clusters table\n",
      "Created cluster_members table\n",
      "Created kegg_info table\n",
      "Starting to process sample SRR12068548\n",
      "Sample paths: SamplePaths(sequences=PosixPath('/mnt/data4/recombia.planter/SRR12068548/transdecoder/SRR12068548.pep'), annotations=PosixPath('/mnt/data4/recombia.planter/SRR12068548/eggnog/SRR12068548.emapper.annotations'), expression=PosixPath('/mnt/data4/recombia.planter/SRR12068548/quants/SRR12068548.quant.json'))\n",
      "Fetching metadata for SRR12068548\n",
      "Fetching metadata for SRR12068548\n",
      "Fetching metadata for SRR12068548\n",
      "Inserting metadata for SRR12068548\n",
      "Successfully inserted metadata for SRR12068548\n",
      "Loading sequences for SRR12068548\n",
      "Loading sequences from /mnt/data4/recombia.planter/SRR12068548/transdecoder/SRR12068548.pep\n",
      "Inserted 369 sequences\n",
      "Inserted 369 new gene-protein mappings\n",
      "Loaded 369 new sequences for SRR12068548\n",
      "Loaded 369 sequences for SRR12068548\n",
      "Verified sequence loading: 369 sequences in database\n",
      "Loading annotations for SRR12068548\n",
      "Loading annotations from /mnt/data4/recombia.planter/SRR12068548/eggnog/SRR12068548.emapper.annotations\n",
      "Created kegg_info table\n",
      "Added KEGG information for SRR12068548\n",
      "Loaded 234 annotations for SRR12068548\n",
      "Loading expression data for SRR12068548\n",
      "Loading expression data from /mnt/data4/recombia.planter/SRR12068548/quants/SRR12068548.quant.json\n",
      "Verified JSON file format: 4331 records\n",
      "First entry structure: ['Name', 'Length', 'EffectiveLength', 'TPM', 'NumReads', 'sample']\n",
      "Creating gene-to-protein mapping table\n",
      "Filtering expression data to match genes in sequences\n",
      "Filtered expression data: 351 of 4331 entries match genes\n",
      "Found 369 total gene-protein mappings\n",
      "Preparing to insert expression data\n",
      "Inserting 351 new expression records\n",
      "Loaded 351 expression records for SRR12068548\n",
      "Loaded 351 expression records for SRR12068548\n",
      "Sample processing complete: SRR12068548\n",
      "Processed SRR12068548: 369 sequences, 234 annotations, 0 duplicates\n",
      "Build results:      sample_id   status  sequences_loaded  annotations_loaded  duplicates  \\\n",
      "0  SRR12068548  success               369                 234           0   \n",
      "\n",
      "  error  \n",
      "0  None  \n",
      "Database summary:    total_sequences  total_samples  representative_sequences  \\\n",
      "0              369              1                         0   \n",
      "\n",
      "   annotated_sequences  sequences_with_go  sequences_with_ec  \\\n",
      "0                  234                 22                 74   \n",
      "\n",
      "   sequences_with_expression  total_clusters  avg_sequence_length  \\\n",
      "0                        369               0               146.78   \n",
      "\n",
      "   min_sequence_length  max_sequence_length  \n",
      "0                  100                  523  \n",
      "Processing sample SRR12068549\n",
      "Cleaning up any existing tables...\n",
      "Created sra_metadata table\n",
      "Created sequences table\n",
      "Created gene_protein_map table\n",
      "Created expression table\n",
      "Created annotations table\n",
      "Created go_terms table\n",
      "Created ec_numbers table\n",
      "Created clusters table\n",
      "Created cluster_members table\n",
      "Created kegg_info table\n",
      "Starting to process sample SRR12068549\n",
      "Sample paths: SamplePaths(sequences=PosixPath('/mnt/data4/recombia.planter/SRR12068549/transdecoder/SRR12068549.pep'), annotations=PosixPath('/mnt/data4/recombia.planter/SRR12068549/eggnog/SRR12068549.emapper.annotations'), expression=PosixPath('/mnt/data4/recombia.planter/SRR12068549/quants/SRR12068549.quant.json'))\n",
      "Fetching metadata for SRR12068549\n",
      "Fetching metadata for SRR12068549\n",
      "Fetching metadata for SRR12068549\n",
      "Inserting metadata for SRR12068549\n",
      "Successfully inserted metadata for SRR12068549\n",
      "Loading sequences for SRR12068549\n",
      "Loading sequences from /mnt/data4/recombia.planter/SRR12068549/transdecoder/SRR12068549.pep\n",
      "Inserted 577 sequences\n",
      "Inserted 577 new gene-protein mappings\n",
      "Loaded 577 new sequences for SRR12068549\n",
      "Loaded 577 sequences for SRR12068549\n",
      "Verified sequence loading: 577 sequences in database\n",
      "Loading annotations for SRR12068549\n",
      "Loading annotations from /mnt/data4/recombia.planter/SRR12068549/eggnog/SRR12068549.emapper.annotations\n",
      "Created kegg_info table\n",
      "Added KEGG information for SRR12068549\n",
      "Loaded 397 annotations for SRR12068549\n",
      "Loading expression data for SRR12068549\n",
      "Loading expression data from /mnt/data4/recombia.planter/SRR12068549/quants/SRR12068549.quant.json\n",
      "Verified JSON file format: 3896 records\n",
      "First entry structure: ['Name', 'Length', 'EffectiveLength', 'TPM', 'NumReads', 'sample']\n",
      "Creating gene-to-protein mapping table\n",
      "Filtering expression data to match genes in sequences\n",
      "Filtered expression data: 479 of 3896 entries match genes\n",
      "Found 577 total gene-protein mappings\n",
      "Preparing to insert expression data\n",
      "Inserting 479 new expression records\n",
      "Loaded 479 expression records for SRR12068549\n",
      "Loaded 479 expression records for SRR12068549\n",
      "Sample processing complete: SRR12068549\n",
      "Processed SRR12068549: 577 sequences, 397 annotations, 0 duplicates\n",
      "Build results:      sample_id   status  sequences_loaded  annotations_loaded  duplicates  \\\n",
      "0  SRR12068549  success               577                 397           0   \n",
      "\n",
      "  error  \n",
      "0  None  \n",
      "Database summary:    total_sequences  total_samples  representative_sequences  \\\n",
      "0              577              1                         0   \n",
      "\n",
      "   annotated_sequences  sequences_with_go  sequences_with_ec  \\\n",
      "0                  397                 30                183   \n",
      "\n",
      "   sequences_with_expression  total_clusters  avg_sequence_length  \\\n",
      "0                        577               0               141.62   \n",
      "\n",
      "   min_sequence_length  max_sequence_length  \n",
      "0                  100                  523  \n",
      "Processing sample SRR12068550\n",
      "Cleaning up any existing tables...\n",
      "Created sra_metadata table\n",
      "Created sequences table\n",
      "Created gene_protein_map table\n",
      "Created expression table\n",
      "Created annotations table\n",
      "Created go_terms table\n",
      "Created ec_numbers table\n",
      "Created clusters table\n",
      "Created cluster_members table\n",
      "Created kegg_info table\n",
      "Starting to process sample SRR12068550\n",
      "Sample paths: SamplePaths(sequences=PosixPath('/mnt/data4/recombia.planter/SRR12068550/transdecoder/SRR12068550.pep'), annotations=PosixPath('/mnt/data4/recombia.planter/SRR12068550/eggnog/SRR12068550.emapper.annotations'), expression=PosixPath('/mnt/data4/recombia.planter/SRR12068550/quants/SRR12068550.quant.json'))\n",
      "Fetching metadata for SRR12068550\n",
      "Fetching metadata for SRR12068550\n",
      "Fetching metadata for SRR12068550\n",
      "Inserting metadata for SRR12068550\n",
      "Successfully inserted metadata for SRR12068550\n",
      "Loading sequences for SRR12068550\n",
      "Loading sequences from /mnt/data4/recombia.planter/SRR12068550/transdecoder/SRR12068550.pep\n",
      "Inserted 519 sequences\n",
      "Inserted 519 new gene-protein mappings\n",
      "Loaded 519 new sequences for SRR12068550\n",
      "Loaded 519 sequences for SRR12068550\n",
      "Verified sequence loading: 519 sequences in database\n",
      "Loading annotations for SRR12068550\n",
      "Loading annotations from /mnt/data4/recombia.planter/SRR12068550/eggnog/SRR12068550.emapper.annotations\n",
      "Created kegg_info table\n",
      "Added KEGG information for SRR12068550\n",
      "Loaded 320 annotations for SRR12068550\n",
      "Loading expression data for SRR12068550\n",
      "Loading expression data from /mnt/data4/recombia.planter/SRR12068550/quants/SRR12068550.quant.json\n",
      "Verified JSON file format: 4439 records\n",
      "First entry structure: ['Name', 'Length', 'EffectiveLength', 'TPM', 'NumReads', 'sample']\n",
      "Creating gene-to-protein mapping table\n",
      "Filtering expression data to match genes in sequences\n",
      "Filtered expression data: 472 of 4439 entries match genes\n",
      "Found 519 total gene-protein mappings\n",
      "Preparing to insert expression data\n",
      "Inserting 472 new expression records\n",
      "Loaded 472 expression records for SRR12068550\n",
      "Loaded 472 expression records for SRR12068550\n",
      "Sample processing complete: SRR12068550\n",
      "Processed SRR12068550: 519 sequences, 320 annotations, 0 duplicates\n",
      "Build results:      sample_id   status  sequences_loaded  annotations_loaded  duplicates  \\\n",
      "0  SRR12068550  success               519                 320           0   \n",
      "\n",
      "  error  \n",
      "0  None  \n",
      "Database summary:    total_sequences  total_samples  representative_sequences  \\\n",
      "0              519              1                         0   \n",
      "\n",
      "   annotated_sequences  sequences_with_go  sequences_with_ec  \\\n",
      "0                  320                 19                134   \n",
      "\n",
      "   sequences_with_expression  total_clusters  avg_sequence_length  \\\n",
      "0                        519               0               143.32   \n",
      "\n",
      "   min_sequence_length  max_sequence_length  \n",
      "0                  100                  523  \n",
      "Processing sample SRR12068551\n",
      "Cleaning up any existing tables...\n",
      "Created sra_metadata table\n",
      "Created sequences table\n",
      "Created gene_protein_map table\n",
      "Created expression table\n",
      "Created annotations table\n",
      "Created go_terms table\n",
      "Created ec_numbers table\n",
      "Created clusters table\n",
      "Created cluster_members table\n",
      "Created kegg_info table\n",
      "Starting to process sample SRR12068551\n",
      "Sample paths: SamplePaths(sequences=PosixPath('/mnt/data4/recombia.planter/SRR12068551/transdecoder/SRR12068551.pep'), annotations=PosixPath('/mnt/data4/recombia.planter/SRR12068551/eggnog/SRR12068551.emapper.annotations'), expression=PosixPath('/mnt/data4/recombia.planter/SRR12068551/quants/SRR12068551.quant.json'))\n",
      "Fetching metadata for SRR12068551\n",
      "Fetching metadata for SRR12068551\n",
      "Fetching metadata for SRR12068551\n",
      "Inserting metadata for SRR12068551\n",
      "Successfully inserted metadata for SRR12068551\n",
      "Loading sequences for SRR12068551\n",
      "Loading sequences from /mnt/data4/recombia.planter/SRR12068551/transdecoder/SRR12068551.pep\n",
      "Inserted 388 sequences\n",
      "Inserted 388 new gene-protein mappings\n",
      "Loaded 388 new sequences for SRR12068551\n",
      "Loaded 388 sequences for SRR12068551\n",
      "Verified sequence loading: 388 sequences in database\n",
      "Loading annotations for SRR12068551\n",
      "Loading annotations from /mnt/data4/recombia.planter/SRR12068551/eggnog/SRR12068551.emapper.annotations\n",
      "Created kegg_info table\n",
      "Added KEGG information for SRR12068551\n",
      "Loaded 239 annotations for SRR12068551\n",
      "Loading expression data for SRR12068551\n",
      "Loading expression data from /mnt/data4/recombia.planter/SRR12068551/quants/SRR12068551.quant.json\n",
      "Verified JSON file format: 4731 records\n",
      "First entry structure: ['Name', 'Length', 'EffectiveLength', 'TPM', 'NumReads', 'sample']\n",
      "Creating gene-to-protein mapping table\n",
      "Filtering expression data to match genes in sequences\n",
      "Filtered expression data: 374 of 4731 entries match genes\n",
      "Found 388 total gene-protein mappings\n",
      "Preparing to insert expression data\n",
      "Inserting 374 new expression records\n",
      "Loaded 374 expression records for SRR12068551\n",
      "Loaded 374 expression records for SRR12068551\n",
      "Sample processing complete: SRR12068551\n",
      "Processed SRR12068551: 388 sequences, 239 annotations, 0 duplicates\n",
      "Build results:      sample_id   status  sequences_loaded  annotations_loaded  duplicates  \\\n",
      "0  SRR12068551  success               388                 239           0   \n",
      "\n",
      "  error  \n",
      "0  None  \n",
      "Database summary:    total_sequences  total_samples  representative_sequences  \\\n",
      "0              388              1                         0   \n",
      "\n",
      "   annotated_sequences  sequences_with_go  sequences_with_ec  \\\n",
      "0                  239                 23                111   \n",
      "\n",
      "   sequences_with_expression  total_clusters  avg_sequence_length  \\\n",
      "0                        388               0               141.62   \n",
      "\n",
      "   min_sequence_length  max_sequence_length  \n",
      "0                  100                  523  \n",
      "Processing sample SRR12068552\n",
      "Cleaning up any existing tables...\n",
      "Created sra_metadata table\n",
      "Created sequences table\n",
      "Created gene_protein_map table\n",
      "Created expression table\n",
      "Created annotations table\n",
      "Created go_terms table\n",
      "Created ec_numbers table\n",
      "Created clusters table\n",
      "Created cluster_members table\n",
      "Created kegg_info table\n",
      "Starting to process sample SRR12068552\n",
      "Sample paths: SamplePaths(sequences=PosixPath('/mnt/data4/recombia.planter/SRR12068552/transdecoder/SRR12068552.pep'), annotations=PosixPath('/mnt/data4/recombia.planter/SRR12068552/eggnog/SRR12068552.emapper.annotations'), expression=PosixPath('/mnt/data4/recombia.planter/SRR12068552/quants/SRR12068552.quant.json'))\n",
      "Fetching metadata for SRR12068552\n",
      "Fetching metadata for SRR12068552\n",
      "Fetching metadata for SRR12068552\n",
      "Inserting metadata for SRR12068552\n",
      "Successfully inserted metadata for SRR12068552\n",
      "Loading sequences for SRR12068552\n",
      "Loading sequences from /mnt/data4/recombia.planter/SRR12068552/transdecoder/SRR12068552.pep\n",
      "Inserted 422 sequences\n",
      "Inserted 422 new gene-protein mappings\n",
      "Loaded 422 new sequences for SRR12068552\n",
      "Loaded 422 sequences for SRR12068552\n",
      "Verified sequence loading: 422 sequences in database\n",
      "Loading annotations for SRR12068552\n",
      "Loading annotations from /mnt/data4/recombia.planter/SRR12068552/eggnog/SRR12068552.emapper.annotations\n",
      "Created kegg_info table\n",
      "Added KEGG information for SRR12068552\n",
      "Loaded 259 annotations for SRR12068552\n",
      "Loading expression data for SRR12068552\n",
      "Loading expression data from /mnt/data4/recombia.planter/SRR12068552/quants/SRR12068552.quant.json\n",
      "Verified JSON file format: 4029 records\n",
      "First entry structure: ['Name', 'Length', 'EffectiveLength', 'TPM', 'NumReads', 'sample']\n",
      "Creating gene-to-protein mapping table\n",
      "Filtering expression data to match genes in sequences\n",
      "Filtered expression data: 391 of 4029 entries match genes\n",
      "Found 422 total gene-protein mappings\n",
      "Preparing to insert expression data\n",
      "Inserting 391 new expression records\n",
      "Loaded 391 expression records for SRR12068552\n",
      "Loaded 391 expression records for SRR12068552\n",
      "Sample processing complete: SRR12068552\n",
      "Processed SRR12068552: 422 sequences, 259 annotations, 0 duplicates\n",
      "Build results:      sample_id   status  sequences_loaded  annotations_loaded  duplicates  \\\n",
      "0  SRR12068552  success               422                 259           0   \n",
      "\n",
      "  error  \n",
      "0  None  \n",
      "Database summary:    total_sequences  total_samples  representative_sequences  \\\n",
      "0              422              1                         0   \n",
      "\n",
      "   annotated_sequences  sequences_with_go  sequences_with_ec  \\\n",
      "0                  259                 22                119   \n",
      "\n",
      "   sequences_with_expression  total_clusters  avg_sequence_length  \\\n",
      "0                        422               0                143.9   \n",
      "\n",
      "   min_sequence_length  max_sequence_length  \n",
      "0                  100                  428  \n",
      "Using existing master database at /mnt/data4/recombia.planter/master.duckdb\n",
      "Merging databases using schema version 2\n",
      "Existing tables in master database: gene_protein_map, go_terms, kegg_info, ec_numbers, cluster_members, clusters, schema_version, sra_metadata, expression, sequences, annotations\n",
      "Attaching /mnt/data4/recombia.planter/SRR12068547/SRR12068547.duckdb as db0...\n",
      "Source database schema version: 2\n",
      "Tables in source database: gene_protein_map, go_terms, kegg_info, ec_numbers, cluster_members, clusters, schema_version, sra_metadata, expression, sequences, annotations\n",
      "  - Inserted rows in sra_metadata: 100\n",
      "  - Inserted rows in sequences: 2489980\n",
      "  - Inserted rows in annotations: 2049722\n",
      "  - Inserted rows in go_terms: 74845016\n",
      "  - Inserted rows in ec_numbers: 571387\n",
      "  - Inserted rows in clusters: 428254\n",
      "  - Inserted rows in cluster_members: 433839\n",
      "Processed 398 rows for gene_protein_map individually\n",
      "  - Inserted rows in gene_protein_map: 744572\n",
      "  - Inserted rows in expression: 3091553\n",
      "Adapting kegg_info schema: matching 6 columns\n",
      "Target columns: ['seqhash_id', 'kegg_ko', 'kegg_pathway', 'kegg_module', 'kegg_reaction', 'kegg_rclass']\n",
      "Source columns: ['seqhash_id', 'kegg_ko', 'kegg_pathway', 'kegg_module', 'kegg_reaction', 'kegg_rclass', 'brite', 'kegg_tc', 'cazy', 'bigg_reaction', 'pfams', 'sample_id']\n",
      "  - Inserted rows in kegg_info: 236\n",
      "Finished merging /mnt/data4/recombia.planter/SRR12068547/SRR12068547.duckdb\n",
      "Attaching /mnt/data4/recombia.planter/SRR12068548/SRR12068548.duckdb as db1...\n",
      "Source database schema version: 2\n",
      "Tables in source database: gene_protein_map, go_terms, kegg_info, ec_numbers, cluster_members, clusters, schema_version, sra_metadata, expression, sequences, annotations\n",
      "  - Inserted rows in sra_metadata: 100\n",
      "  - Inserted rows in sequences: 2489980\n",
      "  - Inserted rows in annotations: 2049722\n",
      "  - Inserted rows in go_terms: 74845016\n",
      "  - Inserted rows in ec_numbers: 571387\n",
      "  - Inserted rows in clusters: 428254\n",
      "  - Inserted rows in cluster_members: 433839\n",
      "Processed 369 rows for gene_protein_map individually\n",
      "  - Inserted rows in gene_protein_map: 744572\n",
      "  - Inserted rows in expression: 3091553\n",
      "Adapting kegg_info schema: matching 6 columns\n",
      "Target columns: ['seqhash_id', 'kegg_ko', 'kegg_pathway', 'kegg_module', 'kegg_reaction', 'kegg_rclass']\n",
      "Source columns: ['seqhash_id', 'kegg_ko', 'kegg_pathway', 'kegg_module', 'kegg_reaction', 'kegg_rclass', 'brite', 'kegg_tc', 'cazy', 'bigg_reaction', 'pfams', 'sample_id']\n",
      "  - Inserted rows in kegg_info: 453\n",
      "Finished merging /mnt/data4/recombia.planter/SRR12068548/SRR12068548.duckdb\n",
      "Attaching /mnt/data4/recombia.planter/SRR12068549/SRR12068549.duckdb as db2...\n",
      "Source database schema version: 2\n",
      "Tables in source database: gene_protein_map, go_terms, kegg_info, ec_numbers, cluster_members, clusters, schema_version, sra_metadata, expression, sequences, annotations\n",
      "  - Inserted rows in sra_metadata: 100\n",
      "  - Inserted rows in sequences: 2489980\n",
      "  - Inserted rows in annotations: 2049722\n",
      "  - Inserted rows in go_terms: 74845016\n",
      "  - Inserted rows in ec_numbers: 571387\n",
      "  - Inserted rows in clusters: 428254\n",
      "  - Inserted rows in cluster_members: 433839\n",
      "Processed 577 rows for gene_protein_map individually\n",
      "  - Inserted rows in gene_protein_map: 744572\n",
      "  - Inserted rows in expression: 3091553\n",
      "Adapting kegg_info schema: matching 6 columns\n",
      "Target columns: ['seqhash_id', 'kegg_ko', 'kegg_pathway', 'kegg_module', 'kegg_reaction', 'kegg_rclass']\n",
      "Source columns: ['seqhash_id', 'kegg_ko', 'kegg_pathway', 'kegg_module', 'kegg_reaction', 'kegg_rclass', 'brite', 'kegg_tc', 'cazy', 'bigg_reaction', 'pfams', 'sample_id']\n",
      "  - Inserted rows in kegg_info: 842\n",
      "Finished merging /mnt/data4/recombia.planter/SRR12068549/SRR12068549.duckdb\n",
      "Attaching /mnt/data4/recombia.planter/SRR12068550/SRR12068550.duckdb as db3...\n",
      "Source database schema version: 2\n",
      "Tables in source database: gene_protein_map, go_terms, kegg_info, ec_numbers, cluster_members, clusters, schema_version, sra_metadata, expression, sequences, annotations\n",
      "  - Inserted rows in sra_metadata: 100\n",
      "  - Inserted rows in sequences: 2489980\n",
      "  - Inserted rows in annotations: 2049722\n",
      "  - Inserted rows in go_terms: 74845016\n",
      "  - Inserted rows in ec_numbers: 571387\n",
      "  - Inserted rows in clusters: 428254\n",
      "  - Inserted rows in cluster_members: 433839\n",
      "Processed 519 rows for gene_protein_map individually\n",
      "  - Inserted rows in gene_protein_map: 745043\n",
      "  - Inserted rows in expression: 3091553\n",
      "Adapting kegg_info schema: matching 6 columns\n",
      "Target columns: ['seqhash_id', 'kegg_ko', 'kegg_pathway', 'kegg_module', 'kegg_reaction', 'kegg_rclass']\n",
      "Source columns: ['seqhash_id', 'kegg_ko', 'kegg_pathway', 'kegg_module', 'kegg_reaction', 'kegg_rclass', 'brite', 'kegg_tc', 'cazy', 'bigg_reaction', 'pfams', 'sample_id']\n",
      "  - Inserted rows in kegg_info: 1149\n",
      "Finished merging /mnt/data4/recombia.planter/SRR12068550/SRR12068550.duckdb\n",
      "Attaching /mnt/data4/recombia.planter/SRR12068551/SRR12068551.duckdb as db4...\n",
      "Source database schema version: 2\n",
      "Tables in source database: gene_protein_map, go_terms, kegg_info, ec_numbers, cluster_members, clusters, schema_version, sra_metadata, expression, sequences, annotations\n",
      "  - Inserted rows in sra_metadata: 100\n",
      "  - Inserted rows in sequences: 2489980\n",
      "  - Inserted rows in annotations: 2049722\n",
      "  - Inserted rows in go_terms: 74845016\n",
      "  - Inserted rows in ec_numbers: 571387\n",
      "  - Inserted rows in clusters: 428254\n",
      "  - Inserted rows in cluster_members: 433839\n",
      "Processed 388 rows for gene_protein_map individually\n",
      "  - Inserted rows in gene_protein_map: 745417\n",
      "  - Inserted rows in expression: 3091553\n",
      "Adapting kegg_info schema: matching 6 columns\n",
      "Target columns: ['seqhash_id', 'kegg_ko', 'kegg_pathway', 'kegg_module', 'kegg_reaction', 'kegg_rclass']\n",
      "Source columns: ['seqhash_id', 'kegg_ko', 'kegg_pathway', 'kegg_module', 'kegg_reaction', 'kegg_rclass', 'brite', 'kegg_tc', 'cazy', 'bigg_reaction', 'pfams', 'sample_id']\n",
      "  - Inserted rows in kegg_info: 1382\n",
      "Finished merging /mnt/data4/recombia.planter/SRR12068551/SRR12068551.duckdb\n",
      "Attaching /mnt/data4/recombia.planter/SRR12068552/SRR12068552.duckdb as db5...\n",
      "Source database schema version: 2\n",
      "Tables in source database: gene_protein_map, go_terms, kegg_info, ec_numbers, cluster_members, clusters, schema_version, sra_metadata, expression, sequences, annotations\n",
      "  - Inserted rows in sra_metadata: 100\n",
      "  - Inserted rows in sequences: 2489980\n",
      "  - Inserted rows in annotations: 2049722\n",
      "  - Inserted rows in go_terms: 74845016\n",
      "  - Inserted rows in ec_numbers: 571387\n",
      "  - Inserted rows in clusters: 428254\n",
      "  - Inserted rows in cluster_members: 433839\n",
      "Processed 422 rows for gene_protein_map individually\n",
      "  - Inserted rows in gene_protein_map: 745417\n",
      "  - Inserted rows in expression: 3091553\n",
      "Adapting kegg_info schema: matching 6 columns\n",
      "Target columns: ['seqhash_id', 'kegg_ko', 'kegg_pathway', 'kegg_module', 'kegg_reaction', 'kegg_rclass']\n",
      "Source columns: ['seqhash_id', 'kegg_ko', 'kegg_pathway', 'kegg_module', 'kegg_reaction', 'kegg_rclass', 'brite', 'kegg_tc', 'cazy', 'bigg_reaction', 'pfams', 'sample_id']\n",
      "  - Inserted rows in kegg_info: 1626\n",
      "Finished merging /mnt/data4/recombia.planter/SRR12068552/SRR12068552.duckdb\n",
      "All databases have been merged into: /mnt/data4/recombia.planter/master.duckdb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating database: /mnt/data4/recombia.planter/master.duckdb\n",
      "\n",
      "=== Tables in database ===\n",
      "Table: annotations - 2049722 rows\n",
      "Table: clusters - 428254 rows\n",
      "Table: cluster_members - 433839 rows\n",
      "Table: ec_numbers - 571387 rows\n",
      "Table: expression - 3091553 rows\n",
      "Table: gene_protein_map - 745417 rows\n",
      "Table: go_terms - 74845016 rows\n",
      "Table: kegg_info - 1626 rows\n",
      "Table: schema_version - 0 rows\n",
      "Table: sequences - 2489980 rows\n",
      "Table: sra_metadata - 100 rows\n",
      "\n",
      "=== Schema for each table ===\n",
      "\n",
      "Schema for annotations:\n",
      "  seqhash_id (VARCHAR) PRIMARY KEY\n",
      "  seed_ortholog (VARCHAR)\n",
      "  evalue (DOUBLE)\n",
      "  score (DOUBLE)\n",
      "  eggnog_ogs (VARCHAR)\n",
      "  max_annot_lvl (VARCHAR)\n",
      "  cog_category (VARCHAR)\n",
      "  description (VARCHAR)\n",
      "  preferred_name (VARCHAR)\n",
      "  sample_id (VARCHAR)\n",
      "\n",
      "Schema for clusters:\n",
      "  cluster_id (VARCHAR) PRIMARY KEY\n",
      "  representative_seqhash_id (VARCHAR)\n",
      "  size (INTEGER)\n",
      "\n",
      "Schema for cluster_members:\n",
      "  seqhash_id (VARCHAR) PRIMARY KEY\n",
      "  cluster_id (VARCHAR)\n",
      "\n",
      "Schema for ec_numbers:\n",
      "  seqhash_id (VARCHAR) PRIMARY KEY\n",
      "  ec_number (VARCHAR) PRIMARY KEY\n",
      "\n",
      "Schema for expression:\n",
      "  gene_seqhash_id (VARCHAR) PRIMARY KEY\n",
      "  sample_id (VARCHAR) PRIMARY KEY\n",
      "  tpm (DOUBLE)\n",
      "  num_reads (DOUBLE)\n",
      "  effective_length (DOUBLE)\n",
      "\n",
      "Schema for gene_protein_map:\n",
      "  gene_seqhash_id (VARCHAR) PRIMARY KEY\n",
      "  protein_seqhash_id (VARCHAR)\n",
      "\n",
      "Schema for go_terms:\n",
      "  seqhash_id (VARCHAR) PRIMARY KEY\n",
      "  go_term (VARCHAR) PRIMARY KEY\n",
      "\n",
      "Schema for kegg_info:\n",
      "  seqhash_id (VARCHAR) PRIMARY KEY\n",
      "  kegg_ko (VARCHAR)\n",
      "  kegg_pathway (VARCHAR)\n",
      "  kegg_module (VARCHAR)\n",
      "  kegg_reaction (VARCHAR)\n",
      "  kegg_rclass (VARCHAR)\n",
      "\n",
      "Schema for schema_version:\n",
      "  version (INTEGER) PRIMARY KEY\n",
      "  migration_name (VARCHAR)\n",
      "  applied_at (TIMESTAMP)\n",
      "\n",
      "Schema for sequences:\n",
      "  seqhash_id (VARCHAR) PRIMARY KEY\n",
      "  sequence (VARCHAR)\n",
      "  sample_id (VARCHAR)\n",
      "  assembly_date (TIMESTAMP)\n",
      "  is_representative (BOOLEAN)\n",
      "  repseq_id (VARCHAR)\n",
      "  length (INTEGER)\n",
      "\n",
      "Schema for sra_metadata:\n",
      "  sample_id (VARCHAR) PRIMARY KEY\n",
      "  organism (VARCHAR)\n",
      "  study_title (VARCHAR)\n",
      "  study_abstract (VARCHAR)\n",
      "  bioproject (VARCHAR)\n",
      "  biosample (VARCHAR)\n",
      "  library_strategy (VARCHAR)\n",
      "  library_source (VARCHAR)\n",
      "  library_selection (VARCHAR)\n",
      "  library_layout (VARCHAR)\n",
      "  instrument (VARCHAR)\n",
      "  run_spots (VARCHAR)\n",
      "  run_bases (VARCHAR)\n",
      "  run_published (VARCHAR)\n",
      "\n",
      "=== Gene-Protein Relationships ===\n",
      "Total genes: 745417\n",
      "Total proteins: 745417\n",
      "Total gene-protein relationships: 745417\n",
      "\n",
      "=== Expression Data ===\n",
      "Genes with expression data: 3089378\n",
      "Samples with expression data: 100\n",
      "Average TPM: 23.76\n",
      "Genes with both expression and protein mappings: 745415\n",
      "Proteins linked to genes with expression: 745415\n",
      "\n",
      "=== Annotation Data ===\n",
      "Total annotated sequences: 2049722\n",
      "Samples with annotations: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting cluster update for database: /mnt/data4/recombia.planter/master.duckdb\n",
      "Starting cluster update for database: /mnt/data4/recombia.planter/master.duckdb\n",
      "Using clustering data from: /mnt/data4/planter_outputs/tmp/newClusterDB.tsv\n",
      "Using clustering data from: /mnt/data4/planter_outputs/tmp/newClusterDB.tsv\n",
      "Creating backup at: /mnt/data4/recombia.planter/master.duckdb.backup\n",
      "Creating backup at: /mnt/data4/recombia.planter/master.duckdb.backup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated proteins: 622261\n",
      "Genes of annotated proteins: 622261\n",
      "Genes with both annotation and expression: 622259\n",
      "\n",
      "=== Cluster Data ===\n",
      "Total clusters: 428254\n",
      "Average cluster size: 1.01\n",
      "Largest cluster size: 11\n",
      "Unique sequences in clusters: 433839\n",
      "Total cluster membership records: 433839\n",
      "\n",
      "Top 3 largest clusters:\n",
      "  Cluster v1_DLS_b6cf04a60dfba05cfefdf7b30e5096b124df4862e8ca750b224ce458186859b2.p1: 11 members\n",
      "  Cluster v1_DLS_9840696f6ab23bf92c6f0052abb5a1155bb216e1fd9f4cf72640dc61d0d1067f.p1: 10 members\n",
      "  Cluster v1_DLS_9cc2c904a6081b260551b7098f155bbd47bed2065f5df13581bf137cec7793e6.p1: 9 members\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning database transaction\n",
      "Beginning database transaction\n",
      "Dropping existing cluster tables...\n",
      "Dropping existing cluster tables...\n",
      "Recreating cluster tables...\n",
      "Recreating cluster tables...\n",
      "Loading cluster data from TSV...\n",
      "Loading cluster data from TSV...\n",
      "Loaded 436483 entries from clustering TSV\n",
      "Loaded 436483 entries from clustering TSV\n",
      "Identifying missing sequences...\n",
      "Identifying missing sequences...\n",
      "Found 2585 unique sequences missing from database\n",
      "Found 2585 unique sequences missing from database\n",
      "Found 655 unique representatives missing from database\n",
      "Found 655 unique representatives missing from database\n",
      "Examples of missing sequences:\n",
      "Examples of missing sequences:\n",
      "  1. v1_DLS_4c4626a1897a1f168a9ee958b114630cbce70ff019fa8e3b20ebb2b8d52a54fd.p1\n",
      "  1. v1_DLS_4c4626a1897a1f168a9ee958b114630cbce70ff019fa8e3b20ebb2b8d52a54fd.p1\n",
      "  2. v1_DLS_8bb5336f84993daa8ac182f9bd7a7d39c7f4427b45f746669882383b74f52792.p1\n",
      "  2. v1_DLS_8bb5336f84993daa8ac182f9bd7a7d39c7f4427b45f746669882383b74f52792.p1\n",
      "  3. v1_DLS_971fa54672d4332990b6854bd963b30a5955f34a7969ddea65bb46fbc15b59f7.p1\n",
      "  3. v1_DLS_971fa54672d4332990b6854bd963b30a5955f34a7969ddea65bb46fbc15b59f7.p1\n",
      "  4. v1_DLS_ffddc1838d79d4e7db61ea10a6b5eabe6699f0c588ee0033c19083b741b2141b.p1\n",
      "  4. v1_DLS_ffddc1838d79d4e7db61ea10a6b5eabe6699f0c588ee0033c19083b741b2141b.p1\n",
      "  5. v1_DLS_5d13da8ffb39eba0645510f66588d2c07c50e1f376f28a83f0d134fa64750285.p1\n",
      "  5. v1_DLS_5d13da8ffb39eba0645510f66588d2c07c50e1f376f28a83f0d134fa64750285.p1\n",
      "  6. v1_DLS_cd655a7569c448f85955bebfbc2ec4de741ec62447048dc597d9e41d6d7380b1.p2\n",
      "  6. v1_DLS_cd655a7569c448f85955bebfbc2ec4de741ec62447048dc597d9e41d6d7380b1.p2\n",
      "  7. v1_DLS_cf265061ce0a933d3d2899dc3806ea5df095e55e26e9ff20db9956191379162c.p1\n",
      "  7. v1_DLS_cf265061ce0a933d3d2899dc3806ea5df095e55e26e9ff20db9956191379162c.p1\n",
      "  8. v1_DLS_df23cd4509c7cb3176712cde3055f1581a8b697c7a20983f7890d4108cc8f136.p2\n",
      "  8. v1_DLS_df23cd4509c7cb3176712cde3055f1581a8b697c7a20983f7890d4108cc8f136.p2\n",
      "  9. v1_DLS_f350ef3bb715c5f2640732d8f9598b6625f6c5f867690479eaf58f4f73b752d2.p1\n",
      "  9. v1_DLS_f350ef3bb715c5f2640732d8f9598b6625f6c5f867690479eaf58f4f73b752d2.p1\n",
      "  10. v1_DLS_bcff92d3357c234e3b16448b3c2f7c3462fe3335110ca3f1e8fb440f573d80d8.p2\n",
      "  10. v1_DLS_bcff92d3357c234e3b16448b3c2f7c3462fe3335110ca3f1e8fb440f573d80d8.p2\n",
      "Filtering to valid entries only...\n",
      "Filtering to valid entries only...\n",
      "Retained 433898/436483 entries after filtering\n",
      "Retained 433898/436483 entries after filtering\n",
      "Updating sequences with representative information...\n",
      "Updating sequences with representative information...\n",
      "Updated 2489980 sequences with representative info\n",
      "Updated 2489980 sequences with representative info\n",
      "Creating clusters...\n",
      "Creating clusters...\n",
      "Created 428254 clusters\n",
      "Created 428254 clusters\n",
      "Adding cluster memberships...\n",
      "Adding cluster memberships...\n",
      "Added 433839 cluster memberships\n",
      "Added 433839 cluster memberships\n",
      "Average cluster size: 1.01\n",
      "Average cluster size: 1.01\n",
      "Largest cluster size: 11\n",
      "Largest cluster size: 11\n",
      "Successfully updated cluster information\n",
      "Successfully updated cluster information\n",
      "Log file saved to: /mnt/data4/recombia.planter/cluster_update_20250311_184104.log\n",
      "Log file saved to: /mnt/data4/recombia.planter/cluster_update_20250311_184104.log\n"
     ]
    }
   ],
   "source": [
    "samples = ['SRR12068547', 'SRR12068548', 'SRR12068549', 'SRR12068550', 'SRR12068551', 'SRR12068552']\n",
    "outdir = Path('/mnt/data4/recombia.planter')\n",
    "cluster_path = '/mnt/data4/planter_outputs/tmp/newClusterDB.tsv'\n",
    "\n",
    "# 1. Create duckdbs for Mesoplasma samples\n",
    "for sample in samples:\n",
    "    duckdb_path = outdir / f'{sample}/{sample}.duckdb'\n",
    "    if duckdb_path.exists():\n",
    "        # remove the duckdb file\n",
    "        duckdb_path.unlink()\n",
    "    create_duckdb(\n",
    "        sample_id=sample,\n",
    "        outdir=outdir,\n",
    "        duckdb_out=outdir / f'{sample}/{sample}.duckdb'\n",
    "    )\n",
    "\n",
    "# 2. Merge all duckdbs into a master duckdb\n",
    "merge_duckdbs(\n",
    "    duckdb_paths=[outdir / f'{sample}/{sample}.duckdb' for sample in samples],\n",
    "    master_db_path=outdir / 'master.duckdb',\n",
    "    schema_sql_path=Path('../planter/database/schema/migrations/004_add_gene_protein_map.sql'),\n",
    "    upgrade_schema=True,\n",
    "    target_schema_version=None\n",
    ")\n",
    "\n",
    "# 3. Validate the master duckdb\n",
    "validate_duckdb_schema(outdir / 'master.duckdb')\n",
    "\n",
    "# 4. Add cluster info to the master duckdb\n",
    "update_clusters(\n",
    "    db_path=outdir / 'master.duckdb',\n",
    "    tsv_path=cluster_path,\n",
    "    backup_first=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating database: /mnt/data4/recombia.planter/SRR12068547/SRR12068547.duckdb\n",
      "\n",
      "=== Tables in database ===\n",
      "Table: annotations - 251 rows\n",
      "Table: clusters - 0 rows\n",
      "Table: cluster_members - 0 rows\n",
      "Table: ec_numbers - 114 rows\n",
      "Table: expression - 365 rows\n",
      "Table: gene_protein_map - 398 rows\n",
      "Table: go_terms - 267 rows\n",
      "Table: kegg_info - 236 rows\n",
      "Table: schema_version - 0 rows\n",
      "Table: sequences - 398 rows\n",
      "Table: sra_metadata - 1 rows\n",
      "\n",
      "=== Schema for each table ===\n",
      "\n",
      "Schema for annotations:\n",
      "  seqhash_id (VARCHAR) PRIMARY KEY\n",
      "  seed_ortholog (VARCHAR)\n",
      "  evalue (DOUBLE)\n",
      "  score (DOUBLE)\n",
      "  eggnog_ogs (VARCHAR)\n",
      "  max_annot_lvl (VARCHAR)\n",
      "  cog_category (VARCHAR)\n",
      "  description (VARCHAR)\n",
      "  preferred_name (VARCHAR)\n",
      "  sample_id (VARCHAR)\n",
      "\n",
      "Schema for clusters:\n",
      "  cluster_id (VARCHAR) PRIMARY KEY\n",
      "  representative_seqhash_id (VARCHAR)\n",
      "  size (INTEGER)\n",
      "\n",
      "Schema for cluster_members:\n",
      "  seqhash_id (VARCHAR) PRIMARY KEY\n",
      "  cluster_id (VARCHAR) PRIMARY KEY\n",
      "\n",
      "Schema for ec_numbers:\n",
      "  seqhash_id (VARCHAR) PRIMARY KEY\n",
      "  ec_number (VARCHAR) PRIMARY KEY\n",
      "\n",
      "Schema for expression:\n",
      "  gene_seqhash_id (VARCHAR) PRIMARY KEY\n",
      "  sample_id (VARCHAR) PRIMARY KEY\n",
      "  tpm (DOUBLE)\n",
      "  num_reads (DOUBLE)\n",
      "  effective_length (DOUBLE)\n",
      "\n",
      "Schema for gene_protein_map:\n",
      "  gene_seqhash_id (VARCHAR) PRIMARY KEY\n",
      "  protein_seqhash_id (VARCHAR) PRIMARY KEY\n",
      "\n",
      "Schema for go_terms:\n",
      "  seqhash_id (VARCHAR) PRIMARY KEY\n",
      "  go_term (VARCHAR) PRIMARY KEY\n",
      "\n",
      "Schema for kegg_info:\n",
      "  seqhash_id (VARCHAR) PRIMARY KEY\n",
      "  kegg_ko (VARCHAR)\n",
      "  kegg_pathway (VARCHAR)\n",
      "  kegg_module (VARCHAR)\n",
      "  kegg_reaction (VARCHAR)\n",
      "  kegg_rclass (VARCHAR)\n",
      "  brite (VARCHAR)\n",
      "  kegg_tc (VARCHAR)\n",
      "  cazy (VARCHAR)\n",
      "  bigg_reaction (VARCHAR)\n",
      "  pfams (VARCHAR)\n",
      "  sample_id (VARCHAR)\n",
      "\n",
      "Schema for schema_version:\n",
      "  version (INTEGER) PRIMARY KEY\n",
      "  migration_name (VARCHAR)\n",
      "  applied_at (TIMESTAMP)\n",
      "\n",
      "Schema for sequences:\n",
      "  seqhash_id (VARCHAR) PRIMARY KEY\n",
      "  sequence (VARCHAR)\n",
      "  sample_id (VARCHAR)\n",
      "  assembly_date (TIMESTAMP)\n",
      "  is_representative (BOOLEAN)\n",
      "  repseq_id (VARCHAR)\n",
      "  length (INTEGER)\n",
      "\n",
      "Schema for sra_metadata:\n",
      "  sample_id (VARCHAR) PRIMARY KEY\n",
      "  organism (VARCHAR)\n",
      "  study_title (VARCHAR)\n",
      "  study_abstract (VARCHAR)\n",
      "  bioproject (VARCHAR)\n",
      "  biosample (VARCHAR)\n",
      "  library_strategy (VARCHAR)\n",
      "  library_source (VARCHAR)\n",
      "  library_selection (VARCHAR)\n",
      "  library_layout (VARCHAR)\n",
      "  instrument (VARCHAR)\n",
      "  run_spots (INTEGER)\n",
      "  run_bases (INTEGER)\n",
      "  run_published (TIMESTAMP)\n",
      "\n",
      "=== Gene-Protein Relationships ===\n",
      "Total genes: 365\n",
      "Total proteins: 398\n",
      "Total gene-protein relationships: 398\n",
      "\n",
      "Top 5 genes with multiple proteins:\n",
      "  Gene v1_DLS_4879919a9500fb706789ca502276536ad444bd0da850c4bd6a3f7a27c209f709 has 4 proteins\n",
      "    - v1_DLS_4879919a9500fb706789ca502276536ad444bd0da850c4bd6a3f7a27c209f709.p2\n",
      "    - v1_DLS_4879919a9500fb706789ca502276536ad444bd0da850c4bd6a3f7a27c209f709.p3\n",
      "    - v1_DLS_4879919a9500fb706789ca502276536ad444bd0da850c4bd6a3f7a27c209f709.p1\n",
      "  Gene v1_DLS_1326316412ebf3de1b3287ad9d63156b914d59fac8091a0ace01b5460d43e49c has 4 proteins\n",
      "    - v1_DLS_1326316412ebf3de1b3287ad9d63156b914d59fac8091a0ace01b5460d43e49c.p2\n",
      "    - v1_DLS_1326316412ebf3de1b3287ad9d63156b914d59fac8091a0ace01b5460d43e49c.p6\n",
      "    - v1_DLS_1326316412ebf3de1b3287ad9d63156b914d59fac8091a0ace01b5460d43e49c.p3\n",
      "  Gene v1_DLS_9f167d5c7a86a0ded7a83334f059cfb43d33cb35a9310f4478a76377899610a4 has 3 proteins\n",
      "    - v1_DLS_9f167d5c7a86a0ded7a83334f059cfb43d33cb35a9310f4478a76377899610a4.p3\n",
      "    - v1_DLS_9f167d5c7a86a0ded7a83334f059cfb43d33cb35a9310f4478a76377899610a4.p2\n",
      "    - v1_DLS_9f167d5c7a86a0ded7a83334f059cfb43d33cb35a9310f4478a76377899610a4.p1\n",
      "  Gene v1_DLS_52d01839cfc860fba1017005768fa11813eb278cd5fe2751d6c9eac0fd67bbe1 has 3 proteins\n",
      "    - v1_DLS_52d01839cfc860fba1017005768fa11813eb278cd5fe2751d6c9eac0fd67bbe1.p2\n",
      "    - v1_DLS_52d01839cfc860fba1017005768fa11813eb278cd5fe2751d6c9eac0fd67bbe1.p3\n",
      "    - v1_DLS_52d01839cfc860fba1017005768fa11813eb278cd5fe2751d6c9eac0fd67bbe1.p1\n",
      "  Gene v1_DLS_a7cd3791f1a9e89eec6553492f2d4a1a07bee071fe2edf333dcffd21ac953e7c has 2 proteins\n",
      "    - v1_DLS_a7cd3791f1a9e89eec6553492f2d4a1a07bee071fe2edf333dcffd21ac953e7c.p1\n",
      "    - v1_DLS_a7cd3791f1a9e89eec6553492f2d4a1a07bee071fe2edf333dcffd21ac953e7c.p2\n",
      "\n",
      "=== Expression Data ===\n",
      "Genes with expression data: 365\n",
      "Samples with expression data: 1\n",
      "Average TPM: 124.44\n",
      "Genes with both expression and protein mappings: 365\n",
      "Proteins linked to genes with expression: 398\n",
      "\n",
      "=== Annotation Data ===\n",
      "Total annotated sequences: 251\n",
      "Samples with annotations: 1\n",
      "Annotated proteins: 251\n",
      "Genes of annotated proteins: 224\n",
      "Genes with both annotation and expression: 224\n",
      "\n",
      "=== Cluster Data ===\n",
      "Total clusters: 0\n",
      "Error checking cluster data: unsupported format string passed to NoneType.__format__\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def validate_duckdb_schema(db_path):\n",
    "    \"\"\"Validate schema and relationships in the database.\"\"\"\n",
    "    print(f\"Validating database: {db_path}\")\n",
    "    \n",
    "    with duckdb.connect(db_path) as con:\n",
    "        # 1. Get list of all tables\n",
    "        print(\"\\n=== Tables in database ===\")\n",
    "        tables = con.execute(\"SELECT name FROM sqlite_master WHERE type='table'\").fetchall()\n",
    "        for table in tables:\n",
    "            table_name = table[0]\n",
    "            count = con.execute(f\"SELECT COUNT(*) FROM {table_name}\").fetchone()[0]\n",
    "            print(f\"Table: {table_name} - {count} rows\")\n",
    "        \n",
    "        # 2. Check schema of each table\n",
    "        print(\"\\n=== Schema for each table ===\")\n",
    "        for table in tables:\n",
    "            table_name = table[0]\n",
    "            print(f\"\\nSchema for {table_name}:\")\n",
    "            schema = con.execute(f\"PRAGMA table_info({table_name})\").fetchall()\n",
    "            for col in schema:\n",
    "                print(f\"  {col[1]} ({col[2]}){' PRIMARY KEY' if col[5] > 0 else ''}\")\n",
    "        \n",
    "        # 3. Check the gene-protein relationships\n",
    "        print(\"\\n=== Gene-Protein Relationships ===\")\n",
    "        try:\n",
    "            gene_protein_stats = con.execute(\"\"\"\n",
    "                SELECT \n",
    "                    COUNT(DISTINCT gene_seqhash_id) AS total_genes,\n",
    "                    COUNT(DISTINCT protein_seqhash_id) AS total_proteins,\n",
    "                    COUNT(*) AS total_relationships\n",
    "                FROM gene_protein_map\n",
    "            \"\"\").fetchone()\n",
    "            \n",
    "            print(f\"Total genes: {gene_protein_stats[0]}\")\n",
    "            print(f\"Total proteins: {gene_protein_stats[1]}\")\n",
    "            print(f\"Total gene-protein relationships: {gene_protein_stats[2]}\")\n",
    "            \n",
    "            # Check for genes with multiple proteins\n",
    "            multi_protein_genes = con.execute(\"\"\"\n",
    "                SELECT gene_seqhash_id, COUNT(protein_seqhash_id) as protein_count\n",
    "                FROM gene_protein_map\n",
    "                GROUP BY gene_seqhash_id\n",
    "                HAVING COUNT(protein_seqhash_id) > 1\n",
    "                ORDER BY COUNT(protein_seqhash_id) DESC\n",
    "                LIMIT 5\n",
    "            \"\"\").fetchall()\n",
    "            \n",
    "            if multi_protein_genes:\n",
    "                print(\"\\nTop 5 genes with multiple proteins:\")\n",
    "                for gene in multi_protein_genes:\n",
    "                    print(f\"  Gene {gene[0]} has {gene[1]} proteins\")\n",
    "                    # Sample of proteins for this gene\n",
    "                    proteins = con.execute(f\"\"\"\n",
    "                        SELECT protein_seqhash_id \n",
    "                        FROM gene_protein_map \n",
    "                        WHERE gene_seqhash_id = '{gene[0]}'\n",
    "                        LIMIT 3\n",
    "                    \"\"\").fetchall()\n",
    "                    for protein in proteins:\n",
    "                        print(f\"    - {protein[0]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error checking gene-protein relationships: {e}\")\n",
    "        \n",
    "        # 4. Check expression data and linkage to genes\n",
    "        print(\"\\n=== Expression Data ===\")\n",
    "        try:\n",
    "            expr_stats = con.execute(\"\"\"\n",
    "                SELECT \n",
    "                    COUNT(DISTINCT gene_seqhash_id) AS genes_with_expression,\n",
    "                    COUNT(DISTINCT sample_id) AS samples_with_expression,\n",
    "                    AVG(tpm) AS avg_tpm\n",
    "                FROM expression\n",
    "            \"\"\").fetchone()\n",
    "            \n",
    "            print(f\"Genes with expression data: {expr_stats[0]}\")\n",
    "            print(f\"Samples with expression data: {expr_stats[1]}\")\n",
    "            print(f\"Average TPM: {expr_stats[2]:.2f}\")\n",
    "            \n",
    "            # Check gene-expression-protein linkage\n",
    "            gene_expr_protein = con.execute(\"\"\"\n",
    "                SELECT \n",
    "                    COUNT(DISTINCT e.gene_seqhash_id) AS genes_with_expr_and_protein,\n",
    "                    COUNT(DISTINCT gpm.protein_seqhash_id) AS proteins_linked_to_expr\n",
    "                FROM expression e\n",
    "                JOIN gene_protein_map gpm ON e.gene_seqhash_id = gpm.gene_seqhash_id\n",
    "            \"\"\").fetchone()\n",
    "            \n",
    "            print(f\"Genes with both expression and protein mappings: {gene_expr_protein[0]}\")\n",
    "            print(f\"Proteins linked to genes with expression: {gene_expr_protein[1]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error checking expression data: {e}\")\n",
    "        \n",
    "        # 5. Check annotations\n",
    "        print(\"\\n=== Annotation Data ===\")\n",
    "        try:\n",
    "            anno_stats = con.execute(\"\"\"\n",
    "                SELECT \n",
    "                    COUNT(*) AS total_annotations,\n",
    "                    COUNT(DISTINCT sample_id) AS samples_with_annotations\n",
    "                FROM annotations\n",
    "            \"\"\").fetchone()\n",
    "            \n",
    "            print(f\"Total annotated sequences: {anno_stats[0]}\")\n",
    "            print(f\"Samples with annotations: {anno_stats[1]}\")\n",
    "            \n",
    "            # Check annotation-sequence-gene-expression linkage\n",
    "            anno_gene_expr = con.execute(\"\"\"\n",
    "                SELECT \n",
    "                    COUNT(DISTINCT a.seqhash_id) AS annotated_proteins,\n",
    "                    COUNT(DISTINCT gpm.gene_seqhash_id) AS genes_of_annotated_proteins,\n",
    "                    COUNT(DISTINCT e.gene_seqhash_id) AS genes_with_annotation_and_expression\n",
    "                FROM annotations a\n",
    "                JOIN sequences s ON a.seqhash_id = s.seqhash_id\n",
    "                JOIN gene_protein_map gpm ON s.seqhash_id = gpm.protein_seqhash_id\n",
    "                LEFT JOIN expression e ON gpm.gene_seqhash_id = e.gene_seqhash_id\n",
    "            \"\"\").fetchone()\n",
    "            \n",
    "            print(f\"Annotated proteins: {anno_gene_expr[0]}\")\n",
    "            print(f\"Genes of annotated proteins: {anno_gene_expr[1]}\")\n",
    "            print(f\"Genes with both annotation and expression: {anno_gene_expr[2]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error checking annotation data: {e}\")\n",
    "        \n",
    "        # 6. Check clusters\n",
    "        print(\"\\n=== Cluster Data ===\")\n",
    "        try:\n",
    "            cluster_stats = con.execute(\"\"\"\n",
    "                SELECT \n",
    "                    COUNT(DISTINCT cluster_id) AS total_clusters,\n",
    "                    AVG(size) AS avg_cluster_size,\n",
    "                    MAX(size) AS largest_cluster\n",
    "                FROM clusters\n",
    "            \"\"\").fetchone()\n",
    "            \n",
    "            print(f\"Total clusters: {cluster_stats[0]}\")\n",
    "            print(f\"Average cluster size: {cluster_stats[1]:.2f}\")\n",
    "            print(f\"Largest cluster size: {cluster_stats[2]}\")\n",
    "            \n",
    "            # Check cluster members\n",
    "            member_stats = con.execute(\"\"\"\n",
    "                SELECT \n",
    "                    COUNT(DISTINCT seqhash_id) AS unique_members,\n",
    "                    COUNT(*) AS total_membership_records\n",
    "                FROM cluster_members\n",
    "            \"\"\").fetchone()\n",
    "            \n",
    "            print(f\"Unique sequences in clusters: {member_stats[0]}\")\n",
    "            print(f\"Total cluster membership records: {member_stats[1]}\")\n",
    "            \n",
    "            # Get top clusters\n",
    "            top_clusters = con.execute(\"\"\"\n",
    "                SELECT cluster_id, size\n",
    "                FROM clusters\n",
    "                ORDER BY size DESC\n",
    "                LIMIT 3\n",
    "            \"\"\").fetchall()\n",
    "            \n",
    "            if top_clusters:\n",
    "                print(\"\\nTop 3 largest clusters:\")\n",
    "                for cluster in top_clusters:\n",
    "                    print(f\"  Cluster {cluster[0]}: {cluster[1]} members\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error checking cluster data: {e}\")\n",
    "\n",
    "# Usage\n",
    "db_path = \"/mnt/data4/recombia.planter/SRR12068547/SRR12068547.duckdb\"\n",
    "validate_duckdb_schema(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/data4/recombia.planter/master.duckdb'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_duckdbs(\n",
    "    duckdb_paths=[outdir / f'{sample}/{sample}.duckdb' for sample in samples],\n",
    "    master_db_path=outdir / 'master.duckdb',\n",
    "    schema_sql_path=Path('../planter/database/schema/migrations/004_add_gene_protein_map.sql'),\n",
    "    upgrade_schema=True,\n",
    "    target_schema_version=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annotations': {'row_count': 2049722,\n",
       "  'columns': ['seqhash_id',\n",
       "   'seed_ortholog',\n",
       "   'evalue',\n",
       "   'score',\n",
       "   'eggnog_ogs',\n",
       "   'max_annot_lvl',\n",
       "   'cog_category',\n",
       "   'description',\n",
       "   'preferred_name',\n",
       "   'sample_id']},\n",
       " 'clusters': {'row_count': 433785,\n",
       "  'columns': ['cluster_id', 'representative_seqhash_id', 'size']},\n",
       " 'cluster_members': {'row_count': 2489980,\n",
       "  'columns': ['seqhash_id', 'cluster_id']},\n",
       " 'ec_numbers': {'row_count': 571387, 'columns': ['seqhash_id', 'ec_number']},\n",
       " 'expression': {'row_count': 3091553,\n",
       "  'columns': ['gene_seqhash_id',\n",
       "   'sample_id',\n",
       "   'tpm',\n",
       "   'num_reads',\n",
       "   'effective_length']},\n",
       " 'gene_protein_map': {'row_count': 744572,\n",
       "  'columns': ['gene_seqhash_id', 'protein_seqhash_id']},\n",
       " 'go_terms': {'row_count': 74845016, 'columns': ['seqhash_id', 'go_term']},\n",
       " 'kegg_info': {'row_count': 0,\n",
       "  'columns': ['seqhash_id',\n",
       "   'kegg_ko',\n",
       "   'kegg_pathway',\n",
       "   'kegg_module',\n",
       "   'kegg_reaction',\n",
       "   'kegg_rclass']},\n",
       " 'schema_version': {'row_count': 0,\n",
       "  'columns': ['version', 'migration_name', 'applied_at']},\n",
       " 'sequences': {'row_count': 2489980,\n",
       "  'columns': ['seqhash_id',\n",
       "   'sequence',\n",
       "   'sample_id',\n",
       "   'assembly_date',\n",
       "   'is_representative',\n",
       "   'repseq_id',\n",
       "   'length']},\n",
       " 'sra_metadata': {'row_count': 100,\n",
       "  'columns': ['sample_id',\n",
       "   'organism',\n",
       "   'study_title',\n",
       "   'study_abstract',\n",
       "   'bioproject',\n",
       "   'biosample',\n",
       "   'library_strategy',\n",
       "   'library_source',\n",
       "   'library_selection',\n",
       "   'library_layout',\n",
       "   'instrument',\n",
       "   'run_spots',\n",
       "   'run_bases',\n",
       "   'run_published']}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_tables_in_db(db_path):\n",
    "    \"\"\"\n",
    "    Check which tables exist in a DuckDB database.\n",
    "    \n",
    "    Args:\n",
    "        db_path: Path to the DuckDB file\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of table names and their row counts\n",
    "    \"\"\"\n",
    "    db_path = Path(db_path)\n",
    "    \n",
    "    if not db_path.exists():\n",
    "        print(f\"Database file does not exist: {db_path}\")\n",
    "        return {}\n",
    "    \n",
    "    try:\n",
    "        with duckdb.connect(str(db_path)) as conn:\n",
    "            # Get all table names\n",
    "            tables = conn.execute(\n",
    "                \"SELECT name FROM sqlite_master WHERE type='table'\"\n",
    "            ).fetchall()\n",
    "            \n",
    "            # Create a dictionary to store table info\n",
    "            table_info = {}\n",
    "            \n",
    "            # For each table, get row count and column info\n",
    "            for table_row in tables:\n",
    "                table_name = table_row[0]\n",
    "                \n",
    "                # Get row count\n",
    "                try:\n",
    "                    row_count = conn.execute(f\"SELECT COUNT(*) FROM {table_name}\").fetchone()[0]\n",
    "                except Exception as e:\n",
    "                    row_count = f\"Error: {str(e)}\"\n",
    "                \n",
    "                # Get column info\n",
    "                try:\n",
    "                    columns = conn.execute(f\"PRAGMA table_info({table_name})\").fetchall()\n",
    "                    column_names = [col[1] for col in columns]\n",
    "                except Exception as e:\n",
    "                    column_names = [f\"Error: {str(e)}\"]\n",
    "                \n",
    "                # Store table info\n",
    "                table_info[table_name] = {\n",
    "                    \"row_count\": row_count,\n",
    "                    \"columns\": column_names\n",
    "                }\n",
    "            \n",
    "            return table_info\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to database: {str(e)}\")\n",
    "        return {}\n",
    "    \n",
    "# db_path = \"/mnt/data4/recombia.planter/SRR12068547/SRR12068547.duckdb\"\n",
    "db_path = '/mnt/data4/recombia.planter/master.duckdb'\n",
    "check_tables_in_db(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/data4/recombia.planter/master.duckdb'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_path = '/mnt/data4/planter_outputs/tmp/newClusterDB.tsv'\n",
    "from planter.database.utils.duckdb_utils import (\n",
    "    update_clusters\n",
    ")\n",
    "\n",
    "update_clusters(\n",
    "    db_path=db_path,\n",
    "    tsv_path=cluster_path,\n",
    "    backup_first=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 2)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "clusters = pd.read_csv(cluster_path, sep='\\t', header=None, names=['cluster_id', 'seqhash_id'])\n",
    "clusters[clusters['cluster_id'] == 'v1_DLS_42f03501d692b370647a4bac7059434916aa1d21968fca917aa214f32f2ced17.p1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugging foreign key constraints for ID: v1_DLS_19696ccb77b302cd0cdff9203ea61ab6436f11d2972fe64be97b00a5961373da.p1\n",
      "ID exists in clusters table: True\n",
      "Found 12 tables in the database\n",
      "Error checking foreign keys for table annotations: Catalog Error: Pragma Function with name foreign_key_list does not exist!\n",
      "Did you mean \"force_checkpoint\"?\n",
      "Error checking foreign keys for table cluster_members: Catalog Error: Pragma Function with name foreign_key_list does not exist!\n",
      "Did you mean \"force_checkpoint\"?\n",
      "Error checking foreign keys for table ec_numbers: Catalog Error: Pragma Function with name foreign_key_list does not exist!\n",
      "Did you mean \"force_checkpoint\"?\n",
      "Error checking foreign keys for table expression: Catalog Error: Pragma Function with name foreign_key_list does not exist!\n",
      "Did you mean \"force_checkpoint\"?\n",
      "Error checking foreign keys for table expression_backup: Catalog Error: Pragma Function with name foreign_key_list does not exist!\n",
      "Did you mean \"force_checkpoint\"?\n",
      "Error checking foreign keys for table gene_protein_map: Catalog Error: Pragma Function with name foreign_key_list does not exist!\n",
      "Did you mean \"force_checkpoint\"?\n",
      "Error checking foreign keys for table go_terms: Catalog Error: Pragma Function with name foreign_key_list does not exist!\n",
      "Did you mean \"force_checkpoint\"?\n",
      "Error checking foreign keys for table kegg_info: Catalog Error: Pragma Function with name foreign_key_list does not exist!\n",
      "Did you mean \"force_checkpoint\"?\n",
      "Error checking foreign keys for table schema_version: Catalog Error: Pragma Function with name foreign_key_list does not exist!\n",
      "Did you mean \"force_checkpoint\"?\n",
      "Error checking foreign keys for table sequences: Catalog Error: Pragma Function with name foreign_key_list does not exist!\n",
      "Did you mean \"force_checkpoint\"?\n",
      "Error checking foreign keys for table sra_metadata: Catalog Error: Pragma Function with name foreign_key_list does not exist!\n",
      "Did you mean \"force_checkpoint\"?\n",
      "No explicit references to the problematic ID were found.\n",
      "This might indicate a schema issue or a constraint that's not properly detected.\n",
      "\n",
      "Checking for ID in different formats:\n",
      "Table annotations.seqhash_id contains exact match: 1 rows\n",
      "Table clusters.cluster_id contains exact match: 1 rows\n",
      "Table clusters.representative_seqhash_id contains exact match: 1 rows\n",
      "Table cluster_members.seqhash_id contains exact match: 1 rows\n",
      "Table cluster_members.cluster_id contains exact match: 2 rows\n",
      "Table sequences.seqhash_id contains exact match: 1 rows\n",
      "Table sequences.repseq_id contains exact match: 2 rows\n",
      "\n",
      "Clusters table structure:\n",
      "  (0, 'cluster_id', 'VARCHAR', True, None, True)\n",
      "  (1, 'representative_seqhash_id', 'VARCHAR', True, None, False)\n",
      "  (2, 'size', 'INTEGER', True, None, False)\n",
      "\n",
      "Cluster_members table structure:\n",
      "  (0, 'seqhash_id', 'VARCHAR', True, None, True)\n",
      "  (1, 'cluster_id', 'VARCHAR', True, None, False)\n"
     ]
    }
   ],
   "source": [
    "def debug_foreign_key_issues(\n",
    "    db_path: Union[str, Path],\n",
    "    problematic_id: str = \"v1_DLS_19696ccb77b302cd0cdff9203ea61ab6436f11d2972fe64be97b00a5961373da.p1\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Debug foreign key constraint issues with a specific cluster ID.\n",
    "    \n",
    "    Args:\n",
    "        db_path: Path to the DuckDB database\n",
    "        problematic_id: The specific ID causing constraint issues\n",
    "    \"\"\"\n",
    "    db_path = str(db_path)\n",
    "    con = duckdb.connect(db_path)\n",
    "    \n",
    "    try:\n",
    "        print(f\"Debugging foreign key constraints for ID: {problematic_id}\")\n",
    "        \n",
    "        # 1. First, check if this ID exists in the clusters table\n",
    "        cluster_exists = con.execute(\n",
    "            f\"SELECT COUNT(*) FROM clusters WHERE cluster_id = '{problematic_id}'\"\n",
    "        ).fetchone()[0]\n",
    "        print(f\"ID exists in clusters table: {cluster_exists > 0}\")\n",
    "        \n",
    "        # 2. Get all tables in the database\n",
    "        tables = con.execute(\"SELECT name FROM sqlite_master WHERE type='table'\").fetchall()\n",
    "        print(f\"Found {len(tables)} tables in the database\")\n",
    "        \n",
    "        # 3. Check each table to see if it references clusters\n",
    "        references = []\n",
    "        for table in tables:\n",
    "            table_name = table[0]\n",
    "            if table_name == 'clusters':\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                # Check if the table has foreign keys to clusters\n",
    "                fk_info = con.execute(f\"PRAGMA foreign_key_list({table_name})\").fetchall()\n",
    "                for fk in fk_info:\n",
    "                    if fk[2] == 'clusters':\n",
    "                        ref_table = table_name\n",
    "                        ref_col = fk[3]  # Referenced column in clusters\n",
    "                        local_col = fk[4]  # Local column in this table\n",
    "                        references.append((ref_table, local_col, ref_col))\n",
    "                        print(f\"Table {ref_table} references clusters.{ref_col} via {local_col}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error checking foreign keys for table {table_name}: {str(e)}\")\n",
    "        \n",
    "        # 4. For each table that references clusters, check if our problematic ID is referenced\n",
    "        found_references = False\n",
    "        for ref_table, local_col, ref_col in references:\n",
    "            try:\n",
    "                if ref_col == 'cluster_id':\n",
    "                    # Check if this table references our problematic ID\n",
    "                    ref_count = con.execute(\n",
    "                        f\"SELECT COUNT(*) FROM {ref_table} WHERE {local_col} = '{problematic_id}'\"\n",
    "                    ).fetchone()[0]\n",
    "                    \n",
    "                    if ref_count > 0:\n",
    "                        found_references = True\n",
    "                        print(f\"FOUND REFERENCE: Table {ref_table} has {ref_count} rows referencing the problematic ID\")\n",
    "                        \n",
    "                        # Get sample rows to understand the reference\n",
    "                        sample_rows = con.execute(\n",
    "                            f\"SELECT * FROM {ref_table} WHERE {local_col} = '{problematic_id}' LIMIT 3\"\n",
    "                        ).fetchall()\n",
    "                        print(f\"Sample rows from {ref_table}:\")\n",
    "                        for row in sample_rows:\n",
    "                            print(f\"  {row}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error checking references in table {ref_table}: {str(e)}\")\n",
    "        \n",
    "        if not found_references:\n",
    "            print(\"No explicit references to the problematic ID were found.\")\n",
    "            print(\"This might indicate a schema issue or a constraint that's not properly detected.\")\n",
    "            \n",
    "        # 5. Check if the ID might be in a different format or location\n",
    "        print(\"\\nChecking for ID in different formats:\")\n",
    "        for table in tables:\n",
    "            table_name = table[0]\n",
    "            try:\n",
    "                # Get column names for this table\n",
    "                columns = con.execute(f\"PRAGMA table_info({table_name})\").fetchall()\n",
    "                column_names = [col[1] for col in columns]\n",
    "                \n",
    "                # Check each column that might contain IDs\n",
    "                for col in column_names:\n",
    "                    if \"id\" in col.lower() or \"hash\" in col.lower() or \"key\" in col.lower():\n",
    "                        # Look for exact match\n",
    "                        exact_match = con.execute(\n",
    "                            f\"SELECT COUNT(*) FROM {table_name} WHERE {col} = '{problematic_id}'\"\n",
    "                        ).fetchone()[0]\n",
    "                        \n",
    "                        # Look for partial match\n",
    "                        partial_match = con.execute(\n",
    "                            f\"SELECT COUNT(*) FROM {table_name} WHERE {col} LIKE '%{problematic_id}%'\"\n",
    "                        ).fetchone()[0]\n",
    "                        \n",
    "                        if exact_match > 0:\n",
    "                            print(f\"Table {table_name}.{col} contains exact match: {exact_match} rows\")\n",
    "                        elif partial_match > 0:\n",
    "                            print(f\"Table {table_name}.{col} contains partial match: {partial_match} rows\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error checking table {table_name} columns: {str(e)}\")\n",
    "                \n",
    "        # 6. Check if the clusters table has the expected structure\n",
    "        print(\"\\nClusters table structure:\")\n",
    "        cluster_cols = con.execute(\"PRAGMA table_info(clusters)\").fetchall()\n",
    "        for col in cluster_cols:\n",
    "            print(f\"  {col}\")\n",
    "            \n",
    "        print(\"\\nCluster_members table structure:\")\n",
    "        member_cols = con.execute(\"PRAGMA table_info(cluster_members)\").fetchall()\n",
    "        for col in member_cols:\n",
    "            print(f\"  {col}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during debugging: {str(e)}\")\n",
    "    finally:\n",
    "        con.close()\n",
    "\n",
    "debug_foreign_key_issues(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for sequence ID: v1_DLS_a0a80e8508b66a50baba10818dc3b384cc13f0efb454dde8fc2c0dba1c936b19.p1\n",
      "ID exists in sequences table: False\n",
      "ID appears in TSV as sequence: True (1 times)\n",
      "ID appears in TSV as representative: False (0 times)\n",
      "Sample entries from TSV where ID is sequence:\n",
      "  ('v1_DLS_76400afa768372fd4118749f12b4252d972ea5024d4a582eaae1406cdf2c409b.p1', 'v1_DLS_a0a80e8508b66a50baba10818dc3b384cc13f0efb454dde8fc2c0dba1c936b19.p1')\n",
      "Total sequences in TSV missing from sequences table: 2585\n",
      "Sample of missing sequences:\n",
      "  1. v1_DLS_0aa8c2e83469e1ffc35fcd62036e912dc065345e35af76618ad10d60c93254a3.p1\n",
      "  2. v1_DLS_535ef37f0da2d881934117e345d4b080562c095bf4261380f2e186568bf6ce93.p1\n",
      "  3. v1_DLS_ad38a37bc806cbc7f948fa82d627b090ebd1dd34198b0690c51207a76b2c64ed.p1\n",
      "  4. v1_DLS_5e3b94322da686cedfffbf7ad8b27321fb217fb3036f886eb871e70d16898a1a.p1\n",
      "  5. v1_DLS_f973093a0658b4dddb4aefcece0e9bf8368a87a5b3708d8ee2a50330bdb478fb.p2\n",
      "  6. v1_DLS_b4948245d0398f054a1a41528136e3577c125a65504f2009ad6ea667c89ee57c.p1\n",
      "  7. v1_DLS_fcc1c5603a02c6e69f955dec7163f9189c23bf3c5f625d21a2e25e9a519ef284.p1\n",
      "  8. v1_DLS_7ee07f2ee58837aaa9b8d905a6de4a457448e1985247d2299c5c879e608b185b.p1\n",
      "  9. v1_DLS_53a16f034ddb2f317537fca07c0f9d1259bc42b3833f75f9b18724c8916eef8c.p1\n",
      "  10. v1_DLS_0638a90f44f329fbcc20927885725f0e01b4dfc8567e8cff34d79ba498ba8c5a.p1\n"
     ]
    }
   ],
   "source": [
    "def check_sequence_id(\n",
    "    db_path: Union[str, Path],\n",
    "    tsv_path: Union[str, Path],\n",
    "    seqhash_id: str = \"v1_DLS_a0a80e8508b66a50baba10818dc3b384cc13f0efb454dde8fc2c0dba1c936b19.p1\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Check if a specific sequence ID exists in the database and clustering TSV.\n",
    "    \n",
    "    Args:\n",
    "        db_path: Path to the DuckDB database\n",
    "        tsv_path: Path to the TSV file with cluster info\n",
    "        seqhash_id: The specific sequence ID to check\n",
    "    \"\"\"\n",
    "    db_path = str(db_path)\n",
    "    tsv_path = str(tsv_path)\n",
    "    \n",
    "    print(f\"Checking for sequence ID: {seqhash_id}\")\n",
    "    \n",
    "    # Check database tables\n",
    "    con = duckdb.connect(db_path)\n",
    "    try:\n",
    "        # Check if this ID exists in sequences table\n",
    "        exists_in_sequences = con.execute(\n",
    "            f\"SELECT COUNT(*) FROM sequences WHERE seqhash_id = '{seqhash_id}'\"\n",
    "        ).fetchone()[0]\n",
    "        \n",
    "        print(f\"ID exists in sequences table: {exists_in_sequences > 0}\")\n",
    "        \n",
    "        if exists_in_sequences > 0:\n",
    "            # Get details about this sequence\n",
    "            seq_details = con.execute(\n",
    "                f\"SELECT * FROM sequences WHERE seqhash_id = '{seqhash_id}'\"\n",
    "            ).fetchone()\n",
    "            print(f\"Sequence details: {seq_details}\")\n",
    "        \n",
    "        # Check TSV file for this ID\n",
    "        con.execute(f\"\"\"\n",
    "            CREATE TEMP TABLE clustering_check AS\n",
    "            SELECT \n",
    "                column0 AS representative_seqhash_id,\n",
    "                column1 AS seqhash_id\n",
    "            FROM read_csv_auto('{tsv_path}', sep='\\t', header=FALSE)\n",
    "        \"\"\")\n",
    "        \n",
    "        # Check if ID appears as a sequence in clusters\n",
    "        as_sequence = con.execute(\n",
    "            f\"SELECT COUNT(*) FROM clustering_check WHERE seqhash_id = '{seqhash_id}'\"\n",
    "        ).fetchone()[0]\n",
    "        \n",
    "        # Check if ID appears as a representative\n",
    "        as_representative = con.execute(\n",
    "            f\"SELECT COUNT(*) FROM clustering_check WHERE representative_seqhash_id = '{seqhash_id}'\"\n",
    "        ).fetchone()[0]\n",
    "        \n",
    "        print(f\"ID appears in TSV as sequence: {as_sequence > 0} ({as_sequence} times)\")\n",
    "        print(f\"ID appears in TSV as representative: {as_representative > 0} ({as_representative} times)\")\n",
    "        \n",
    "        # Get sample of problematic entries from TSV\n",
    "        if as_sequence > 0:\n",
    "            sample = con.execute(\n",
    "                f\"SELECT * FROM clustering_check WHERE seqhash_id = '{seqhash_id}' LIMIT 3\"\n",
    "            ).fetchall()\n",
    "            print(f\"Sample entries from TSV where ID is sequence:\")\n",
    "            for entry in sample:\n",
    "                print(f\"  {entry}\")\n",
    "        \n",
    "        # Count total sequences in TSV not in sequences table\n",
    "        missing_seqs = con.execute(\"\"\"\n",
    "            SELECT COUNT(DISTINCT tc.seqhash_id) \n",
    "            FROM clustering_check tc\n",
    "            LEFT JOIN sequences s ON tc.seqhash_id = s.seqhash_id\n",
    "            WHERE s.seqhash_id IS NULL\n",
    "        \"\"\").fetchone()[0]\n",
    "        \n",
    "        print(f\"Total sequences in TSV missing from sequences table: {missing_seqs}\")\n",
    "        \n",
    "        # Get sample of missing sequences\n",
    "        if missing_seqs > 0:\n",
    "            sample_missing = con.execute(\"\"\"\n",
    "                SELECT DISTINCT tc.seqhash_id \n",
    "                FROM clustering_check tc\n",
    "                LEFT JOIN sequences s ON tc.seqhash_id = s.seqhash_id\n",
    "                WHERE s.seqhash_id IS NULL\n",
    "                LIMIT 10\n",
    "            \"\"\").fetchall()\n",
    "            \n",
    "            print(\"Sample of missing sequences:\")\n",
    "            for i, (seq_id,) in enumerate(sample_missing, 1):\n",
    "                print(f\"  {i}. {seq_id}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during check: {str(e)}\")\n",
    "    finally:\n",
    "        try:\n",
    "            con.execute(\"DROP TABLE IF EXISTS clustering_check\")\n",
    "        except:\n",
    "            pass\n",
    "        con.close()\n",
    "\n",
    "check_sequence_id(db_path, cluster_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
