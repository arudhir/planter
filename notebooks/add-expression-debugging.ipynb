{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating database: /mnt/data4/recombia.planter/master.duckdb\n",
      "\n",
      "=== Tables in database ===\n",
      "Table: annotations - 2049722 rows\n",
      "Table: clusters - 428254 rows\n",
      "Table: cluster_members - 433839 rows\n",
      "Table: ec_numbers - 571387 rows\n",
      "Table: expression - 3091553 rows\n",
      "Table: gene_protein_map - 745417 rows\n",
      "Table: go_terms - 74845016 rows\n",
      "Table: kegg_info - 1626 rows\n",
      "Table: schema_version - 0 rows\n",
      "Table: sequences - 2489980 rows\n",
      "Table: sra_metadata - 100 rows\n",
      "\n",
      "=== Schema for each table ===\n",
      "\n",
      "Schema for annotations:\n",
      "  seqhash_id (VARCHAR) PRIMARY KEY\n",
      "  seed_ortholog (VARCHAR)\n",
      "  evalue (DOUBLE)\n",
      "  score (DOUBLE)\n",
      "  eggnog_ogs (VARCHAR)\n",
      "  max_annot_lvl (VARCHAR)\n",
      "  cog_category (VARCHAR)\n",
      "  description (VARCHAR)\n",
      "  preferred_name (VARCHAR)\n",
      "  sample_id (VARCHAR)\n",
      "\n",
      "Schema for clusters:\n",
      "  cluster_id (VARCHAR) PRIMARY KEY\n",
      "  representative_seqhash_id (VARCHAR)\n",
      "  size (INTEGER)\n",
      "\n",
      "Schema for cluster_members:\n",
      "  seqhash_id (VARCHAR) PRIMARY KEY\n",
      "  cluster_id (VARCHAR)\n",
      "\n",
      "Schema for ec_numbers:\n",
      "  seqhash_id (VARCHAR) PRIMARY KEY\n",
      "  ec_number (VARCHAR) PRIMARY KEY\n",
      "\n",
      "Schema for expression:\n",
      "  gene_seqhash_id (VARCHAR) PRIMARY KEY\n",
      "  sample_id (VARCHAR) PRIMARY KEY\n",
      "  tpm (DOUBLE)\n",
      "  num_reads (DOUBLE)\n",
      "  effective_length (DOUBLE)\n",
      "\n",
      "Schema for gene_protein_map:\n",
      "  gene_seqhash_id (VARCHAR) PRIMARY KEY\n",
      "  protein_seqhash_id (VARCHAR)\n",
      "\n",
      "Schema for go_terms:\n",
      "  seqhash_id (VARCHAR) PRIMARY KEY\n",
      "  go_term (VARCHAR) PRIMARY KEY\n",
      "\n",
      "Schema for kegg_info:\n",
      "  seqhash_id (VARCHAR) PRIMARY KEY\n",
      "  kegg_ko (VARCHAR)\n",
      "  kegg_pathway (VARCHAR)\n",
      "  kegg_module (VARCHAR)\n",
      "  kegg_reaction (VARCHAR)\n",
      "  kegg_rclass (VARCHAR)\n",
      "\n",
      "Schema for schema_version:\n",
      "  version (INTEGER) PRIMARY KEY\n",
      "  migration_name (VARCHAR)\n",
      "  applied_at (TIMESTAMP)\n",
      "\n",
      "Schema for sequences:\n",
      "  seqhash_id (VARCHAR) PRIMARY KEY\n",
      "  sequence (VARCHAR)\n",
      "  sample_id (VARCHAR)\n",
      "  assembly_date (TIMESTAMP)\n",
      "  is_representative (BOOLEAN)\n",
      "  repseq_id (VARCHAR)\n",
      "  length (INTEGER)\n",
      "\n",
      "Schema for sra_metadata:\n",
      "  sample_id (VARCHAR) PRIMARY KEY\n",
      "  organism (VARCHAR)\n",
      "  study_title (VARCHAR)\n",
      "  study_abstract (VARCHAR)\n",
      "  bioproject (VARCHAR)\n",
      "  biosample (VARCHAR)\n",
      "  library_strategy (VARCHAR)\n",
      "  library_source (VARCHAR)\n",
      "  library_selection (VARCHAR)\n",
      "  library_layout (VARCHAR)\n",
      "  instrument (VARCHAR)\n",
      "  run_spots (VARCHAR)\n",
      "  run_bases (VARCHAR)\n",
      "  run_published (VARCHAR)\n",
      "\n",
      "=== Gene-Protein Relationships ===\n",
      "Total genes: 745417\n",
      "Total proteins: 745417\n",
      "Total gene-protein relationships: 745417\n",
      "\n",
      "=== Expression Data ===\n",
      "Genes with expression data: 3089378\n",
      "Samples with expression data: 100\n",
      "Average TPM: 23.76\n",
      "Genes with both expression and protein mappings: 745415\n",
      "Proteins linked to genes with expression: 745415\n",
      "\n",
      "=== Annotation Data ===\n",
      "Total annotated sequences: 2049722\n",
      "Samples with annotations: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting cluster update for database: /mnt/data4/recombia.planter/master.duckdb\n",
      "Using clustering data from: /mnt/data4/planter_outputs/tmp/newClusterDB.tsv\n",
      "Creating backup at: /mnt/data4/recombia.planter/master.duckdb.backup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated proteins: 622261\n",
      "Genes of annotated proteins: 622261\n",
      "Genes with both annotation and expression: 622259\n",
      "\n",
      "=== Cluster Data ===\n",
      "Total clusters: 428254\n",
      "Average cluster size: 1.01\n",
      "Largest cluster size: 11\n",
      "Unique sequences in clusters: 433839\n",
      "Total cluster membership records: 433839\n",
      "\n",
      "Top 3 largest clusters:\n",
      "  Cluster v1_DLS_b6cf04a60dfba05cfefdf7b30e5096b124df4862e8ca750b224ce458186859b2.p1: 11 members\n",
      "  Cluster v1_DLS_9840696f6ab23bf92c6f0052abb5a1155bb216e1fd9f4cf72640dc61d0d1067f.p1: 10 members\n",
      "  Cluster v1_DLS_9cc2c904a6081b260551b7098f155bbd47bed2065f5df13581bf137cec7793e6.p1: 9 members\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning database transaction\n",
      "Dropping existing cluster tables...\n",
      "Recreating cluster tables...\n",
      "Loading cluster data from TSV...\n",
      "Loaded 434196 entries from clustering TSV\n",
      "Identifying missing sequences...\n",
      "Found 405 unique sequences missing from database\n",
      "Found 97 unique representatives missing from database\n",
      "Examples of missing sequences:\n",
      "  1. v1_DLS_949373a9e71f2f214edd35ea996aa191e86d68078100881964c9ae62a807bdfc.p1\n",
      "  2. v1_DLS_980f3743865237442263468769fa1d181375a50a71cbc2a8f4d9b5653c61631e.p1\n",
      "  3. v1_DLS_f849657514ab54a94eafc43e9269145cb965b63f4fc5c9dae3f03f93d39d3e29.p1\n",
      "  4. v1_DLS_fad3debbef4f903e627bf3302904961b8a2e0881b1413428a37f724f889654e0.p3\n",
      "  5. v1_DLS_e43154b19a472f3a71380e77f39d01c164328ebd8ceeaff426b375e21dc96444.p1\n",
      "  6. v1_DLS_ea79808b029b69dd603e99ce798c5b9babd7b7fa57934542d938192d0feeeab4.p1\n",
      "  7. v1_DLS_5f9281e47aef25e07b74bf6c464e6d1febca8efceb8b5d4526d5ac98a5ee2322.p2\n",
      "  8. v1_DLS_b9c34104a087753049bf5ff737c06fdc880308e775d72d943695eff2481b0650.p1\n",
      "  9. v1_DLS_26eecf7a81b6d45af7340b42a5a8d0103a4a9f88b30708b258a657e313ba695f.p1\n",
      "  10. v1_DLS_bc4933dd11479bb3557358bf03eb6ff81e7eb1720f298f7ecdfd010025125fd0.p1\n",
      "Filtering to valid entries only...\n",
      "Retained 433791/434196 entries after filtering\n",
      "Updating sequences with representative information...\n",
      "Updated 2489980 sequences with representative info\n",
      "Creating clusters...\n",
      "Created 428253 clusters\n",
      "Adding cluster memberships...\n",
      "Added 433791 cluster memberships\n",
      "Average cluster size: 1.01\n",
      "Largest cluster size: 11\n",
      "Successfully updated cluster information\n",
      "Log file saved to: /mnt/data4/recombia.planter/cluster_update_20250311_210721.log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/mnt/data4/recombia.planter/master.duckdb.backup'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from planter.database.utils.duckdb_utils import (\n",
    "    extract_representative_sequences, \n",
    "    create_duckdb,\n",
    "    merge_duckdbs,\n",
    "    validate_duckdb_schema,\n",
    "    update_clusters\n",
    ")\n",
    "\n",
    "samples = ['SRR12068547', 'SRR12068548', 'SRR12068549', 'SRR12068550', 'SRR12068551', 'SRR12068552']\n",
    "outdir = Path('/mnt/data4/recombia.planter')\n",
    "cluster_path = '/mnt/data4/planter_outputs/tmp/newClusterDB.tsv'\n",
    "\n",
    "# 1. Create duckdbs for Mesoplasma samples\n",
    "for sample in samples:\n",
    "    duckdb_path = outdir / f'{sample}/{sample}.duckdb'\n",
    "    if duckdb_path.exists():\n",
    "        # remove the duckdb file\n",
    "        duckdb_path.unlink()\n",
    "    create_duckdb(\n",
    "        sample_id=sample,\n",
    "        outdir=outdir,\n",
    "        duckdb_out=outdir / f'{sample}/{sample}.duckdb'\n",
    "    )\n",
    "\n",
    "# 2. Merge all duckdbs into a master duckdb\n",
    "merge_duckdbs(\n",
    "    duckdb_paths=[outdir / f'{sample}/{sample}.duckdb' for sample in samples],\n",
    "    master_db_path=outdir / 'master.duckdb',\n",
    "    schema_sql_path=Path('../planter/database/schema/migrations/004_add_gene_protein_map.sql'),\n",
    "    upgrade_schema=True,\n",
    "    target_schema_version=None\n",
    ")\n",
    "\n",
    "# 3. Validate the master duckdb\n",
    "validate_duckdb_schema(outdir / 'master.duckdb')\n",
    "\n",
    "# 4. Add cluster info to the master duckdb\n",
    "update_clusters(\n",
    "    db_path=outdir / 'master.duckdb',\n",
    "    tsv_path=cluster_path,\n",
    "    backup_first=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using existing master database at /mnt/data4/recombia.planter/master.duckdb.backup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging databases using schema version 2\n",
      "Existing tables in master database: go_terms, cluster_members, gene_protein_map, sra_metadata, kegg_info, annotations, ec_numbers, clusters, sequences, schema_version, expression\n",
      "Attaching /mnt/data4/recombia.planter/SRR12068547/SRR12068547.duckdb as db0...\n",
      "Source database schema version: 2\n",
      "Tables in source database: go_terms, cluster_members, gene_protein_map, sra_metadata, kegg_info, annotations, ec_numbers, clusters, sequences, schema_version, expression\n",
      "  - Inserted rows in sra_metadata: 100\n",
      "  - Inserted rows in sequences: 2489980\n",
      "  - Inserted rows in annotations: 2049722\n",
      "  - Inserted rows in go_terms: 74845016\n",
      "  - Inserted rows in ec_numbers: 571387\n",
      "  - Inserted rows in clusters: 428254\n",
      "  - Inserted rows in cluster_members: 433839\n",
      "Processed 398 rows for gene_protein_map individually\n",
      "  - Inserted rows in gene_protein_map: 745417\n",
      "  - Inserted rows in expression: 3091553\n",
      "Adapting kegg_info schema: matching 6 columns\n",
      "Target columns: ['seqhash_id', 'kegg_ko', 'kegg_pathway', 'kegg_module', 'kegg_reaction', 'kegg_rclass']\n",
      "Source columns: ['seqhash_id', 'kegg_ko', 'kegg_pathway', 'kegg_module', 'kegg_reaction', 'kegg_rclass', 'brite', 'kegg_tc', 'cazy', 'bigg_reaction', 'pfams', 'sample_id']\n",
      "  - Inserted rows in kegg_info: 1626\n",
      "Finished merging /mnt/data4/recombia.planter/SRR12068547/SRR12068547.duckdb\n",
      "Attaching /mnt/data4/recombia.planter/SRR12068548/SRR12068548.duckdb as db1...\n",
      "Source database schema version: 2\n",
      "Tables in source database: go_terms, cluster_members, gene_protein_map, sra_metadata, kegg_info, annotations, ec_numbers, clusters, sequences, schema_version, expression\n",
      "  - Inserted rows in sra_metadata: 100\n",
      "  - Inserted rows in sequences: 2489980\n",
      "  - Inserted rows in annotations: 2049722\n",
      "  - Inserted rows in go_terms: 74845016\n",
      "  - Inserted rows in ec_numbers: 571387\n",
      "  - Inserted rows in clusters: 428254\n",
      "  - Inserted rows in cluster_members: 433839\n",
      "Processed 369 rows for gene_protein_map individually\n",
      "  - Inserted rows in gene_protein_map: 745417\n",
      "  - Inserted rows in expression: 3091553\n",
      "Adapting kegg_info schema: matching 6 columns\n",
      "Target columns: ['seqhash_id', 'kegg_ko', 'kegg_pathway', 'kegg_module', 'kegg_reaction', 'kegg_rclass']\n",
      "Source columns: ['seqhash_id', 'kegg_ko', 'kegg_pathway', 'kegg_module', 'kegg_reaction', 'kegg_rclass', 'brite', 'kegg_tc', 'cazy', 'bigg_reaction', 'pfams', 'sample_id']\n",
      "  - Inserted rows in kegg_info: 1626\n",
      "Finished merging /mnt/data4/recombia.planter/SRR12068548/SRR12068548.duckdb\n",
      "Attaching /mnt/data4/recombia.planter/SRR12068549/SRR12068549.duckdb as db2...\n",
      "Source database schema version: 2\n",
      "Tables in source database: go_terms, cluster_members, gene_protein_map, sra_metadata, kegg_info, annotations, ec_numbers, clusters, sequences, schema_version, expression\n",
      "  - Inserted rows in sra_metadata: 100\n",
      "  - Inserted rows in sequences: 2489980\n",
      "  - Inserted rows in annotations: 2049722\n",
      "  - Inserted rows in go_terms: 74845016\n",
      "  - Inserted rows in ec_numbers: 571387\n",
      "  - Inserted rows in clusters: 428254\n",
      "  - Inserted rows in cluster_members: 433839\n",
      "Processed 577 rows for gene_protein_map individually\n",
      "  - Inserted rows in gene_protein_map: 745417\n",
      "  - Inserted rows in expression: 3091553\n",
      "Adapting kegg_info schema: matching 6 columns\n",
      "Target columns: ['seqhash_id', 'kegg_ko', 'kegg_pathway', 'kegg_module', 'kegg_reaction', 'kegg_rclass']\n",
      "Source columns: ['seqhash_id', 'kegg_ko', 'kegg_pathway', 'kegg_module', 'kegg_reaction', 'kegg_rclass', 'brite', 'kegg_tc', 'cazy', 'bigg_reaction', 'pfams', 'sample_id']\n",
      "  - Inserted rows in kegg_info: 1626\n",
      "Finished merging /mnt/data4/recombia.planter/SRR12068549/SRR12068549.duckdb\n",
      "Attaching /mnt/data4/recombia.planter/SRR12068550/SRR12068550.duckdb as db3...\n",
      "Source database schema version: 2\n",
      "Tables in source database: go_terms, cluster_members, gene_protein_map, sra_metadata, kegg_info, annotations, ec_numbers, clusters, sequences, schema_version, expression\n",
      "  - Inserted rows in sra_metadata: 100\n",
      "  - Inserted rows in sequences: 2489980\n",
      "  - Inserted rows in annotations: 2049722\n",
      "  - Inserted rows in go_terms: 74845016\n",
      "  - Inserted rows in ec_numbers: 571387\n",
      "  - Inserted rows in clusters: 428254\n",
      "  - Inserted rows in cluster_members: 433839\n",
      "Processed 519 rows for gene_protein_map individually\n",
      "  - Inserted rows in gene_protein_map: 745417\n",
      "  - Inserted rows in expression: 3091553\n",
      "Adapting kegg_info schema: matching 6 columns\n",
      "Target columns: ['seqhash_id', 'kegg_ko', 'kegg_pathway', 'kegg_module', 'kegg_reaction', 'kegg_rclass']\n",
      "Source columns: ['seqhash_id', 'kegg_ko', 'kegg_pathway', 'kegg_module', 'kegg_reaction', 'kegg_rclass', 'brite', 'kegg_tc', 'cazy', 'bigg_reaction', 'pfams', 'sample_id']\n",
      "  - Inserted rows in kegg_info: 1626\n",
      "Finished merging /mnt/data4/recombia.planter/SRR12068550/SRR12068550.duckdb\n",
      "Attaching /mnt/data4/recombia.planter/SRR12068551/SRR12068551.duckdb as db4...\n",
      "Source database schema version: 2\n",
      "Tables in source database: go_terms, cluster_members, gene_protein_map, sra_metadata, kegg_info, annotations, ec_numbers, clusters, sequences, schema_version, expression\n",
      "  - Inserted rows in sra_metadata: 100\n",
      "  - Inserted rows in sequences: 2489980\n",
      "  - Inserted rows in annotations: 2049722\n",
      "  - Inserted rows in go_terms: 74845016\n",
      "  - Inserted rows in ec_numbers: 571387\n",
      "  - Inserted rows in clusters: 428254\n",
      "  - Inserted rows in cluster_members: 433839\n",
      "Processed 388 rows for gene_protein_map individually\n",
      "  - Inserted rows in gene_protein_map: 745417\n",
      "  - Inserted rows in expression: 3091553\n",
      "Adapting kegg_info schema: matching 6 columns\n",
      "Target columns: ['seqhash_id', 'kegg_ko', 'kegg_pathway', 'kegg_module', 'kegg_reaction', 'kegg_rclass']\n",
      "Source columns: ['seqhash_id', 'kegg_ko', 'kegg_pathway', 'kegg_module', 'kegg_reaction', 'kegg_rclass', 'brite', 'kegg_tc', 'cazy', 'bigg_reaction', 'pfams', 'sample_id']\n",
      "  - Inserted rows in kegg_info: 1626\n",
      "Finished merging /mnt/data4/recombia.planter/SRR12068551/SRR12068551.duckdb\n",
      "Attaching /mnt/data4/recombia.planter/SRR12068552/SRR12068552.duckdb as db5...\n",
      "Source database schema version: 2\n",
      "Tables in source database: go_terms, cluster_members, gene_protein_map, sra_metadata, kegg_info, annotations, ec_numbers, clusters, sequences, schema_version, expression\n",
      "  - Inserted rows in sra_metadata: 100\n",
      "  - Inserted rows in sequences: 2489980\n",
      "  - Inserted rows in annotations: 2049722\n",
      "  - Inserted rows in go_terms: 74845016\n",
      "  - Inserted rows in ec_numbers: 571387\n",
      "  - Inserted rows in clusters: 428254\n",
      "  - Inserted rows in cluster_members: 433839\n",
      "Processed 422 rows for gene_protein_map individually\n",
      "  - Inserted rows in gene_protein_map: 745417\n",
      "  - Inserted rows in expression: 3091553\n",
      "Adapting kegg_info schema: matching 6 columns\n",
      "Target columns: ['seqhash_id', 'kegg_ko', 'kegg_pathway', 'kegg_module', 'kegg_reaction', 'kegg_rclass']\n",
      "Source columns: ['seqhash_id', 'kegg_ko', 'kegg_pathway', 'kegg_module', 'kegg_reaction', 'kegg_rclass', 'brite', 'kegg_tc', 'cazy', 'bigg_reaction', 'pfams', 'sample_id']\n",
      "  - Inserted rows in kegg_info: 1626\n",
      "Finished merging /mnt/data4/recombia.planter/SRR12068552/SRR12068552.duckdb\n",
      "All databases have been merged into: /mnt/data4/recombia.planter/master.duckdb.backup\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/mnt/data4/recombia.planter/master.duckdb.backup'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_duckdbs(\n",
    "    duckdb_paths=[outdir / f'{sample}/{sample}.duckdb' for sample in samples],\n",
    "    master_db_path=outdir / 'master.duckdb.backup',\n",
    "    schema_sql_path=Path('../planter/database/schema/migrations/004_add_gene_protein_map.sql'),\n",
    "    upgrade_schema=True,\n",
    "    target_schema_version=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annotations': {'row_count': 2049722,\n",
       "  'columns': ['seqhash_id',\n",
       "   'seed_ortholog',\n",
       "   'evalue',\n",
       "   'score',\n",
       "   'eggnog_ogs',\n",
       "   'max_annot_lvl',\n",
       "   'cog_category',\n",
       "   'description',\n",
       "   'preferred_name',\n",
       "   'sample_id']},\n",
       " 'clusters': {'row_count': 433785,\n",
       "  'columns': ['cluster_id', 'representative_seqhash_id', 'size']},\n",
       " 'cluster_members': {'row_count': 2489980,\n",
       "  'columns': ['seqhash_id', 'cluster_id']},\n",
       " 'ec_numbers': {'row_count': 571387, 'columns': ['seqhash_id', 'ec_number']},\n",
       " 'expression': {'row_count': 3091553,\n",
       "  'columns': ['gene_seqhash_id',\n",
       "   'sample_id',\n",
       "   'tpm',\n",
       "   'num_reads',\n",
       "   'effective_length']},\n",
       " 'gene_protein_map': {'row_count': 744572,\n",
       "  'columns': ['gene_seqhash_id', 'protein_seqhash_id']},\n",
       " 'go_terms': {'row_count': 74845016, 'columns': ['seqhash_id', 'go_term']},\n",
       " 'kegg_info': {'row_count': 0,\n",
       "  'columns': ['seqhash_id',\n",
       "   'kegg_ko',\n",
       "   'kegg_pathway',\n",
       "   'kegg_module',\n",
       "   'kegg_reaction',\n",
       "   'kegg_rclass']},\n",
       " 'schema_version': {'row_count': 0,\n",
       "  'columns': ['version', 'migration_name', 'applied_at']},\n",
       " 'sequences': {'row_count': 2489980,\n",
       "  'columns': ['seqhash_id',\n",
       "   'sequence',\n",
       "   'sample_id',\n",
       "   'assembly_date',\n",
       "   'is_representative',\n",
       "   'repseq_id',\n",
       "   'length']},\n",
       " 'sra_metadata': {'row_count': 100,\n",
       "  'columns': ['sample_id',\n",
       "   'organism',\n",
       "   'study_title',\n",
       "   'study_abstract',\n",
       "   'bioproject',\n",
       "   'biosample',\n",
       "   'library_strategy',\n",
       "   'library_source',\n",
       "   'library_selection',\n",
       "   'library_layout',\n",
       "   'instrument',\n",
       "   'run_spots',\n",
       "   'run_bases',\n",
       "   'run_published']}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_tables_in_db(db_path):\n",
    "    \"\"\"\n",
    "    Check which tables exist in a DuckDB database.\n",
    "    \n",
    "    Args:\n",
    "        db_path: Path to the DuckDB file\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of table names and their row counts\n",
    "    \"\"\"\n",
    "    db_path = Path(db_path)\n",
    "    \n",
    "    if not db_path.exists():\n",
    "        print(f\"Database file does not exist: {db_path}\")\n",
    "        return {}\n",
    "    \n",
    "    try:\n",
    "        with duckdb.connect(str(db_path)) as conn:\n",
    "            # Get all table names\n",
    "            tables = conn.execute(\n",
    "                \"SELECT name FROM sqlite_master WHERE type='table'\"\n",
    "            ).fetchall()\n",
    "            \n",
    "            # Create a dictionary to store table info\n",
    "            table_info = {}\n",
    "            \n",
    "            # For each table, get row count and column info\n",
    "            for table_row in tables:\n",
    "                table_name = table_row[0]\n",
    "                \n",
    "                # Get row count\n",
    "                try:\n",
    "                    row_count = conn.execute(f\"SELECT COUNT(*) FROM {table_name}\").fetchone()[0]\n",
    "                except Exception as e:\n",
    "                    row_count = f\"Error: {str(e)}\"\n",
    "                \n",
    "                # Get column info\n",
    "                try:\n",
    "                    columns = conn.execute(f\"PRAGMA table_info({table_name})\").fetchall()\n",
    "                    column_names = [col[1] for col in columns]\n",
    "                except Exception as e:\n",
    "                    column_names = [f\"Error: {str(e)}\"]\n",
    "                \n",
    "                # Store table info\n",
    "                table_info[table_name] = {\n",
    "                    \"row_count\": row_count,\n",
    "                    \"columns\": column_names\n",
    "                }\n",
    "            \n",
    "            return table_info\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to database: {str(e)}\")\n",
    "        return {}\n",
    "    \n",
    "# db_path = \"/mnt/data4/recombia.planter/SRR12068547/SRR12068547.duckdb\"\n",
    "db_path = '/mnt/data4/recombia.planter/master.duckdb'\n",
    "check_tables_in_db(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/data4/recombia.planter/master.duckdb'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_path = '/mnt/data4/planter_outputs/tmp/newClusterDB.tsv'\n",
    "from planter.database.utils.duckdb_utils import (\n",
    "    update_clusters\n",
    ")\n",
    "\n",
    "update_clusters(\n",
    "    db_path=db_path,\n",
    "    tsv_path=cluster_path,\n",
    "    backup_first=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 2)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "clusters = pd.read_csv(cluster_path, sep='\\t', header=None, names=['cluster_id', 'seqhash_id'])\n",
    "clusters[clusters['cluster_id'] == 'v1_DLS_42f03501d692b370647a4bac7059434916aa1d21968fca917aa214f32f2ced17.p1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugging foreign key constraints for ID: v1_DLS_19696ccb77b302cd0cdff9203ea61ab6436f11d2972fe64be97b00a5961373da.p1\n",
      "ID exists in clusters table: True\n",
      "Found 12 tables in the database\n",
      "Error checking foreign keys for table annotations: Catalog Error: Pragma Function with name foreign_key_list does not exist!\n",
      "Did you mean \"force_checkpoint\"?\n",
      "Error checking foreign keys for table cluster_members: Catalog Error: Pragma Function with name foreign_key_list does not exist!\n",
      "Did you mean \"force_checkpoint\"?\n",
      "Error checking foreign keys for table ec_numbers: Catalog Error: Pragma Function with name foreign_key_list does not exist!\n",
      "Did you mean \"force_checkpoint\"?\n",
      "Error checking foreign keys for table expression: Catalog Error: Pragma Function with name foreign_key_list does not exist!\n",
      "Did you mean \"force_checkpoint\"?\n",
      "Error checking foreign keys for table expression_backup: Catalog Error: Pragma Function with name foreign_key_list does not exist!\n",
      "Did you mean \"force_checkpoint\"?\n",
      "Error checking foreign keys for table gene_protein_map: Catalog Error: Pragma Function with name foreign_key_list does not exist!\n",
      "Did you mean \"force_checkpoint\"?\n",
      "Error checking foreign keys for table go_terms: Catalog Error: Pragma Function with name foreign_key_list does not exist!\n",
      "Did you mean \"force_checkpoint\"?\n",
      "Error checking foreign keys for table kegg_info: Catalog Error: Pragma Function with name foreign_key_list does not exist!\n",
      "Did you mean \"force_checkpoint\"?\n",
      "Error checking foreign keys for table schema_version: Catalog Error: Pragma Function with name foreign_key_list does not exist!\n",
      "Did you mean \"force_checkpoint\"?\n",
      "Error checking foreign keys for table sequences: Catalog Error: Pragma Function with name foreign_key_list does not exist!\n",
      "Did you mean \"force_checkpoint\"?\n",
      "Error checking foreign keys for table sra_metadata: Catalog Error: Pragma Function with name foreign_key_list does not exist!\n",
      "Did you mean \"force_checkpoint\"?\n",
      "No explicit references to the problematic ID were found.\n",
      "This might indicate a schema issue or a constraint that's not properly detected.\n",
      "\n",
      "Checking for ID in different formats:\n",
      "Table annotations.seqhash_id contains exact match: 1 rows\n",
      "Table clusters.cluster_id contains exact match: 1 rows\n",
      "Table clusters.representative_seqhash_id contains exact match: 1 rows\n",
      "Table cluster_members.seqhash_id contains exact match: 1 rows\n",
      "Table cluster_members.cluster_id contains exact match: 2 rows\n",
      "Table sequences.seqhash_id contains exact match: 1 rows\n",
      "Table sequences.repseq_id contains exact match: 2 rows\n",
      "\n",
      "Clusters table structure:\n",
      "  (0, 'cluster_id', 'VARCHAR', True, None, True)\n",
      "  (1, 'representative_seqhash_id', 'VARCHAR', True, None, False)\n",
      "  (2, 'size', 'INTEGER', True, None, False)\n",
      "\n",
      "Cluster_members table structure:\n",
      "  (0, 'seqhash_id', 'VARCHAR', True, None, True)\n",
      "  (1, 'cluster_id', 'VARCHAR', True, None, False)\n"
     ]
    }
   ],
   "source": [
    "def debug_foreign_key_issues(\n",
    "    db_path: Union[str, Path],\n",
    "    problematic_id: str = \"v1_DLS_19696ccb77b302cd0cdff9203ea61ab6436f11d2972fe64be97b00a5961373da.p1\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Debug foreign key constraint issues with a specific cluster ID.\n",
    "    \n",
    "    Args:\n",
    "        db_path: Path to the DuckDB database\n",
    "        problematic_id: The specific ID causing constraint issues\n",
    "    \"\"\"\n",
    "    db_path = str(db_path)\n",
    "    con = duckdb.connect(db_path)\n",
    "    \n",
    "    try:\n",
    "        print(f\"Debugging foreign key constraints for ID: {problematic_id}\")\n",
    "        \n",
    "        # 1. First, check if this ID exists in the clusters table\n",
    "        cluster_exists = con.execute(\n",
    "            f\"SELECT COUNT(*) FROM clusters WHERE cluster_id = '{problematic_id}'\"\n",
    "        ).fetchone()[0]\n",
    "        print(f\"ID exists in clusters table: {cluster_exists > 0}\")\n",
    "        \n",
    "        # 2. Get all tables in the database\n",
    "        tables = con.execute(\"SELECT name FROM sqlite_master WHERE type='table'\").fetchall()\n",
    "        print(f\"Found {len(tables)} tables in the database\")\n",
    "        \n",
    "        # 3. Check each table to see if it references clusters\n",
    "        references = []\n",
    "        for table in tables:\n",
    "            table_name = table[0]\n",
    "            if table_name == 'clusters':\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                # Check if the table has foreign keys to clusters\n",
    "                fk_info = con.execute(f\"PRAGMA foreign_key_list({table_name})\").fetchall()\n",
    "                for fk in fk_info:\n",
    "                    if fk[2] == 'clusters':\n",
    "                        ref_table = table_name\n",
    "                        ref_col = fk[3]  # Referenced column in clusters\n",
    "                        local_col = fk[4]  # Local column in this table\n",
    "                        references.append((ref_table, local_col, ref_col))\n",
    "                        print(f\"Table {ref_table} references clusters.{ref_col} via {local_col}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error checking foreign keys for table {table_name}: {str(e)}\")\n",
    "        \n",
    "        # 4. For each table that references clusters, check if our problematic ID is referenced\n",
    "        found_references = False\n",
    "        for ref_table, local_col, ref_col in references:\n",
    "            try:\n",
    "                if ref_col == 'cluster_id':\n",
    "                    # Check if this table references our problematic ID\n",
    "                    ref_count = con.execute(\n",
    "                        f\"SELECT COUNT(*) FROM {ref_table} WHERE {local_col} = '{problematic_id}'\"\n",
    "                    ).fetchone()[0]\n",
    "                    \n",
    "                    if ref_count > 0:\n",
    "                        found_references = True\n",
    "                        print(f\"FOUND REFERENCE: Table {ref_table} has {ref_count} rows referencing the problematic ID\")\n",
    "                        \n",
    "                        # Get sample rows to understand the reference\n",
    "                        sample_rows = con.execute(\n",
    "                            f\"SELECT * FROM {ref_table} WHERE {local_col} = '{problematic_id}' LIMIT 3\"\n",
    "                        ).fetchall()\n",
    "                        print(f\"Sample rows from {ref_table}:\")\n",
    "                        for row in sample_rows:\n",
    "                            print(f\"  {row}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error checking references in table {ref_table}: {str(e)}\")\n",
    "        \n",
    "        if not found_references:\n",
    "            print(\"No explicit references to the problematic ID were found.\")\n",
    "            print(\"This might indicate a schema issue or a constraint that's not properly detected.\")\n",
    "            \n",
    "        # 5. Check if the ID might be in a different format or location\n",
    "        print(\"\\nChecking for ID in different formats:\")\n",
    "        for table in tables:\n",
    "            table_name = table[0]\n",
    "            try:\n",
    "                # Get column names for this table\n",
    "                columns = con.execute(f\"PRAGMA table_info({table_name})\").fetchall()\n",
    "                column_names = [col[1] for col in columns]\n",
    "                \n",
    "                # Check each column that might contain IDs\n",
    "                for col in column_names:\n",
    "                    if \"id\" in col.lower() or \"hash\" in col.lower() or \"key\" in col.lower():\n",
    "                        # Look for exact match\n",
    "                        exact_match = con.execute(\n",
    "                            f\"SELECT COUNT(*) FROM {table_name} WHERE {col} = '{problematic_id}'\"\n",
    "                        ).fetchone()[0]\n",
    "                        \n",
    "                        # Look for partial match\n",
    "                        partial_match = con.execute(\n",
    "                            f\"SELECT COUNT(*) FROM {table_name} WHERE {col} LIKE '%{problematic_id}%'\"\n",
    "                        ).fetchone()[0]\n",
    "                        \n",
    "                        if exact_match > 0:\n",
    "                            print(f\"Table {table_name}.{col} contains exact match: {exact_match} rows\")\n",
    "                        elif partial_match > 0:\n",
    "                            print(f\"Table {table_name}.{col} contains partial match: {partial_match} rows\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error checking table {table_name} columns: {str(e)}\")\n",
    "                \n",
    "        # 6. Check if the clusters table has the expected structure\n",
    "        print(\"\\nClusters table structure:\")\n",
    "        cluster_cols = con.execute(\"PRAGMA table_info(clusters)\").fetchall()\n",
    "        for col in cluster_cols:\n",
    "            print(f\"  {col}\")\n",
    "            \n",
    "        print(\"\\nCluster_members table structure:\")\n",
    "        member_cols = con.execute(\"PRAGMA table_info(cluster_members)\").fetchall()\n",
    "        for col in member_cols:\n",
    "            print(f\"  {col}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during debugging: {str(e)}\")\n",
    "    finally:\n",
    "        con.close()\n",
    "\n",
    "debug_foreign_key_issues(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for sequence ID: v1_DLS_a0a80e8508b66a50baba10818dc3b384cc13f0efb454dde8fc2c0dba1c936b19.p1\n",
      "ID exists in sequences table: False\n",
      "ID appears in TSV as sequence: True (1 times)\n",
      "ID appears in TSV as representative: False (0 times)\n",
      "Sample entries from TSV where ID is sequence:\n",
      "  ('v1_DLS_76400afa768372fd4118749f12b4252d972ea5024d4a582eaae1406cdf2c409b.p1', 'v1_DLS_a0a80e8508b66a50baba10818dc3b384cc13f0efb454dde8fc2c0dba1c936b19.p1')\n",
      "Total sequences in TSV missing from sequences table: 2585\n",
      "Sample of missing sequences:\n",
      "  1. v1_DLS_0aa8c2e83469e1ffc35fcd62036e912dc065345e35af76618ad10d60c93254a3.p1\n",
      "  2. v1_DLS_535ef37f0da2d881934117e345d4b080562c095bf4261380f2e186568bf6ce93.p1\n",
      "  3. v1_DLS_ad38a37bc806cbc7f948fa82d627b090ebd1dd34198b0690c51207a76b2c64ed.p1\n",
      "  4. v1_DLS_5e3b94322da686cedfffbf7ad8b27321fb217fb3036f886eb871e70d16898a1a.p1\n",
      "  5. v1_DLS_f973093a0658b4dddb4aefcece0e9bf8368a87a5b3708d8ee2a50330bdb478fb.p2\n",
      "  6. v1_DLS_b4948245d0398f054a1a41528136e3577c125a65504f2009ad6ea667c89ee57c.p1\n",
      "  7. v1_DLS_fcc1c5603a02c6e69f955dec7163f9189c23bf3c5f625d21a2e25e9a519ef284.p1\n",
      "  8. v1_DLS_7ee07f2ee58837aaa9b8d905a6de4a457448e1985247d2299c5c879e608b185b.p1\n",
      "  9. v1_DLS_53a16f034ddb2f317537fca07c0f9d1259bc42b3833f75f9b18724c8916eef8c.p1\n",
      "  10. v1_DLS_0638a90f44f329fbcc20927885725f0e01b4dfc8567e8cff34d79ba498ba8c5a.p1\n"
     ]
    }
   ],
   "source": [
    "def check_sequence_id(\n",
    "    db_path: Union[str, Path],\n",
    "    tsv_path: Union[str, Path],\n",
    "    seqhash_id: str = \"v1_DLS_a0a80e8508b66a50baba10818dc3b384cc13f0efb454dde8fc2c0dba1c936b19.p1\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Check if a specific sequence ID exists in the database and clustering TSV.\n",
    "    \n",
    "    Args:\n",
    "        db_path: Path to the DuckDB database\n",
    "        tsv_path: Path to the TSV file with cluster info\n",
    "        seqhash_id: The specific sequence ID to check\n",
    "    \"\"\"\n",
    "    db_path = str(db_path)\n",
    "    tsv_path = str(tsv_path)\n",
    "    \n",
    "    print(f\"Checking for sequence ID: {seqhash_id}\")\n",
    "    \n",
    "    # Check database tables\n",
    "    con = duckdb.connect(db_path)\n",
    "    try:\n",
    "        # Check if this ID exists in sequences table\n",
    "        exists_in_sequences = con.execute(\n",
    "            f\"SELECT COUNT(*) FROM sequences WHERE seqhash_id = '{seqhash_id}'\"\n",
    "        ).fetchone()[0]\n",
    "        \n",
    "        print(f\"ID exists in sequences table: {exists_in_sequences > 0}\")\n",
    "        \n",
    "        if exists_in_sequences > 0:\n",
    "            # Get details about this sequence\n",
    "            seq_details = con.execute(\n",
    "                f\"SELECT * FROM sequences WHERE seqhash_id = '{seqhash_id}'\"\n",
    "            ).fetchone()\n",
    "            print(f\"Sequence details: {seq_details}\")\n",
    "        \n",
    "        # Check TSV file for this ID\n",
    "        con.execute(f\"\"\"\n",
    "            CREATE TEMP TABLE clustering_check AS\n",
    "            SELECT \n",
    "                column0 AS representative_seqhash_id,\n",
    "                column1 AS seqhash_id\n",
    "            FROM read_csv_auto('{tsv_path}', sep='\\t', header=FALSE)\n",
    "        \"\"\")\n",
    "        \n",
    "        # Check if ID appears as a sequence in clusters\n",
    "        as_sequence = con.execute(\n",
    "            f\"SELECT COUNT(*) FROM clustering_check WHERE seqhash_id = '{seqhash_id}'\"\n",
    "        ).fetchone()[0]\n",
    "        \n",
    "        # Check if ID appears as a representative\n",
    "        as_representative = con.execute(\n",
    "            f\"SELECT COUNT(*) FROM clustering_check WHERE representative_seqhash_id = '{seqhash_id}'\"\n",
    "        ).fetchone()[0]\n",
    "        \n",
    "        print(f\"ID appears in TSV as sequence: {as_sequence > 0} ({as_sequence} times)\")\n",
    "        print(f\"ID appears in TSV as representative: {as_representative > 0} ({as_representative} times)\")\n",
    "        \n",
    "        # Get sample of problematic entries from TSV\n",
    "        if as_sequence > 0:\n",
    "            sample = con.execute(\n",
    "                f\"SELECT * FROM clustering_check WHERE seqhash_id = '{seqhash_id}' LIMIT 3\"\n",
    "            ).fetchall()\n",
    "            print(f\"Sample entries from TSV where ID is sequence:\")\n",
    "            for entry in sample:\n",
    "                print(f\"  {entry}\")\n",
    "        \n",
    "        # Count total sequences in TSV not in sequences table\n",
    "        missing_seqs = con.execute(\"\"\"\n",
    "            SELECT COUNT(DISTINCT tc.seqhash_id) \n",
    "            FROM clustering_check tc\n",
    "            LEFT JOIN sequences s ON tc.seqhash_id = s.seqhash_id\n",
    "            WHERE s.seqhash_id IS NULL\n",
    "        \"\"\").fetchone()[0]\n",
    "        \n",
    "        print(f\"Total sequences in TSV missing from sequences table: {missing_seqs}\")\n",
    "        \n",
    "        # Get sample of missing sequences\n",
    "        if missing_seqs > 0:\n",
    "            sample_missing = con.execute(\"\"\"\n",
    "                SELECT DISTINCT tc.seqhash_id \n",
    "                FROM clustering_check tc\n",
    "                LEFT JOIN sequences s ON tc.seqhash_id = s.seqhash_id\n",
    "                WHERE s.seqhash_id IS NULL\n",
    "                LIMIT 10\n",
    "            \"\"\").fetchall()\n",
    "            \n",
    "            print(\"Sample of missing sequences:\")\n",
    "            for i, (seq_id,) in enumerate(sample_missing, 1):\n",
    "                print(f\"  {i}. {seq_id}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during check: {str(e)}\")\n",
    "    finally:\n",
    "        try:\n",
    "            con.execute(\"DROP TABLE IF EXISTS clustering_check\")\n",
    "        except:\n",
    "            pass\n",
    "        con.close()\n",
    "\n",
    "check_sequence_id(db_path, cluster_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
