{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from IPython.display import display\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from Bio import SeqIO\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from typing import List, Optional, Union, Dict, Set\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build database\n",
    "\n",
    "We're using our `database.builder` module to build the database.\n",
    "\n",
    "TODO: Add logic to only insert sequences that don't already exist in the database.\n",
    "\n",
    "TODO: I think there's some duplication/differences happening in the context manager that seem dumb, both of the \"with\" statements should be able to be combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:planter.database.builder:Applying migration: 000_schema_version.sql\n",
      "INFO:planter.database.builder:Applying migration: 001_initial_schema.sql\n",
      "INFO:planter.database.builder:Applying migration: 002_add_indexes.sql\n",
      "INFO:planter.database.builder:Fetching metadata for ERR9123871\n",
      "INFO:planter.database.utils.sra:Fetching metadata for ERR9123871\n",
      "INFO:planter.database.builder:Loading sequences from /mnt/data2/planter_outputs/ERR9123871/transdecoder/ERR9123871.pep\n",
      "INFO:planter.database.builder:Loaded 30281 new sequences for ERR9123871\n",
      "INFO:planter.database.builder:Loading annotations from /mnt/data2/planter_outputs/ERR9123871/eggnog/ERR9123871.emapper.annotations\n",
      "INFO:planter.database.builder:Processed ERR9123871: 30281 sequences, 27884 annotations, 0 duplicates\n",
      "INFO:planter.database.builder:Fetching metadata for ERR9123872\n",
      "INFO:planter.database.utils.sra:Fetching metadata for ERR9123872\n",
      "INFO:planter.database.builder:Loading sequences from /mnt/data2/planter_outputs/ERR9123872/transdecoder/ERR9123872.pep\n",
      "INFO:planter.database.builder:Loaded 26342 new sequences for ERR9123872\n",
      "INFO:planter.database.builder:Skipped 9 duplicate sequences\n",
      "INFO:planter.database.builder:Loading annotations from /mnt/data2/planter_outputs/ERR9123872/eggnog/ERR9123872.emapper.annotations\n",
      "INFO:planter.database.builder:Processed ERR9123872: 26342 sequences, 24607 annotations, 9 duplicates\n",
      "INFO:planter.database.builder:Fetching metadata for ERR9123874\n",
      "INFO:planter.database.utils.sra:Fetching metadata for ERR9123874\n",
      "INFO:planter.database.builder:Loading sequences from /mnt/data2/planter_outputs/ERR9123874/transdecoder/ERR9123874.pep\n",
      "INFO:planter.database.builder:Loaded 26649 new sequences for ERR9123874\n",
      "INFO:planter.database.builder:Skipped 5 duplicate sequences\n",
      "INFO:planter.database.builder:Loading annotations from /mnt/data2/planter_outputs/ERR9123874/eggnog/ERR9123874.emapper.annotations\n",
      "INFO:planter.database.builder:Processed ERR9123874: 26649 sequences, 25078 annotations, 5 duplicates\n",
      "INFO:planter.database.builder:Fetching metadata for ERR9123875\n",
      "INFO:planter.database.utils.sra:Fetching metadata for ERR9123875\n",
      "INFO:planter.database.builder:Loading sequences from /mnt/data2/planter_outputs/ERR9123875/transdecoder/ERR9123875.pep\n",
      "INFO:planter.database.builder:Loaded 26224 new sequences for ERR9123875\n",
      "INFO:planter.database.builder:Skipped 23 duplicate sequences\n",
      "INFO:planter.database.builder:Loading annotations from /mnt/data2/planter_outputs/ERR9123875/eggnog/ERR9123875.emapper.annotations\n",
      "INFO:planter.database.builder:Processed ERR9123875: 26224 sequences, 24564 annotations, 23 duplicates\n",
      "INFO:planter.database.builder:Fetching metadata for ERR9123876\n",
      "INFO:planter.database.utils.sra:Fetching metadata for ERR9123876\n",
      "INFO:planter.database.builder:Loading sequences from /mnt/data2/planter_outputs/ERR9123876/transdecoder/ERR9123876.pep\n",
      "INFO:planter.database.builder:Loaded 26284 new sequences for ERR9123876\n",
      "INFO:planter.database.builder:Skipped 29 duplicate sequences\n",
      "INFO:planter.database.builder:Loading annotations from /mnt/data2/planter_outputs/ERR9123876/eggnog/ERR9123876.emapper.annotations\n",
      "INFO:planter.database.builder:Processed ERR9123876: 26284 sequences, 24646 annotations, 29 duplicates\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>status</th>\n",
       "      <th>sequences_loaded</th>\n",
       "      <th>annotations_loaded</th>\n",
       "      <th>duplicates</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ERR9123871</td>\n",
       "      <td>success</td>\n",
       "      <td>30281</td>\n",
       "      <td>27884</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ERR9123872</td>\n",
       "      <td>success</td>\n",
       "      <td>26342</td>\n",
       "      <td>24607</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ERR9123874</td>\n",
       "      <td>success</td>\n",
       "      <td>26649</td>\n",
       "      <td>25078</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ERR9123875</td>\n",
       "      <td>success</td>\n",
       "      <td>26224</td>\n",
       "      <td>24564</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ERR9123876</td>\n",
       "      <td>success</td>\n",
       "      <td>26284</td>\n",
       "      <td>24646</td>\n",
       "      <td>29</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sample_id   status  sequences_loaded  annotations_loaded  duplicates error\n",
       "0  ERR9123871  success             30281               27884           0  None\n",
       "1  ERR9123872  success             26342               24607           9  None\n",
       "2  ERR9123874  success             26649               25078           5  None\n",
       "3  ERR9123875  success             26224               24564          23  None\n",
       "4  ERR9123876  success             26284               24646          29  None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_sequences</th>\n",
       "      <th>total_samples</th>\n",
       "      <th>representative_sequences</th>\n",
       "      <th>annotated_sequences</th>\n",
       "      <th>sequences_with_go</th>\n",
       "      <th>sequences_with_ec</th>\n",
       "      <th>total_clusters</th>\n",
       "      <th>avg_sequence_length</th>\n",
       "      <th>min_sequence_length</th>\n",
       "      <th>max_sequence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135780</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>126779</td>\n",
       "      <td>69579</td>\n",
       "      <td>30115</td>\n",
       "      <td>0</td>\n",
       "      <td>433.54</td>\n",
       "      <td>100</td>\n",
       "      <td>3243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_sequences  total_samples  representative_sequences  \\\n",
       "0           135780              5                         0   \n",
       "\n",
       "   annotated_sequences  sequences_with_go  sequences_with_ec  total_clusters  \\\n",
       "0               126779              69579              30115               0   \n",
       "\n",
       "   avg_sequence_length  min_sequence_length  max_sequence_length  \n",
       "0               433.54                  100                 3243  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from planter.database.builder import SequenceDBBuilder\n",
    "# Define paths\n",
    "DB_PATH = \"/mnt/data2/planter_outputs/planter-test.duckdb\"\n",
    "OUTPUT_DIR = Path(\"/mnt/data2/planter_outputs\")\n",
    "# CLUSTER_TSV = \"/mnt/data/planter_outputs/clusters.tsv\"  # if you have clustering results\n",
    "\n",
    "# List of SRA IDs to process\n",
    "# sample_ids = ['ERR9123871', 'ERR9123872', 'ERR9123874', 'ERR9123875', 'ERR9123876']\n",
    "\n",
    "sample_ids = [\n",
    "    'ERR9123871', 'ERR9123872', 'ERR9123874', 'ERR9123875', 'ERR9123876', \n",
    "    'ERR9123877', 'ERR9123878', 'ERR9123879', 'ERR9123880', 'ERR9123881', \n",
    "    'ERR9123882', 'SRR10444679', 'SRR10444680', 'SRR10444681', 'SRR10444682', \n",
    "    'SRR10444683', 'SRR10444684', 'SRR11011255', 'SRR11011256', 'SRR11011257', \n",
    "    'SRR11011258', 'SRR11011259', 'SRR11011260', 'SRR12068547', 'SRR128113', \n",
    "    'SRR128114', 'SRR13765006', 'SRR14292007', 'SRR14292008', 'SRR18070778', \n",
    "    'SRR18070779', 'SRR18070780', 'SRR18070781', 'SRR18070782', 'SRR18070783', \n",
    "    'SRR18070784', 'SRR18070785', 'SRR18070786', 'SRR18070787', 'SRR18070788', \n",
    "    'SRR18070789', 'SRR18070790', 'SRR18070791', 'SRR18070792', 'SRR18070793', \n",
    "    'SRR18070794', 'SRR18070795', 'SRR18735292', 'SRR19034772', 'SRR19034773', \n",
    "    'SRR19619612', 'SRR19619613', 'SRR19619614', 'SRR22271585', 'SRR22271586', \n",
    "    'SRR22271587', 'SRR22271588', 'SRR22271589', 'SRR22904707', 'SRR24974225', \n",
    "    'SRR24974226', 'SRR24974227', 'SRR24974228', 'SRR25582085', 'SRR29366264', \n",
    "    'SRR29366265', 'SRR29366266', 'SRR5489198', 'SRR5992919', 'SRR5992920', \n",
    "    'SRR6048009', 'SRR8859643', 'SRR8859644', 'SRR8859645', \n",
    "    'SRR8859646', 'SRR8859647', 'SRR8859648'\n",
    "]\n",
    "\n",
    "\n",
    "# Build database\n",
    "with SequenceDBBuilder(DB_PATH, output_dir=OUTPUT_DIR) as builder:\n",
    "    # Build initial database with sequences and annotations\n",
    "    results = builder.build_database(sample_ids)\n",
    "    display(results)\n",
    "    \n",
    "    # # Optionally load clustering results if available\n",
    "    # if Path(CLUSTER_TSV).exists():\n",
    "    #     builder.load_clusters_from_tsv(CLUSTER_TSV)\n",
    "    \n",
    "    # Get final database summary\n",
    "    summary = builder.get_database_summary()\n",
    "    display(summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the database summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_sequences</th>\n",
       "      <th>total_samples</th>\n",
       "      <th>representative_sequences</th>\n",
       "      <th>annotated_sequences</th>\n",
       "      <th>sequences_with_go</th>\n",
       "      <th>sequences_with_ec</th>\n",
       "      <th>total_clusters</th>\n",
       "      <th>avg_sequence_length</th>\n",
       "      <th>min_sequence_length</th>\n",
       "      <th>max_sequence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1985570</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>1637348</td>\n",
       "      <td>785398</td>\n",
       "      <td>387029</td>\n",
       "      <td>0</td>\n",
       "      <td>430.94</td>\n",
       "      <td>100</td>\n",
       "      <td>7993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_sequences  total_samples  representative_sequences  \\\n",
       "0          1985570             77                         0   \n",
       "\n",
       "   annotated_sequences  sequences_with_go  sequences_with_ec  total_clusters  \\\n",
       "0              1637348             785398             387029               0   \n",
       "\n",
       "   avg_sequence_length  min_sequence_length  max_sequence_length  \n",
       "0               430.94                  100                 7993  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from planter.database.query_manager import DatabaseManager\n",
    "db_path = \"/mnt/data2/planter_outputs/planter2.duckdb\"\n",
    "\n",
    "with DatabaseManager(db_path) as db_manager:\n",
    "    summary = db_manager.query_manager.database_summary()\n",
    "    display(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See what tables and schemas are present in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in database:\n",
      "              name\n",
      "0      annotations\n",
      "1  cluster_members\n",
      "2         clusters\n",
      "3       ec_numbers\n",
      "4         go_terms\n",
      "5        kegg_info\n",
      "6   schema_version\n",
      "7        sequences\n",
      "8     sra_metadata\n",
      "\n",
      "Schema for table: annotations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>notnull</th>\n",
       "      <th>dflt_value</th>\n",
       "      <th>pk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>seqhash_id</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>seed_ortholog</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>evalue</td>\n",
       "      <td>DOUBLE</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>score</td>\n",
       "      <td>DOUBLE</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>eggnog_ogs</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>max_annot_lvl</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>cog_category</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>description</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>preferred_name</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>sample_id</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cid            name     type  notnull dflt_value     pk\n",
       "0    0      seqhash_id  VARCHAR     True       None   True\n",
       "1    1   seed_ortholog  VARCHAR    False       None  False\n",
       "2    2          evalue   DOUBLE    False       None  False\n",
       "3    3           score   DOUBLE    False       None  False\n",
       "4    4      eggnog_ogs  VARCHAR    False       None  False\n",
       "5    5   max_annot_lvl  VARCHAR    False       None  False\n",
       "6    6    cog_category  VARCHAR    False       None  False\n",
       "7    7     description  VARCHAR    False       None  False\n",
       "8    8  preferred_name  VARCHAR    False       None  False\n",
       "9    9       sample_id  VARCHAR     True       None  False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schema for table: cluster_members\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>notnull</th>\n",
       "      <th>dflt_value</th>\n",
       "      <th>pk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>seqhash_id</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>cluster_id</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cid        name     type  notnull dflt_value     pk\n",
       "0    0  seqhash_id  VARCHAR     True       None   True\n",
       "1    1  cluster_id  VARCHAR     True       None  False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schema for table: clusters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>notnull</th>\n",
       "      <th>dflt_value</th>\n",
       "      <th>pk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cluster_id</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>representative_seqhash_id</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>size</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cid                       name     type  notnull dflt_value     pk\n",
       "0    0                 cluster_id  VARCHAR     True       None   True\n",
       "1    1  representative_seqhash_id  VARCHAR     True       None  False\n",
       "2    2                       size  INTEGER     True       None  False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schema for table: ec_numbers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>notnull</th>\n",
       "      <th>dflt_value</th>\n",
       "      <th>pk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>seqhash_id</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ec_number</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cid        name     type  notnull dflt_value    pk\n",
       "0    0  seqhash_id  VARCHAR     True       None  True\n",
       "1    1   ec_number  VARCHAR     True       None  True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schema for table: go_terms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>notnull</th>\n",
       "      <th>dflt_value</th>\n",
       "      <th>pk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>seqhash_id</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>go_term</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cid        name     type  notnull dflt_value    pk\n",
       "0    0  seqhash_id  VARCHAR     True       None  True\n",
       "1    1     go_term  VARCHAR     True       None  True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schema for table: kegg_info\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>notnull</th>\n",
       "      <th>dflt_value</th>\n",
       "      <th>pk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>seqhash_id</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>kegg_ko</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>kegg_pathway</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>kegg_module</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>kegg_reaction</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>kegg_rclass</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cid           name     type  notnull dflt_value     pk\n",
       "0    0     seqhash_id  VARCHAR     True       None   True\n",
       "1    1        kegg_ko  VARCHAR    False       None  False\n",
       "2    2   kegg_pathway  VARCHAR    False       None  False\n",
       "3    3    kegg_module  VARCHAR    False       None  False\n",
       "4    4  kegg_reaction  VARCHAR    False       None  False\n",
       "5    5    kegg_rclass  VARCHAR    False       None  False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schema for table: schema_version\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>notnull</th>\n",
       "      <th>dflt_value</th>\n",
       "      <th>pk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>version</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>migration_name</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>applied_at</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "      <td>False</td>\n",
       "      <td>CURRENT_TIMESTAMP</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cid            name       type  notnull         dflt_value     pk\n",
       "0    0         version    INTEGER     True               None   True\n",
       "1    1  migration_name    VARCHAR     True               None  False\n",
       "2    2      applied_at  TIMESTAMP    False  CURRENT_TIMESTAMP  False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schema for table: sequences\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>notnull</th>\n",
       "      <th>dflt_value</th>\n",
       "      <th>pk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>seqhash_id</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sequence</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sample_id</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>assembly_date</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>is_representative</td>\n",
       "      <td>BOOLEAN</td>\n",
       "      <td>True</td>\n",
       "      <td>CAST('f' AS BOOLEAN)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>length</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cid               name       type  notnull            dflt_value     pk\n",
       "0    0         seqhash_id    VARCHAR     True                  None   True\n",
       "1    1           sequence    VARCHAR     True                  None  False\n",
       "2    2          sample_id    VARCHAR     True                  None  False\n",
       "3    3      assembly_date  TIMESTAMP     True                  None  False\n",
       "4    4  is_representative    BOOLEAN     True  CAST('f' AS BOOLEAN)  False\n",
       "5    5             length    INTEGER     True                  None  False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schema for table: sra_metadata\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>notnull</th>\n",
       "      <th>dflt_value</th>\n",
       "      <th>pk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>sample_id</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>organism</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>study_title</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>study_abstract</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>bioproject</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>biosample</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>library_strategy</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>library_source</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>library_selection</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>library_layout</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>instrument</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>run_spots</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>run_bases</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>run_published</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cid               name     type  notnull dflt_value     pk\n",
       "0     0          sample_id  VARCHAR     True       None   True\n",
       "1     1           organism  VARCHAR    False       None  False\n",
       "2     2        study_title  VARCHAR    False       None  False\n",
       "3     3     study_abstract  VARCHAR    False       None  False\n",
       "4     4         bioproject  VARCHAR    False       None  False\n",
       "5     5          biosample  VARCHAR    False       None  False\n",
       "6     6   library_strategy  VARCHAR    False       None  False\n",
       "7     7     library_source  VARCHAR    False       None  False\n",
       "8     8  library_selection  VARCHAR    False       None  False\n",
       "9     9     library_layout  VARCHAR    False       None  False\n",
       "10   10         instrument  VARCHAR    False       None  False\n",
       "11   11          run_spots  VARCHAR    False       None  False\n",
       "12   12          run_bases  VARCHAR    False       None  False\n",
       "13   13      run_published  VARCHAR    False       None  False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with DatabaseManager(db_path) as db_manager:\n",
    "    # Fetch all tables\n",
    "    tables = db_manager.con.execute(\"SHOW TABLES;\").fetchdf()\n",
    "    print(\"Tables in database:\")\n",
    "    print(tables)\n",
    "\n",
    "    # Iterate through each table and fetch its schema\n",
    "    for table in tables['name']:\n",
    "        print(f\"\\nSchema for table: {table}\")\n",
    "        schema = db_manager.con.execute(f\"PRAGMA table_info('{table}');\").fetchdf()\n",
    "        display(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sequence_annotations for seqhashIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAnnotations:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqhash_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>organism</th>\n",
       "      <th>description</th>\n",
       "      <th>preferred_name</th>\n",
       "      <th>cog_category</th>\n",
       "      <th>go_terms</th>\n",
       "      <th>ec_numbers</th>\n",
       "      <th>kegg_ko</th>\n",
       "      <th>kegg_pathway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v1_DLS_633f05f5d947805a8eae5b38eea7cdd090f48c3...</td>\n",
       "      <td>SRR10444679</td>\n",
       "      <td>Xanthoria parietina</td>\n",
       "      <td>PKS_DH</td>\n",
       "      <td>-</td>\n",
       "      <td>Q</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v1_DLS_8813cfa2d04ae4cf4c316e335a01c9d81b66255...</td>\n",
       "      <td>SRR128114</td>\n",
       "      <td>Digitalis purpurea</td>\n",
       "      <td>Belongs to the UDP-glycosyltransferase family</td>\n",
       "      <td>-</td>\n",
       "      <td>CG</td>\n",
       "      <td>None</td>\n",
       "      <td>2.4.1.210</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v1_DLS_416333688207b36e52865182ab219b807e55f9b...</td>\n",
       "      <td>SRR24974225</td>\n",
       "      <td>Digitalis purpurea</td>\n",
       "      <td>Belongs to the UDP-glycosyltransferase family</td>\n",
       "      <td>-</td>\n",
       "      <td>CG</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          seqhash_id    sample_id  \\\n",
       "0  v1_DLS_633f05f5d947805a8eae5b38eea7cdd090f48c3...  SRR10444679   \n",
       "1  v1_DLS_8813cfa2d04ae4cf4c316e335a01c9d81b66255...    SRR128114   \n",
       "2  v1_DLS_416333688207b36e52865182ab219b807e55f9b...  SRR24974225   \n",
       "\n",
       "              organism                                    description  \\\n",
       "0  Xanthoria parietina                                         PKS_DH   \n",
       "1   Digitalis purpurea  Belongs to the UDP-glycosyltransferase family   \n",
       "2   Digitalis purpurea  Belongs to the UDP-glycosyltransferase family   \n",
       "\n",
       "  preferred_name cog_category go_terms ec_numbers kegg_ko kegg_pathway  \n",
       "0              -            Q     None       None    None         None  \n",
       "1              -           CG     None  2.4.1.210    None         None  \n",
       "2              -           CG     None       None    None         None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from planter.database.query_manager import DatabaseManager\n",
    "import pandas as pd\n",
    "\n",
    "db_path = \"/mnt/data2/planter_outputs/planter2.duckdb\"\n",
    "\n",
    "# Test some seqhash IDs from your MMseqs results\n",
    "test_ids = [\n",
    "   \"v1_DLS_8813cfa2d04ae4cf4c316e335a01c9d81b66255681bc3e51a98cd00dc5563466.p2\",\n",
    "   \"v1_DLS_416333688207b36e52865182ab219b807e55f9b9cc56f30bb249fd4faa38e3da.p1\",\n",
    "   \"v1_DLS_9ec0dd0c4e615b3c23b1b8e475cd0dc87f96b87d66fb13d2d033dc87dc652ca1.p1\",\n",
    "   \"v1_DLS_633f05f5d947805a8eae5b38eea7cdd090f48c3dc1e3ce89eb0b6732042591aa.p1\",\n",
    "   \"v1_DLS_700011b382d7c61a71117db9be1cfde6ad9435a22f74e60d769f57737d13c55b.p1\"\n",
    "]\n",
    "\n",
    "with DatabaseManager(db_path) as db:\n",
    "    annotations = db.query_manager.sequence_annotations(values=(test_ids,))\n",
    "    display(\"\\nAnnotations:\", annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search sequences\n",
    "\n",
    "You can parameterize the search:\n",
    "```sql\n",
    "\n",
    "    {% if sample_id_condition %} AND {{ sample_id_condition }} {% endif %}\n",
    "    {% if min_length_condition %} AND {{ min_length_condition }} {% endif %}\n",
    "    {% if max_length_condition %} AND {{ max_length_condition }} {% endif %}\n",
    "    {% if description_condition %} AND {{ description_condition }} {% endif %}\n",
    "    {% if organism_condition %} AND {{ organism_condition }} {% endif %}\n",
    "LIMIT {{ limit }}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqhash_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>length</th>\n",
       "      <th>is_representative</th>\n",
       "      <th>description</th>\n",
       "      <th>preferred_name</th>\n",
       "      <th>cog_category</th>\n",
       "      <th>evalue</th>\n",
       "      <th>seed_ortholog</th>\n",
       "      <th>max_annot_lvl</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>cluster_size</th>\n",
       "      <th>organism</th>\n",
       "      <th>study_title</th>\n",
       "      <th>bioproject</th>\n",
       "      <th>biosample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v1_DLS_633d5b574e7f1bb30b6c8343ecbf46c6e7abfdb...</td>\n",
       "      <td>SRR10444679</td>\n",
       "      <td>416</td>\n",
       "      <td>False</td>\n",
       "      <td>Belongs to the zinc-containing alcohol dehydro...</td>\n",
       "      <td>FDH1</td>\n",
       "      <td>Q</td>\n",
       "      <td>2.120000e-245</td>\n",
       "      <td>364733.XP_007786925.1</td>\n",
       "      <td>4751|Fungi</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Xanthoria parietina</td>\n",
       "      <td>Xanthoria parietina 46-1 Gene Expression Profi...</td>\n",
       "      <td>PRJNA584076</td>\n",
       "      <td>SAMN13173247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v1_DLS_77c014405bcc0337388bb239ab428f9dd03a48c...</td>\n",
       "      <td>SRR10444679</td>\n",
       "      <td>411</td>\n",
       "      <td>False</td>\n",
       "      <td>Alcohol dehydrogenase GroES-like domain</td>\n",
       "      <td>lad1</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.160000e-192</td>\n",
       "      <td>35720.XP_003656577.1</td>\n",
       "      <td>4751|Fungi</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Xanthoria parietina</td>\n",
       "      <td>Xanthoria parietina 46-1 Gene Expression Profi...</td>\n",
       "      <td>PRJNA584076</td>\n",
       "      <td>SAMN13173247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v1_DLS_3f591e78ad65d2f652f99bebccccd2723af48de...</td>\n",
       "      <td>SRR10444679</td>\n",
       "      <td>563</td>\n",
       "      <td>False</td>\n",
       "      <td>Cytochrome p-450</td>\n",
       "      <td>-</td>\n",
       "      <td>IQ</td>\n",
       "      <td>1.490000e-169</td>\n",
       "      <td>40559.M7TAT1</td>\n",
       "      <td>4751|Fungi</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Xanthoria parietina</td>\n",
       "      <td>Xanthoria parietina 46-1 Gene Expression Profi...</td>\n",
       "      <td>PRJNA584076</td>\n",
       "      <td>SAMN13173247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v1_DLS_daa45c4ccbd841941d2b87d2f9c0d5d016da6d2...</td>\n",
       "      <td>SRR10444679</td>\n",
       "      <td>155</td>\n",
       "      <td>False</td>\n",
       "      <td>Destroys radicals which are normally produced ...</td>\n",
       "      <td>SOD1</td>\n",
       "      <td>Q</td>\n",
       "      <td>2.500000e-97</td>\n",
       "      <td>364733.XP_007805264.1</td>\n",
       "      <td>4751|Fungi</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Xanthoria parietina</td>\n",
       "      <td>Xanthoria parietina 46-1 Gene Expression Profi...</td>\n",
       "      <td>PRJNA584076</td>\n",
       "      <td>SAMN13173247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v1_DLS_22ffb3919b77d3c8ede9ccaed821bba709981fc...</td>\n",
       "      <td>SRR10444679</td>\n",
       "      <td>744</td>\n",
       "      <td>False</td>\n",
       "      <td>ABC transport system ATP-binding protein</td>\n",
       "      <td>MDL1</td>\n",
       "      <td>Q</td>\n",
       "      <td>3.750000e-293</td>\n",
       "      <td>43228.XP_007730531.1</td>\n",
       "      <td>4751|Fungi</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Xanthoria parietina</td>\n",
       "      <td>Xanthoria parietina 46-1 Gene Expression Profi...</td>\n",
       "      <td>PRJNA584076</td>\n",
       "      <td>SAMN13173247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3049</th>\n",
       "      <td>v1_DLS_aee85287c230fdf88dadc38dbf040b317690430...</td>\n",
       "      <td>SRR10444679</td>\n",
       "      <td>545</td>\n",
       "      <td>False</td>\n",
       "      <td>Phosphopantetheine attachment site</td>\n",
       "      <td>-</td>\n",
       "      <td>Q</td>\n",
       "      <td>1.450000e-86</td>\n",
       "      <td>364733.XP_007801216.1</td>\n",
       "      <td>4751|Fungi</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Xanthoria parietina</td>\n",
       "      <td>Xanthoria parietina 46-1 Gene Expression Profi...</td>\n",
       "      <td>PRJNA584076</td>\n",
       "      <td>SAMN13173247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3050</th>\n",
       "      <td>v1_DLS_af30a17a3e559e5ab99082ab00ffde6f9f094a3...</td>\n",
       "      <td>SRR10444679</td>\n",
       "      <td>341</td>\n",
       "      <td>False</td>\n",
       "      <td>cytochrome P450</td>\n",
       "      <td>-</td>\n",
       "      <td>Q</td>\n",
       "      <td>3.570000e-102</td>\n",
       "      <td>37727.XP_002145199.1</td>\n",
       "      <td>4751|Fungi</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Xanthoria parietina</td>\n",
       "      <td>Xanthoria parietina 46-1 Gene Expression Profi...</td>\n",
       "      <td>PRJNA584076</td>\n",
       "      <td>SAMN13173247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051</th>\n",
       "      <td>v1_DLS_be130915e2b2268f933a9cf059aee1f995c696f...</td>\n",
       "      <td>SRR10444679</td>\n",
       "      <td>177</td>\n",
       "      <td>False</td>\n",
       "      <td>Belongs to the cytochrome P450 family</td>\n",
       "      <td>-</td>\n",
       "      <td>Q</td>\n",
       "      <td>3.900000e-83</td>\n",
       "      <td>86049.XP_008728781.1</td>\n",
       "      <td>4751|Fungi</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Xanthoria parietina</td>\n",
       "      <td>Xanthoria parietina 46-1 Gene Expression Profi...</td>\n",
       "      <td>PRJNA584076</td>\n",
       "      <td>SAMN13173247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3052</th>\n",
       "      <td>v1_DLS_c3588ced93d98d666bf9d656c7d7aa6e86bdb93...</td>\n",
       "      <td>SRR10444679</td>\n",
       "      <td>475</td>\n",
       "      <td>False</td>\n",
       "      <td>Occurs in almost all aerobically respiring org...</td>\n",
       "      <td>-</td>\n",
       "      <td>Q</td>\n",
       "      <td>2.150000e-308</td>\n",
       "      <td>248742.XP_005645077.1</td>\n",
       "      <td>3041|Chlorophyta</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Xanthoria parietina</td>\n",
       "      <td>Xanthoria parietina 46-1 Gene Expression Profi...</td>\n",
       "      <td>PRJNA584076</td>\n",
       "      <td>SAMN13173247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3053</th>\n",
       "      <td>v1_DLS_ea6d13296dbcfd17ac0e9cbe73fd08370c543ea...</td>\n",
       "      <td>SRR10444679</td>\n",
       "      <td>514</td>\n",
       "      <td>False</td>\n",
       "      <td>cytochrome P450</td>\n",
       "      <td>-</td>\n",
       "      <td>Q</td>\n",
       "      <td>3.480000e-201</td>\n",
       "      <td>37727.XP_002145199.1</td>\n",
       "      <td>4751|Fungi</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Xanthoria parietina</td>\n",
       "      <td>Xanthoria parietina 46-1 Gene Expression Profi...</td>\n",
       "      <td>PRJNA584076</td>\n",
       "      <td>SAMN13173247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3054 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             seqhash_id    sample_id  length  \\\n",
       "0     v1_DLS_633d5b574e7f1bb30b6c8343ecbf46c6e7abfdb...  SRR10444679     416   \n",
       "1     v1_DLS_77c014405bcc0337388bb239ab428f9dd03a48c...  SRR10444679     411   \n",
       "2     v1_DLS_3f591e78ad65d2f652f99bebccccd2723af48de...  SRR10444679     563   \n",
       "3     v1_DLS_daa45c4ccbd841941d2b87d2f9c0d5d016da6d2...  SRR10444679     155   \n",
       "4     v1_DLS_22ffb3919b77d3c8ede9ccaed821bba709981fc...  SRR10444679     744   \n",
       "...                                                 ...          ...     ...   \n",
       "3049  v1_DLS_aee85287c230fdf88dadc38dbf040b317690430...  SRR10444679     545   \n",
       "3050  v1_DLS_af30a17a3e559e5ab99082ab00ffde6f9f094a3...  SRR10444679     341   \n",
       "3051  v1_DLS_be130915e2b2268f933a9cf059aee1f995c696f...  SRR10444679     177   \n",
       "3052  v1_DLS_c3588ced93d98d666bf9d656c7d7aa6e86bdb93...  SRR10444679     475   \n",
       "3053  v1_DLS_ea6d13296dbcfd17ac0e9cbe73fd08370c543ea...  SRR10444679     514   \n",
       "\n",
       "      is_representative                                        description  \\\n",
       "0                 False  Belongs to the zinc-containing alcohol dehydro...   \n",
       "1                 False            Alcohol dehydrogenase GroES-like domain   \n",
       "2                 False                                   Cytochrome p-450   \n",
       "3                 False  Destroys radicals which are normally produced ...   \n",
       "4                 False           ABC transport system ATP-binding protein   \n",
       "...                 ...                                                ...   \n",
       "3049              False                 Phosphopantetheine attachment site   \n",
       "3050              False                                    cytochrome P450   \n",
       "3051              False              Belongs to the cytochrome P450 family   \n",
       "3052              False  Occurs in almost all aerobically respiring org...   \n",
       "3053              False                                    cytochrome P450   \n",
       "\n",
       "     preferred_name cog_category         evalue          seed_ortholog  \\\n",
       "0              FDH1            Q  2.120000e-245  364733.XP_007786925.1   \n",
       "1              lad1            Q  7.160000e-192   35720.XP_003656577.1   \n",
       "2                 -           IQ  1.490000e-169           40559.M7TAT1   \n",
       "3              SOD1            Q   2.500000e-97  364733.XP_007805264.1   \n",
       "4              MDL1            Q  3.750000e-293   43228.XP_007730531.1   \n",
       "...             ...          ...            ...                    ...   \n",
       "3049              -            Q   1.450000e-86  364733.XP_007801216.1   \n",
       "3050              -            Q  3.570000e-102   37727.XP_002145199.1   \n",
       "3051              -            Q   3.900000e-83   86049.XP_008728781.1   \n",
       "3052              -            Q  2.150000e-308  248742.XP_005645077.1   \n",
       "3053              -            Q  3.480000e-201   37727.XP_002145199.1   \n",
       "\n",
       "         max_annot_lvl cluster_id  cluster_size             organism  \\\n",
       "0           4751|Fungi       None           NaN  Xanthoria parietina   \n",
       "1           4751|Fungi       None           NaN  Xanthoria parietina   \n",
       "2           4751|Fungi       None           NaN  Xanthoria parietina   \n",
       "3           4751|Fungi       None           NaN  Xanthoria parietina   \n",
       "4           4751|Fungi       None           NaN  Xanthoria parietina   \n",
       "...                ...        ...           ...                  ...   \n",
       "3049        4751|Fungi       None           NaN  Xanthoria parietina   \n",
       "3050        4751|Fungi       None           NaN  Xanthoria parietina   \n",
       "3051        4751|Fungi       None           NaN  Xanthoria parietina   \n",
       "3052  3041|Chlorophyta       None           NaN  Xanthoria parietina   \n",
       "3053        4751|Fungi       None           NaN  Xanthoria parietina   \n",
       "\n",
       "                                            study_title   bioproject  \\\n",
       "0     Xanthoria parietina 46-1 Gene Expression Profi...  PRJNA584076   \n",
       "1     Xanthoria parietina 46-1 Gene Expression Profi...  PRJNA584076   \n",
       "2     Xanthoria parietina 46-1 Gene Expression Profi...  PRJNA584076   \n",
       "3     Xanthoria parietina 46-1 Gene Expression Profi...  PRJNA584076   \n",
       "4     Xanthoria parietina 46-1 Gene Expression Profi...  PRJNA584076   \n",
       "...                                                 ...          ...   \n",
       "3049  Xanthoria parietina 46-1 Gene Expression Profi...  PRJNA584076   \n",
       "3050  Xanthoria parietina 46-1 Gene Expression Profi...  PRJNA584076   \n",
       "3051  Xanthoria parietina 46-1 Gene Expression Profi...  PRJNA584076   \n",
       "3052  Xanthoria parietina 46-1 Gene Expression Profi...  PRJNA584076   \n",
       "3053  Xanthoria parietina 46-1 Gene Expression Profi...  PRJNA584076   \n",
       "\n",
       "         biosample  \n",
       "0     SAMN13173247  \n",
       "1     SAMN13173247  \n",
       "2     SAMN13173247  \n",
       "3     SAMN13173247  \n",
       "4     SAMN13173247  \n",
       "...            ...  \n",
       "3049  SAMN13173247  \n",
       "3050  SAMN13173247  \n",
       "3051  SAMN13173247  \n",
       "3052  SAMN13173247  \n",
       "3053  SAMN13173247  \n",
       "\n",
       "[3054 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from planter.database.query_manager import DatabaseManager\n",
    "\n",
    "db_path = \"/mnt/data2/planter_outputs/planter2.duckdb\"\n",
    "output_dir = \"/mnt/data2/planter_outputs\"\n",
    "\n",
    "with DatabaseManager(db_path) as db_manager:\n",
    "    sample_ids = [\"SRR18070780\", \"SRR10444679\"]\n",
    "    # sample_id_condition = \", \".join([f\"'{sample_id}'\" for sample_id in sample_ids])\n",
    "    cog_categories = ['Q']  # desired COG categories\n",
    "    # cog_category_condition = \", \".join([f\"'{c}'\" for c in cog_categories])\n",
    "\n",
    "    go_terms = ['GO:0075109']  # example GO terms to search\n",
    "\n",
    "    params = {\n",
    "        \"sample_id_condition\": sample_ids,  # e.g., \"s.sample_id IN ('SRR18070780', 'SRR18070781')\"\n",
    "        \"cog_category_condition\": ['M', 'Q'],\n",
    "        # \"go_term_condition\": go_terms,  # pass a list of GO terms        \n",
    "        \"min_length_condition\": \"s.length >= 100\",\n",
    "        \"max_length_condition\": \"s.length <= 1000\",\n",
    "        \"description_condition\": None,\n",
    "        \"organism_condition\": None,\n",
    "        # \"limit\": 10,\n",
    "    }\n",
    "\n",
    "    results = db_manager.query_manager.search_sequences(params=params)\n",
    "    display(results)\n",
    "\n",
    "    # call go_term_summary dynamically\n",
    "    # go_summary = db_manager.query_manager.go_term_summary(None, None, 5)\n",
    "    # print(\"\\nGO term summary:\")\n",
    "    # display(go_summary)\n",
    "\n",
    "    # call organism_summary dynamically\n",
    "    # organism_summary = db_manager.query_manager.organism_summary()\n",
    "    # print(\"\\nOrganism summary:\")\n",
    "    # display(organism_summary)\n",
    "    # print(dir(db_manager.query_manager))\n",
    "    # db_manager.query_manager.search_sequences('v1_DLS_31412ec4347c212e6892097053de8dc39cd53341988080fd7b80866c35840a0a.p1')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39mcon\u001b[38;5;241m.\u001b[39mexecute(query)\u001b[38;5;241m.\u001b[39mfetchdf()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "self.con.execute(query).fetchdf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading GO file...\n",
      ".cache/go.obo: fmt(1.2) rel(2024-11-03) 43,983 Terms\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "from goatools.obo_parser import GODag\n",
    "\n",
    "def download_go_file(cache_dir=\".cache\", file_name=\"go.obo\"):\n",
    "    \"\"\"Download the GO file if it doesn't exist.\"\"\"\n",
    "    cache_path = Path(cache_dir)\n",
    "    cache_path.mkdir(exist_ok=True)\n",
    "    file_path = cache_path / file_name\n",
    "\n",
    "    if not file_path.exists():\n",
    "        print(\"Downloading GO file...\")\n",
    "        url = \"https://purl.obolibrary.org/obo/go.obo\"\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "    return file_path\n",
    "\n",
    "# usage\n",
    "obo_file = download_go_file()\n",
    "go_dag = GODag(obo_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary mapping GO term IDs to their names\n",
    "go_terms_dict = {term.id: term.name for term in go_dag.values()}\n",
    "\n",
    "# add the \"description\" column to the dataframe\n",
    "go_summary[\"description\"] = go_summary[\"go_term\"].map(go_terms_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>go_term</th>\n",
       "      <th>sequence_count</th>\n",
       "      <th>sample_ids</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22945</th>\n",
       "      <td>GO:0034771</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR18735292, SRR5992920, SRR5992919</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22946</th>\n",
       "      <td>GO:0036216</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR18735292, SRR5992919, SRR5992920</td>\n",
       "      <td>cellular response to stem cell factor stimulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22947</th>\n",
       "      <td>GO:0034264</td>\n",
       "      <td>5</td>\n",
       "      <td>ERR9123875, ERR9123877, ERR9123876, ERR9123874...</td>\n",
       "      <td>isopentenyl adenine metabolic process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22948</th>\n",
       "      <td>GO:2000354</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR5992920, SRR18735292, SRR5992919, SRR22904707</td>\n",
       "      <td>regulation of ovarian follicle development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22949</th>\n",
       "      <td>GO:0046208</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR18735292, SRR10444679, SRR5992920, SRR10444680</td>\n",
       "      <td>spermine catabolic process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22950</th>\n",
       "      <td>GO:1990335</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR5992920, SRR18735292</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22951</th>\n",
       "      <td>GO:1905550</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR5992920, SRR5992919, SRR25582085, SRR10444680</td>\n",
       "      <td>regulation of protein localization to endoplas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22952</th>\n",
       "      <td>GO:0047191</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR5992920</td>\n",
       "      <td>1-alkylglycerophosphocholine O-acyltransferase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22953</th>\n",
       "      <td>GO:0004796</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR10444680, SRR8859647, SRR8859646, SRR10444679</td>\n",
       "      <td>thromboxane-A synthase activity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22954</th>\n",
       "      <td>GO:1905600</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR22904707, SRR5992919, SRR5992920, SRR18735292</td>\n",
       "      <td>regulation of receptor-mediated endocytosis in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22955</th>\n",
       "      <td>GO:0051919</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR5992920, SRR18735292, SRR25582085, SRR5992919</td>\n",
       "      <td>positive regulation of fibrinolysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22956</th>\n",
       "      <td>GO:0098575</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR22904707, SRR8859648, SRR25582085, SRR5992919</td>\n",
       "      <td>lumenal side of lysosomal membrane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22957</th>\n",
       "      <td>GO:0090189</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR5992919, SRR22904707, SRR5992920</td>\n",
       "      <td>regulation of branching involved in ureteric b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22958</th>\n",
       "      <td>GO:0098891</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR5992919, SRR18735292, SRR5992920</td>\n",
       "      <td>extrinsic component of presynaptic active zone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22959</th>\n",
       "      <td>GO:0070054</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR13765006, SRR5992919, SRR5992920</td>\n",
       "      <td>mRNA splicing, via endonucleolytic cleavage an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22960</th>\n",
       "      <td>GO:0061074</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR18735292, SRR5992920, SRR5992919, SRR22904707</td>\n",
       "      <td>regulation of neural retina development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22961</th>\n",
       "      <td>GO:0070406</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR5992920, SRR18735292, SRR5992919</td>\n",
       "      <td>glutamine binding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22962</th>\n",
       "      <td>GO:0047045</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR8859647, SRR8859646, SRR29366264, SRR255820...</td>\n",
       "      <td>testosterone 17-beta-dehydrogenase (NADP+) act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22963</th>\n",
       "      <td>GO:1901692</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR5992920, SRR5992919</td>\n",
       "      <td>regulation of compound eye retinal cell apopto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22964</th>\n",
       "      <td>GO:0035726</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR5992920, SRR22904707, SRR25582085, SRR5992919</td>\n",
       "      <td>common myeloid progenitor cell proliferation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22965</th>\n",
       "      <td>GO:1990780</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR22904707, SRR5992920, SRR18735292</td>\n",
       "      <td>cytoplasmic side of dendritic spine plasma mem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22966</th>\n",
       "      <td>GO:0030200</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR18735292, SRR5992920, SRR5992919</td>\n",
       "      <td>heparan sulfate proteoglycan catabolic process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22967</th>\n",
       "      <td>GO:0071603</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR5992919, SRR11011258, SRR5992920</td>\n",
       "      <td>endothelial cell-cell adhesion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22968</th>\n",
       "      <td>GO:0033650</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR5992920, SRR5992919, SRR18735292</td>\n",
       "      <td>host cell mitochondrion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22969</th>\n",
       "      <td>GO:0046334</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR128113, SRR18735292, SRR5992920, SRR24974228</td>\n",
       "      <td>octopamine catabolic process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22970</th>\n",
       "      <td>GO:0098889</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR5992919, SRR18735292, SRR5992920</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22971</th>\n",
       "      <td>GO:0007383</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR5992919, SRR18735292, SRR5992920</td>\n",
       "      <td>specification of segmental identity, antennal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22972</th>\n",
       "      <td>GO:0070551</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR18735292, SRR5992919, SRR5992920</td>\n",
       "      <td>endoribonuclease activity, cleaving siRNA-pair...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22973</th>\n",
       "      <td>GO:0021530</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR18735292</td>\n",
       "      <td>spinal cord oligodendrocyte cell fate specific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22974</th>\n",
       "      <td>GO:0031276</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR14292007, SRR14292008</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22975</th>\n",
       "      <td>GO:0072134</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR5992919, SRR5992920, SRR18735292</td>\n",
       "      <td>nephrogenic mesenchyme morphogenesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22976</th>\n",
       "      <td>GO:1904920</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR8859643, SRR5992920, SRR22904707</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22977</th>\n",
       "      <td>GO:0022615</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR5992919, SRR22904707, SRR8859643, SRR5992920</td>\n",
       "      <td>protein to membrane docking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22978</th>\n",
       "      <td>GO:0014802</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR5992920, SRR22904707, SRR18735292</td>\n",
       "      <td>terminal cisterna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22979</th>\n",
       "      <td>GO:0075109</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR5992920, SRR18735292, SRR10444679, SRR5992919</td>\n",
       "      <td>symbiont-mediated perturbation of host recepto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22980</th>\n",
       "      <td>GO:0046619</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR18735292, SRR5992920, SRR5992919</td>\n",
       "      <td>lens placode formation involved in camera-type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22981</th>\n",
       "      <td>GO:0051102</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR5992919, SRR5992920</td>\n",
       "      <td>DNA ligation involved in DNA recombination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22982</th>\n",
       "      <td>GO:0006391</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR18735292, SRR5992919, SRR5992920</td>\n",
       "      <td>transcription initiation at mitochondrial prom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22983</th>\n",
       "      <td>GO:2001181</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR25582085, SRR22904707</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22984</th>\n",
       "      <td>GO:0016752</td>\n",
       "      <td>5</td>\n",
       "      <td>SRR13765006, SRR11011255</td>\n",
       "      <td>sinapoyltransferase activity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          go_term  sequence_count  \\\n",
       "22945  GO:0034771               5   \n",
       "22946  GO:0036216               5   \n",
       "22947  GO:0034264               5   \n",
       "22948  GO:2000354               5   \n",
       "22949  GO:0046208               5   \n",
       "22950  GO:1990335               5   \n",
       "22951  GO:1905550               5   \n",
       "22952  GO:0047191               5   \n",
       "22953  GO:0004796               5   \n",
       "22954  GO:1905600               5   \n",
       "22955  GO:0051919               5   \n",
       "22956  GO:0098575               5   \n",
       "22957  GO:0090189               5   \n",
       "22958  GO:0098891               5   \n",
       "22959  GO:0070054               5   \n",
       "22960  GO:0061074               5   \n",
       "22961  GO:0070406               5   \n",
       "22962  GO:0047045               5   \n",
       "22963  GO:1901692               5   \n",
       "22964  GO:0035726               5   \n",
       "22965  GO:1990780               5   \n",
       "22966  GO:0030200               5   \n",
       "22967  GO:0071603               5   \n",
       "22968  GO:0033650               5   \n",
       "22969  GO:0046334               5   \n",
       "22970  GO:0098889               5   \n",
       "22971  GO:0007383               5   \n",
       "22972  GO:0070551               5   \n",
       "22973  GO:0021530               5   \n",
       "22974  GO:0031276               5   \n",
       "22975  GO:0072134               5   \n",
       "22976  GO:1904920               5   \n",
       "22977  GO:0022615               5   \n",
       "22978  GO:0014802               5   \n",
       "22979  GO:0075109               5   \n",
       "22980  GO:0046619               5   \n",
       "22981  GO:0051102               5   \n",
       "22982  GO:0006391               5   \n",
       "22983  GO:2001181               5   \n",
       "22984  GO:0016752               5   \n",
       "\n",
       "                                              sample_ids  \\\n",
       "22945                SRR18735292, SRR5992920, SRR5992919   \n",
       "22946                SRR18735292, SRR5992919, SRR5992920   \n",
       "22947  ERR9123875, ERR9123877, ERR9123876, ERR9123874...   \n",
       "22948   SRR5992920, SRR18735292, SRR5992919, SRR22904707   \n",
       "22949  SRR18735292, SRR10444679, SRR5992920, SRR10444680   \n",
       "22950                            SRR5992920, SRR18735292   \n",
       "22951   SRR5992920, SRR5992919, SRR25582085, SRR10444680   \n",
       "22952                                         SRR5992920   \n",
       "22953   SRR10444680, SRR8859647, SRR8859646, SRR10444679   \n",
       "22954   SRR22904707, SRR5992919, SRR5992920, SRR18735292   \n",
       "22955   SRR5992920, SRR18735292, SRR25582085, SRR5992919   \n",
       "22956   SRR22904707, SRR8859648, SRR25582085, SRR5992919   \n",
       "22957                SRR5992919, SRR22904707, SRR5992920   \n",
       "22958                SRR5992919, SRR18735292, SRR5992920   \n",
       "22959                SRR13765006, SRR5992919, SRR5992920   \n",
       "22960   SRR18735292, SRR5992920, SRR5992919, SRR22904707   \n",
       "22961                SRR5992920, SRR18735292, SRR5992919   \n",
       "22962  SRR8859647, SRR8859646, SRR29366264, SRR255820...   \n",
       "22963                             SRR5992920, SRR5992919   \n",
       "22964   SRR5992920, SRR22904707, SRR25582085, SRR5992919   \n",
       "22965               SRR22904707, SRR5992920, SRR18735292   \n",
       "22966                SRR18735292, SRR5992920, SRR5992919   \n",
       "22967                SRR5992919, SRR11011258, SRR5992920   \n",
       "22968                SRR5992920, SRR5992919, SRR18735292   \n",
       "22969    SRR128113, SRR18735292, SRR5992920, SRR24974228   \n",
       "22970                SRR5992919, SRR18735292, SRR5992920   \n",
       "22971                SRR5992919, SRR18735292, SRR5992920   \n",
       "22972                SRR18735292, SRR5992919, SRR5992920   \n",
       "22973                                        SRR18735292   \n",
       "22974                           SRR14292007, SRR14292008   \n",
       "22975                SRR5992919, SRR5992920, SRR18735292   \n",
       "22976                SRR8859643, SRR5992920, SRR22904707   \n",
       "22977    SRR5992919, SRR22904707, SRR8859643, SRR5992920   \n",
       "22978               SRR5992920, SRR22904707, SRR18735292   \n",
       "22979   SRR5992920, SRR18735292, SRR10444679, SRR5992919   \n",
       "22980                SRR18735292, SRR5992920, SRR5992919   \n",
       "22981                             SRR5992919, SRR5992920   \n",
       "22982                SRR18735292, SRR5992919, SRR5992920   \n",
       "22983                           SRR25582085, SRR22904707   \n",
       "22984                           SRR13765006, SRR11011255   \n",
       "\n",
       "                                             description  \n",
       "22945                                                NaN  \n",
       "22946     cellular response to stem cell factor stimulus  \n",
       "22947              isopentenyl adenine metabolic process  \n",
       "22948         regulation of ovarian follicle development  \n",
       "22949                         spermine catabolic process  \n",
       "22950                                                NaN  \n",
       "22951  regulation of protein localization to endoplas...  \n",
       "22952  1-alkylglycerophosphocholine O-acyltransferase...  \n",
       "22953                    thromboxane-A synthase activity  \n",
       "22954  regulation of receptor-mediated endocytosis in...  \n",
       "22955                positive regulation of fibrinolysis  \n",
       "22956                 lumenal side of lysosomal membrane  \n",
       "22957  regulation of branching involved in ureteric b...  \n",
       "22958  extrinsic component of presynaptic active zone...  \n",
       "22959  mRNA splicing, via endonucleolytic cleavage an...  \n",
       "22960            regulation of neural retina development  \n",
       "22961                                  glutamine binding  \n",
       "22962  testosterone 17-beta-dehydrogenase (NADP+) act...  \n",
       "22963  regulation of compound eye retinal cell apopto...  \n",
       "22964       common myeloid progenitor cell proliferation  \n",
       "22965  cytoplasmic side of dendritic spine plasma mem...  \n",
       "22966     heparan sulfate proteoglycan catabolic process  \n",
       "22967                     endothelial cell-cell adhesion  \n",
       "22968                            host cell mitochondrion  \n",
       "22969                       octopamine catabolic process  \n",
       "22970                                                NaN  \n",
       "22971  specification of segmental identity, antennal ...  \n",
       "22972  endoribonuclease activity, cleaving siRNA-pair...  \n",
       "22973  spinal cord oligodendrocyte cell fate specific...  \n",
       "22974                                                NaN  \n",
       "22975               nephrogenic mesenchyme morphogenesis  \n",
       "22976                                                NaN  \n",
       "22977                        protein to membrane docking  \n",
       "22978                                  terminal cisterna  \n",
       "22979  symbiont-mediated perturbation of host recepto...  \n",
       "22980  lens placode formation involved in camera-type...  \n",
       "22981         DNA ligation involved in DNA recombination  \n",
       "22982  transcription initiation at mitochondrial prom...  \n",
       "22983                                                NaN  \n",
       "22984                       sinapoyltransferase activity  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "go_summary.tail(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDBQuery:\n",
    "    \"\"\"Handles database queries and analysis.\"\"\"\n",
    "    def __init__(self, db_path: str):\n",
    "        self.db_path = db_path\n",
    "        self.con = duckdb.connect(db_path)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def __enter__(self):\n",
    "        \"\"\"Context manager entry\"\"\"\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Context manager exit\"\"\"\n",
    "        self.con.close()\n",
    "\n",
    "    def get_organism_summary(self) -> pd.DataFrame:\n",
    "        \"\"\"Get summary of sequence counts per organism.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            m.organism,\n",
    "            COUNT(DISTINCT m.sample_id) as sample_count,\n",
    "            COUNT(DISTINCT s.seqhash_id) as total_sequences,\n",
    "            ROUND(AVG(s.length), 2) as avg_sequence_length,\n",
    "            COUNT(DISTINCT CASE WHEN a.seqhash_id IS NOT NULL THEN s.seqhash_id END) as annotated_sequences,\n",
    "            ROUND(COUNT(DISTINCT CASE WHEN a.seqhash_id IS NOT NULL THEN s.seqhash_id END) * 100.0 / \n",
    "                  COUNT(DISTINCT s.seqhash_id), 2) as percent_annotated,\n",
    "            COUNT(DISTINCT CASE WHEN cm.seqhash_id IS NOT NULL THEN s.seqhash_id END) as sequences_in_clusters,\n",
    "            STRING_AGG(DISTINCT m.bioproject, '; ') as bioprojects\n",
    "        FROM sra_metadata m\n",
    "        JOIN sequences s ON s.sample_id = m.sample_id\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        LEFT JOIN cluster_members cm ON s.seqhash_id = cm.seqhash_id\n",
    "        WHERE m.organism IS NOT NULL\n",
    "        GROUP BY m.organism\n",
    "        ORDER BY total_sequences DESC\n",
    "        \"\"\"\n",
    "        return self.con.execute(query).fetchdf()\n",
    "\n",
    "    def get_sample_with_metadata(self, sample_id: str) -> pd.DataFrame:\n",
    "        \"\"\"Get complete sample information including SRA metadata.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            m.*,\n",
    "            COUNT(DISTINCT s.seqhash_id) as total_sequences,\n",
    "            COUNT(DISTINCT CASE WHEN a.seqhash_id IS NOT NULL THEN s.seqhash_id END) as annotated_sequences,\n",
    "            COUNT(DISTINCT CASE WHEN g.seqhash_id IS NOT NULL THEN s.seqhash_id END) as sequences_with_go,\n",
    "            COUNT(DISTINCT CASE WHEN e.seqhash_id IS NOT NULL THEN s.seqhash_id END) as sequences_with_ec,\n",
    "            COUNT(DISTINCT CASE WHEN cm.seqhash_id IS NOT NULL THEN s.seqhash_id END) as sequences_in_clusters\n",
    "        FROM sra_metadata m\n",
    "        JOIN sequences s ON s.sample_id = m.sample_id\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        LEFT JOIN go_terms g ON s.seqhash_id = g.seqhash_id\n",
    "        LEFT JOIN ec_numbers e ON s.seqhash_id = e.seqhash_id\n",
    "        LEFT JOIN cluster_members cm ON s.seqhash_id = cm.seqhash_id\n",
    "        WHERE m.sample_id = ?\n",
    "        GROUP BY m.sample_id, m.organism, m.study_title, m.study_abstract, \n",
    "                 m.bioproject, m.biosample, m.library_strategy, m.library_source,\n",
    "                 m.library_selection, m.library_layout, m.instrument, \n",
    "                 m.run_spots, m.run_bases, m.run_published\n",
    "        \"\"\"\n",
    "        return self.con.execute(query, [sample_id]).fetchdf()\n",
    "\n",
    "    def get_organism_summary(self) -> pd.DataFrame:\n",
    "        \"\"\"Get summary of sequence counts per organism.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            m.organism,\n",
    "            COUNT(DISTINCT m.sample_id) as sample_count,\n",
    "            COUNT(DISTINCT s.seqhash_id) as total_sequences,\n",
    "            COUNT(DISTINCT CASE WHEN a.seqhash_id IS NOT NULL THEN s.seqhash_id END) as annotated_sequences,\n",
    "            COUNT(DISTINCT CASE WHEN g.seqhash_id IS NOT NULL THEN s.seqhash_id END) as sequences_with_go,\n",
    "            COUNT(DISTINCT CASE WHEN e.seqhash_id IS NOT NULL THEN s.seqhash_id END) as sequences_with_ec,\n",
    "            COUNT(DISTINCT CASE WHEN cm.seqhash_id IS NOT NULL THEN s.seqhash_id END) as sequences_in_clusters,\n",
    "            STRING_AGG(DISTINCT m.bioproject, '; ') as bioprojects\n",
    "        FROM sra_metadata m\n",
    "        JOIN sequences s ON s.sample_id = m.sample_id\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        LEFT JOIN go_terms g ON s.seqhash_id = g.seqhash_id\n",
    "        LEFT JOIN ec_numbers e ON s.seqhash_id = e.seqhash_id\n",
    "        LEFT JOIN cluster_members cm ON s.seqhash_id = cm.seqhash_id\n",
    "        WHERE m.organism IS NOT NULL\n",
    "        GROUP BY m.organism\n",
    "        ORDER BY total_sequences DESC\n",
    "        \"\"\"\n",
    "        return self.con.execute(query).fetchdf()\n",
    "    \n",
    "    def get_sequence_by_id(self, seqhash_id: str) -> dict:\n",
    "        \"\"\"Retrieve complete information for a specific sequence.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            s.*,\n",
    "            a.seed_ortholog,\n",
    "            a.evalue,\n",
    "            a.score,\n",
    "            a.eggnog_ogs,\n",
    "            a.description,\n",
    "            a.preferred_name,\n",
    "            a.cog_category,\n",
    "            STRING_AGG(DISTINCT g.go_term, '; ') as go_terms,\n",
    "            STRING_AGG(DISTINCT e.ec_number, '; ') as ec_numbers,\n",
    "            k.kegg_ko,\n",
    "            k.kegg_pathway,\n",
    "            k.kegg_module,\n",
    "            c.cluster_id,\n",
    "            c.size as cluster_size\n",
    "        FROM sequences s\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        LEFT JOIN go_terms g ON s.seqhash_id = g.seqhash_id\n",
    "        LEFT JOIN ec_numbers e ON s.seqhash_id = e.seqhash_id\n",
    "        LEFT JOIN kegg_info k ON s.seqhash_id = k.seqhash_id\n",
    "        LEFT JOIN cluster_members cm ON s.seqhash_id = cm.seqhash_id\n",
    "        LEFT JOIN clusters c ON cm.cluster_id = c.cluster_id\n",
    "        WHERE s.seqhash_id = ?\n",
    "        GROUP BY s.seqhash_id, s.sequence, s.sample_id, s.assembly_date, \n",
    "                 s.is_representative, s.length, a.seed_ortholog, a.evalue, \n",
    "                 a.score, a.eggnog_ogs, a.description, a.preferred_name,\n",
    "                 a.cog_category, k.kegg_ko, k.kegg_pathway, k.kegg_module,\n",
    "                 c.cluster_id, c.size\n",
    "        \"\"\"\n",
    "        result = self.con.execute(query, [seqhash_id]).fetchdf()\n",
    "        return result.to_dict('records')[0] if not result.empty else None\n",
    "\n",
    "    def search_sequences(self, \n",
    "                        sample_id: Optional[str] = None,\n",
    "                        min_length: Optional[int] = None,\n",
    "                        max_length: Optional[int] = None,\n",
    "                        has_annotation: Optional[bool] = None,\n",
    "                        description_contains: Optional[str] = None,\n",
    "                        go_term: Optional[str] = None,\n",
    "                        ec_number: Optional[str] = None,\n",
    "                        is_representative: Optional[bool] = None,\n",
    "                        min_cluster_size: Optional[int] = None,\n",
    "                        limit: int = 100) -> pd.DataFrame:\n",
    "        \"\"\"Search sequences with multiple criteria.\"\"\"\n",
    "        conditions = [\"1=1\"]\n",
    "        params = []\n",
    "        \n",
    "        if sample_id:\n",
    "            conditions.append(\"s.sample_id = ?\")\n",
    "            params.append(sample_id)\n",
    "            \n",
    "        if min_length:\n",
    "            conditions.append(\"s.length >= ?\")\n",
    "            params.append(min_length)\n",
    "            \n",
    "        if max_length:\n",
    "            conditions.append(\"s.length <= ?\")\n",
    "            params.append(max_length)\n",
    "            \n",
    "        if has_annotation is not None:\n",
    "            if has_annotation:\n",
    "                conditions.append(\"a.seqhash_id IS NOT NULL\")\n",
    "            else:\n",
    "                conditions.append(\"a.seqhash_id IS NULL\")\n",
    "                \n",
    "        if description_contains:\n",
    "            conditions.append(\"LOWER(a.description) LIKE ?\")\n",
    "            params.append(f\"%{description_contains.lower()}%\")\n",
    "            \n",
    "        if go_term:\n",
    "            conditions.append(\"\"\"\n",
    "                EXISTS (\n",
    "                    SELECT 1 FROM go_terms g \n",
    "                    WHERE g.seqhash_id = s.seqhash_id \n",
    "                    AND g.go_term = ?\n",
    "                )\n",
    "            \"\"\")\n",
    "            params.append(go_term)\n",
    "            \n",
    "        if ec_number:\n",
    "            conditions.append(\"\"\"\n",
    "                EXISTS (\n",
    "                    SELECT 1 FROM ec_numbers e \n",
    "                    WHERE e.seqhash_id = s.seqhash_id \n",
    "                    AND e.ec_number = ?\n",
    "                )\n",
    "            \"\"\")\n",
    "            params.append(ec_number)\n",
    "            \n",
    "        if is_representative is not None:\n",
    "            conditions.append(\"s.is_representative = ?\")\n",
    "            params.append(is_representative)\n",
    "            \n",
    "        if min_cluster_size is not None:\n",
    "            conditions.append(\"\"\"\n",
    "                EXISTS (\n",
    "                    SELECT 1 FROM clusters c \n",
    "                    JOIN cluster_members cm ON c.cluster_id = cm.cluster_id\n",
    "                    WHERE cm.seqhash_id = s.seqhash_id \n",
    "                    AND c.size >= ?\n",
    "                )\n",
    "            \"\"\")\n",
    "            params.append(min_cluster_size)\n",
    "            \n",
    "        query = f\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            s.seqhash_id,\n",
    "            s.sample_id,\n",
    "            s.length,\n",
    "            s.is_representative,\n",
    "            a.description,\n",
    "            a.preferred_name,\n",
    "            a.cog_category,\n",
    "            c.cluster_id,\n",
    "            c.size as cluster_size\n",
    "        FROM sequences s\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        LEFT JOIN cluster_members cm ON s.seqhash_id = cm.seqhash_id\n",
    "        LEFT JOIN clusters c ON cm.cluster_id = c.cluster_id\n",
    "        WHERE {' AND '.join(conditions)}\n",
    "        LIMIT ?\n",
    "        \"\"\"\n",
    "        params.append(limit)\n",
    "        \n",
    "        return self.con.execute(query, params).fetchdf()\n",
    "\n",
    "    def get_sample_stats(self, sample_id: Optional[str] = None) -> pd.DataFrame:\n",
    "        \"\"\"Get statistics for all samples or a specific sample.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            s.sample_id,\n",
    "            COUNT(DISTINCT s.seqhash_id) as total_sequences,\n",
    "            AVG(s.length) as avg_length,\n",
    "            MIN(s.length) as min_length,\n",
    "            MAX(s.length) as max_length,\n",
    "            COUNT(DISTINCT a.seqhash_id) as annotated_sequences,\n",
    "            COUNT(DISTINCT g.seqhash_id) as sequences_with_go,\n",
    "            COUNT(DISTINCT e.seqhash_id) as sequences_with_ec,\n",
    "            COUNT(DISTINCT CASE WHEN s.is_representative THEN s.seqhash_id END) as representative_sequences,\n",
    "            COUNT(DISTINCT cm.cluster_id) as clusters\n",
    "        FROM sequences s\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        LEFT JOIN go_terms g ON s.seqhash_id = g.seqhash_id\n",
    "        LEFT JOIN ec_numbers e ON s.seqhash_id = e.seqhash_id\n",
    "        LEFT JOIN cluster_members cm ON s.seqhash_id = cm.seqhash_id\n",
    "        \"\"\"\n",
    "        if sample_id:\n",
    "            query += \" WHERE s.sample_id = ?\"\n",
    "            return self.con.execute(query + \" GROUP BY s.sample_id\", [sample_id]).fetchdf()\n",
    "        return self.con.execute(query + \" GROUP BY s.sample_id\").fetchdf()\n",
    "\n",
    "    def get_cluster_info(self, cluster_id: str) -> pd.DataFrame:\n",
    "        \"\"\"Get detailed information about a specific cluster.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            s.seqhash_id,\n",
    "            s.sample_id,\n",
    "            s.length,\n",
    "            s.is_representative,\n",
    "            a.description,\n",
    "            a.preferred_name,\n",
    "            a.cog_category,\n",
    "            STRING_AGG(DISTINCT g.go_term, '; ') as go_terms,\n",
    "            STRING_AGG(DISTINCT e.ec_number, '; ') as ec_numbers\n",
    "        FROM cluster_members cm\n",
    "        JOIN sequences s ON cm.seqhash_id = s.seqhash_id\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        LEFT JOIN go_terms g ON s.seqhash_id = g.seqhash_id\n",
    "        LEFT JOIN ec_numbers e ON s.seqhash_id = e.seqhash_id\n",
    "        WHERE cm.cluster_id = ?\n",
    "        GROUP BY s.seqhash_id, s.sample_id, s.length, s.is_representative,\n",
    "                 a.description, a.preferred_name, a.cog_category\n",
    "        \"\"\"\n",
    "        return self.con.execute(query, [cluster_id]).fetchdf()\n",
    "\n",
    "    def get_cluster_stats(self) -> pd.DataFrame:\n",
    "        \"\"\"Get summary statistics about clusters.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            COUNT(DISTINCT cluster_id) as total_clusters,\n",
    "            AVG(size) as avg_cluster_size,\n",
    "            MIN(size) as min_cluster_size,\n",
    "            MAX(size) as max_cluster_size,\n",
    "            APPROX_QUANTILE(size, 0.5) as median_cluster_size\n",
    "        FROM clusters\n",
    "        \"\"\"\n",
    "        return self.con.execute(query).fetchdf()\n",
    "\n",
    "    def get_go_term_summary(self, \n",
    "                          sample_id: Optional[str] = None, \n",
    "                          min_sequences: int = 5) -> pd.DataFrame:\n",
    "        \"\"\"Get summary of GO term frequencies.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            g.go_term,\n",
    "            COUNT(DISTINCT s.seqhash_id) as sequence_count\n",
    "        FROM sequences s\n",
    "        JOIN go_terms g ON s.seqhash_id = g.seqhash_id\n",
    "        \"\"\"\n",
    "        if sample_id:\n",
    "            query += \" WHERE s.sample_id = ?\"\n",
    "            params = [sample_id]\n",
    "        else:\n",
    "            params = []\n",
    "            \n",
    "        query += f\"\"\"\n",
    "            GROUP BY g.go_term \n",
    "            HAVING COUNT(DISTINCT s.seqhash_id) >= {min_sequences} \n",
    "            ORDER BY sequence_count DESC\n",
    "        \"\"\"\n",
    "        return self.con.execute(query, params).fetchdf()\n",
    "\n",
    "    def get_ec_number_summary(self, \n",
    "                            sample_id: Optional[str] = None, \n",
    "                            min_sequences: int = 5) -> pd.DataFrame:\n",
    "        \"\"\"Get summary of EC number frequencies.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            e.ec_number,\n",
    "            COUNT(DISTINCT s.seqhash_id) as sequence_count\n",
    "        FROM sequences s\n",
    "        JOIN ec_numbers e ON s.seqhash_id = e.seqhash_id\n",
    "        \"\"\"\n",
    "        if sample_id:\n",
    "            query += \" WHERE s.sample_id = ?\"\n",
    "            params = [sample_id]\n",
    "        else:\n",
    "            params = []\n",
    "            \n",
    "        query += f\"\"\"\n",
    "            GROUP BY e.ec_number \n",
    "            HAVING COUNT(DISTINCT s.seqhash_id) >= {min_sequences} \n",
    "            ORDER BY sequence_count DESC\n",
    "        \"\"\"\n",
    "        return self.con.execute(query, params).fetchdf()\n",
    "\n",
    "    def compare_samples(self, sample_ids: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"Compare statistics between multiple samples.\"\"\"\n",
    "        sample_list = \", \".join([f\"'{s}'\" for s in sample_ids])\n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            s.sample_id,\n",
    "            COUNT(DISTINCT s.seqhash_id) as total_sequences,\n",
    "            COUNT(DISTINCT a.seqhash_id) as annotated_sequences,\n",
    "            COUNT(DISTINCT g.seqhash_id) as sequences_with_go,\n",
    "            COUNT(DISTINCT e.seqhash_id) as sequences_with_ec,\n",
    "            COUNT(DISTINCT cm.cluster_id) as clusters,\n",
    "            AVG(s.length) as avg_length,\n",
    "            COUNT(DISTINCT CASE WHEN s.is_representative THEN s.seqhash_id END) as representative_sequences\n",
    "        FROM sequences s\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        LEFT JOIN go_terms g ON s.seqhash_id = g.seqhash_id\n",
    "        LEFT JOIN ec_numbers e ON s.seqhash_id = e.seqhash_id\n",
    "        LEFT JOIN cluster_members cm ON s.seqhash_id = cm.seqhash_id\n",
    "        WHERE s.sample_id IN ({sample_list})\n",
    "        GROUP BY s.sample_id\n",
    "        \"\"\"\n",
    "        return self.con.execute(query).fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Organism metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRAMetadataCollector:\n",
    "    \"\"\"Handles collection and caching of SRA metadata.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def collect_metadata(self, sample_ids: List[str], cache_path: Optional[str] = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Collect metadata for a list of SRA samples, with optional caching.\n",
    "        \n",
    "        Args:\n",
    "            sample_ids: List of SRA identifiers\n",
    "            cache_path: Optional path to cache results in CSV format\n",
    "        \"\"\"\n",
    "        # Check cache if provided\n",
    "        existing_data = pd.DataFrame()\n",
    "        samples_to_fetch = sample_ids\n",
    "        \n",
    "        if cache_path and Path(cache_path).exists():\n",
    "            existing_data = pd.read_csv(cache_path)\n",
    "            samples_to_fetch = [sid for sid in sample_ids \n",
    "                              if sid not in existing_data['sample_id'].values]\n",
    "            self.logger.info(f\"Found {len(existing_data)} cached entries\")\n",
    "            \n",
    "        # Fetch new samples\n",
    "        new_data = []\n",
    "        for sample_id in samples_to_fetch:\n",
    "            self.logger.info(f\"Fetching metadata for {sample_id}\")\n",
    "            try:\n",
    "                info = get_sra_info(sample_id)\n",
    "                if isinstance(info, dict):  # Successful fetch\n",
    "                    metadata = {\n",
    "                        'sample_id': sample_id,\n",
    "                        'organism': info.get('organism'),\n",
    "                        'study_title': info.get('study_title'),\n",
    "                        'study_abstract': info.get('study_abstract'),\n",
    "                        'bioproject': info.get('bioproject'),\n",
    "                        'biosample': info.get('biosample'),\n",
    "                        'library_strategy': info.get('library', {}).get('strategy'),\n",
    "                        'library_source': info.get('library', {}).get('source'),\n",
    "                        'library_selection': info.get('library', {}).get('selection'),\n",
    "                        'library_layout': info.get('library', {}).get('layout'),\n",
    "                        'instrument': info.get('instrument'),\n",
    "                        'run_spots': info.get('run', {}).get('spots'),\n",
    "                        'run_bases': info.get('run', {}).get('bases'),\n",
    "                        'run_published': info.get('run', {}).get('published')\n",
    "                    }\n",
    "                    new_data.append(metadata)\n",
    "                else:\n",
    "                    self.logger.warning(f\"Failed to fetch {sample_id}: {info}\")\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error processing {sample_id}: {str(e)}\")\n",
    "            \n",
    "            time.sleep(1)  # Respect rate limit\n",
    "            \n",
    "        # Combine new and existing data\n",
    "        new_df = pd.DataFrame(new_data)\n",
    "        combined_df = pd.concat([existing_data, new_df], ignore_index=True)\n",
    "        \n",
    "        # Cache if path provided\n",
    "        if cache_path and not new_df.empty:\n",
    "            combined_df.to_csv(cache_path, index=False)\n",
    "            self.logger.info(f\"Updated cache at {cache_path}\")\n",
    "        \n",
    "        return combined_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from Bio import SeqIO\n",
    "from datetime import datetime\n",
    "from typing import List, Optional, Union, Dict, Set\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class SequenceDBBuilder:\n",
    "    \"\"\"Handles database creation and data loading operations.\"\"\"\n",
    "    \n",
    "    def __init__(self, db_path: str):\n",
    "        self.db_path = db_path\n",
    "        self.con = None\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def __enter__(self):\n",
    "        \"\"\"Context manager entry\"\"\"\n",
    "        self.con = duckdb.connect(self.db_path)\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Context manager exit\"\"\"\n",
    "        if self.con:\n",
    "            self.con.close()\n",
    "            \n",
    "    def clean_database(self):\n",
    "        \"\"\"Drop all existing tables\"\"\"\n",
    "        self.logger.info(\"Cleaning up any existing tables...\")\n",
    "        cleanup_sql = \"\"\"\n",
    "        DROP TABLE IF EXISTS cluster_members;\n",
    "        DROP TABLE IF EXISTS clusters;\n",
    "        DROP TABLE IF EXISTS kegg_info;\n",
    "        DROP TABLE IF EXISTS ec_numbers;\n",
    "        DROP TABLE IF EXISTS go_terms;\n",
    "        DROP TABLE IF EXISTS annotations;\n",
    "        DROP TABLE IF EXISTS sequences;\n",
    "        DROP TABLE IF EXISTS temp_annotations;\n",
    "        DROP TABLE IF EXISTS temp_clusters;\n",
    "        \"\"\"\n",
    "        self.con.execute(cleanup_sql)\n",
    "\n",
    "    def init_database(self):\n",
    "        \"\"\"Initialize database with clean schema including SRA metadata.\"\"\"\n",
    "        self.clean_database()\n",
    "        \n",
    "        schema_sql = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS sequences (\n",
    "            seqhash_id VARCHAR PRIMARY KEY,\n",
    "            sequence VARCHAR NOT NULL,\n",
    "            sample_id VARCHAR NOT NULL,\n",
    "            assembly_date TIMESTAMP NOT NULL,\n",
    "            is_representative BOOLEAN NOT NULL DEFAULT FALSE,\n",
    "            length INTEGER NOT NULL\n",
    "        );\n",
    "\n",
    "        CREATE TABLE IF NOT EXISTS annotations (\n",
    "            seqhash_id VARCHAR PRIMARY KEY,\n",
    "            seed_ortholog VARCHAR,\n",
    "            evalue DOUBLE,\n",
    "            score DOUBLE,\n",
    "            eggnog_ogs VARCHAR,\n",
    "            max_annot_lvl VARCHAR,\n",
    "            cog_category VARCHAR,\n",
    "            description VARCHAR,\n",
    "            preferred_name VARCHAR,\n",
    "            sample_id VARCHAR NOT NULL\n",
    "        );\n",
    "\n",
    "        CREATE TABLE IF NOT EXISTS go_terms (\n",
    "            seqhash_id VARCHAR NOT NULL,\n",
    "            go_term VARCHAR NOT NULL,\n",
    "            PRIMARY KEY (seqhash_id, go_term)\n",
    "        );\n",
    "\n",
    "        CREATE TABLE IF NOT EXISTS ec_numbers (\n",
    "            seqhash_id VARCHAR NOT NULL,\n",
    "            ec_number VARCHAR NOT NULL,\n",
    "            PRIMARY KEY (seqhash_id, ec_number)\n",
    "        );\n",
    "\n",
    "        CREATE TABLE IF NOT EXISTS kegg_info (\n",
    "            seqhash_id VARCHAR PRIMARY KEY,\n",
    "            kegg_ko VARCHAR,\n",
    "            kegg_pathway VARCHAR,\n",
    "            kegg_module VARCHAR,\n",
    "            kegg_reaction VARCHAR,\n",
    "            kegg_rclass VARCHAR\n",
    "        );\n",
    "\n",
    "        CREATE TABLE IF NOT EXISTS clusters (\n",
    "            cluster_id VARCHAR PRIMARY KEY,\n",
    "            representative_seqhash_id VARCHAR NOT NULL,\n",
    "            size INTEGER NOT NULL,\n",
    "            FOREIGN KEY (representative_seqhash_id) REFERENCES sequences(seqhash_id)\n",
    "        );\n",
    "\n",
    "        CREATE TABLE IF NOT EXISTS cluster_members (\n",
    "            seqhash_id VARCHAR NOT NULL,\n",
    "            cluster_id VARCHAR NOT NULL,\n",
    "            PRIMARY KEY (seqhash_id),\n",
    "            FOREIGN KEY (seqhash_id) REFERENCES sequences(seqhash_id),\n",
    "            FOREIGN KEY (cluster_id) REFERENCES clusters(cluster_id)\n",
    "        );\n",
    "\n",
    "        CREATE TABLE IF NOT EXISTS sra_metadata (\n",
    "            sample_id VARCHAR PRIMARY KEY,\n",
    "            organism VARCHAR,\n",
    "            study_title VARCHAR,\n",
    "            study_abstract VARCHAR,\n",
    "            bioproject VARCHAR,\n",
    "            biosample VARCHAR,\n",
    "            library_strategy VARCHAR,\n",
    "            library_source VARCHAR,\n",
    "            library_selection VARCHAR,\n",
    "            library_layout VARCHAR,\n",
    "            instrument VARCHAR,\n",
    "            run_spots VARCHAR,\n",
    "            run_bases VARCHAR,\n",
    "            run_published VARCHAR\n",
    "        );\n",
    "        \"\"\"\n",
    "        \n",
    "        self.con.execute(schema_sql)\n",
    "    \n",
    "    def load_sra_metadata(self, metadata_df: pd.DataFrame):\n",
    "        \"\"\"Load SRA metadata into the database.\"\"\"\n",
    "        self.logger.info(\"Loading SRA metadata into database\")\n",
    "        self.con.execute(\"\"\"\n",
    "            INSERT INTO sra_metadata \n",
    "            SELECT * FROM metadata_df\n",
    "            ON CONFLICT (sample_id) DO UPDATE \n",
    "            SET \n",
    "                organism = EXCLUDED.organism,\n",
    "                study_title = EXCLUDED.study_title,\n",
    "                study_abstract = EXCLUDED.study_abstract,\n",
    "                bioproject = EXCLUDED.bioproject,\n",
    "                biosample = EXCLUDED.biosample,\n",
    "                library_strategy = EXCLUDED.library_strategy,\n",
    "                library_source = EXCLUDED.library_source,\n",
    "                library_selection = EXCLUDED.library_selection,\n",
    "                library_layout = EXCLUDED.library_layout,\n",
    "                instrument = EXCLUDED.instrument,\n",
    "                run_spots = EXCLUDED.run_spots,\n",
    "                run_bases = EXCLUDED.run_bases,\n",
    "                run_published = EXCLUDED.run_published\n",
    "        \"\"\")\n",
    "\n",
    "    def load_sample_data(self, base_dir: Path, sample_id: str) -> List[dict]:\n",
    "        \"\"\"Load data for a single sample, tracking duplicates.\"\"\"\n",
    "        self.logger.info(f\"\\nProcessing sample: {sample_id}\")\n",
    "        \n",
    "        try:\n",
    "            # Keep track of duplicates\n",
    "            duplicates = []\n",
    "            \n",
    "            # Define paths\n",
    "            sequence_path = base_dir / sample_id / f'transdecoder/{sample_id}.pep'\n",
    "            annotation_path = base_dir / sample_id / f'eggnog/{sample_id}.emapper.annotations'\n",
    "            \n",
    "            # Load sequences\n",
    "            self._load_sequences(sequence_path, sample_id, duplicates)\n",
    "            \n",
    "            # Load annotations if file exists\n",
    "            if annotation_path.exists():\n",
    "                self._load_annotations(annotation_path, sample_id)\n",
    "            else:\n",
    "                self.logger.warning(f\"No annotation file found at {annotation_path}\")\n",
    "            \n",
    "            return duplicates\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing sample {sample_id}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _load_sequences(self, sequence_path: Path, sample_id: str, duplicates: list):\n",
    "        \"\"\"Helper method to load sequences from FASTA file.\"\"\"\n",
    "        self.logger.info(f\"Loading sequences from {sequence_path}\")\n",
    "        \n",
    "        existing_seqs = set(self.con.execute(\"SELECT seqhash_id FROM sequences\").df()['seqhash_id'])\n",
    "        sequences = []\n",
    "        skipped_count = 0\n",
    "        \n",
    "        for record in SeqIO.parse(sequence_path, \"fasta\"):\n",
    "            seqhash_id = record.id.split()[0]\n",
    "            \n",
    "            if seqhash_id in existing_seqs:\n",
    "                duplicates.append({\n",
    "                    'seqhash_id': seqhash_id,\n",
    "                    'sample_id': sample_id,\n",
    "                    'length': len(record.seq)\n",
    "                })\n",
    "                skipped_count += 1\n",
    "                continue\n",
    "                \n",
    "            sequences.append({\n",
    "                'seqhash_id': seqhash_id,\n",
    "                'sequence': str(record.seq),\n",
    "                'sample_id': sample_id,\n",
    "                'assembly_date': datetime.now(),\n",
    "                'is_representative': False,\n",
    "                'length': len(record.seq)\n",
    "            })\n",
    "            \n",
    "            if len(sequences) % 1000 == 0:\n",
    "                self._batch_insert_sequences(sequences)\n",
    "                sequences = []\n",
    "        \n",
    "        if sequences:\n",
    "            self._batch_insert_sequences(sequences)\n",
    "        \n",
    "        self.logger.info(f\"Loaded {len(sequences)} new sequences for {sample_id}\")\n",
    "        if skipped_count > 0:\n",
    "            self.logger.info(f\"Skipped {skipped_count} duplicate sequences\")\n",
    "\n",
    "    def _batch_insert_sequences(self, sequences: List[dict]):\n",
    "        \"\"\"Helper method to insert sequences in batches.\"\"\"\n",
    "        if not sequences:\n",
    "            return\n",
    "        df = pd.DataFrame(sequences)\n",
    "        self.con.execute(\"INSERT INTO sequences SELECT * FROM df\")\n",
    "\n",
    "    def _load_annotations(self, annotation_path: Path, sample_id: str):\n",
    "        \"\"\"Helper method to load annotations from eggNOG file.\"\"\"\n",
    "        self.logger.info(f\"Loading annotations from {annotation_path}\")\n",
    "        \n",
    "        column_names = [\n",
    "            'query', 'seed_ortholog', 'evalue', 'score', 'eggNOG_OGs', \n",
    "            'max_annot_lvl', 'COG_category', 'Description', 'Preferred_name',\n",
    "            'GOs', 'EC', 'KEGG_ko', 'KEGG_Pathway', 'KEGG_Module', \n",
    "            'KEGG_Reaction', 'KEGG_rclass', 'BRITE', 'KEGG_TC', 'CAZy',\n",
    "            'BiGG_Reaction', 'PFAMs'\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            # Create temporary table\n",
    "            columns_def = \", \".join([f'\"{name}\" VARCHAR' for name in column_names])\n",
    "            self.con.execute(f\"CREATE TABLE temp_annotations ({columns_def})\")\n",
    "            \n",
    "            # Load annotation data\n",
    "            self.con.execute(f\"\"\"\n",
    "                INSERT INTO temp_annotations\n",
    "                SELECT * FROM read_csv_auto(\n",
    "                    '{annotation_path}',\n",
    "                    sep='\\t',\n",
    "                    header=False,\n",
    "                    names={column_names},\n",
    "                    comment='#'\n",
    "                )\n",
    "            \"\"\")\n",
    "            \n",
    "            # Process annotations\n",
    "            self._process_annotations(sample_id)\n",
    "            \n",
    "        finally:\n",
    "            # Clean up\n",
    "            self.con.execute(\"DROP TABLE IF EXISTS temp_annotations\")\n",
    "\n",
    "    def _process_annotations(self, sample_id: str):\n",
    "        \"\"\"Process annotations from temporary table into final tables.\"\"\"\n",
    "        # Main annotations\n",
    "        self.con.execute(f\"\"\"\n",
    "            INSERT INTO annotations\n",
    "            SELECT \n",
    "                query as seqhash_id,\n",
    "                seed_ortholog,\n",
    "                TRY_CAST(evalue AS DOUBLE) as evalue,\n",
    "                TRY_CAST(score AS DOUBLE) as score,\n",
    "                \"eggNOG_OGs\" as eggnog_ogs,\n",
    "                max_annot_lvl,\n",
    "                \"COG_category\" as cog_category,\n",
    "                \"Description\" as description,\n",
    "                \"Preferred_name\" as preferred_name,\n",
    "                '{sample_id}' as sample_id\n",
    "            FROM temp_annotations\n",
    "            WHERE query IN (SELECT seqhash_id FROM sequences)\n",
    "            AND query NOT IN (SELECT seqhash_id FROM annotations)\n",
    "        \"\"\")\n",
    "        \n",
    "        # GO terms\n",
    "        self.con.execute(\"\"\"\n",
    "            INSERT INTO go_terms\n",
    "            SELECT DISTINCT\n",
    "                query as seqhash_id,\n",
    "                UNNEST(STRING_SPLIT(NULLIF(\"GOs\", '-'), ',')) as go_term\n",
    "            FROM temp_annotations\n",
    "            WHERE query IN (SELECT seqhash_id FROM sequences)\n",
    "            AND query NOT IN (SELECT seqhash_id FROM go_terms)\n",
    "            AND \"GOs\" IS NOT NULL AND \"GOs\" != '-'\n",
    "        \"\"\")\n",
    "        \n",
    "        # EC numbers\n",
    "        self.con.execute(\"\"\"\n",
    "            INSERT INTO ec_numbers\n",
    "            SELECT DISTINCT\n",
    "                query as seqhash_id,\n",
    "                UNNEST(STRING_SPLIT(NULLIF(\"EC\", '-'), ',')) as ec_number\n",
    "            FROM temp_annotations\n",
    "            WHERE query IN (SELECT seqhash_id FROM sequences)\n",
    "            AND query NOT IN (SELECT seqhash_id FROM ec_numbers)\n",
    "            AND \"EC\" IS NOT NULL AND \"EC\" != '-'\n",
    "        \"\"\")\n",
    "\n",
    "    def load_clusters_from_tsv(self, tsv_path: str):\n",
    "        \"\"\"Load cluster information from MMseqs2 cluster update TSV.\"\"\"\n",
    "        self.logger.info(f\"Loading cluster data from {tsv_path}\")\n",
    "        \n",
    "        try:\n",
    "            # Create temporary table for TSV data\n",
    "            self.con.execute(\"\"\"\n",
    "            CREATE TEMP TABLE temp_clusters AS \n",
    "            SELECT \n",
    "                representative as representative_seqhash_id,\n",
    "                member as seqhash_id\n",
    "            FROM read_csv_auto(?, sep='\\t', header=False, \n",
    "                             names=['representative', 'member'])\n",
    "            WHERE representative IN (SELECT seqhash_id FROM sequences)\n",
    "            AND member IN (SELECT seqhash_id FROM sequences)\n",
    "            \"\"\", [tsv_path])\n",
    "            \n",
    "            # Insert clusters\n",
    "            self.con.execute(\"\"\"\n",
    "            WITH cluster_info AS (\n",
    "                SELECT \n",
    "                    representative_seqhash_id,\n",
    "                    ROW_NUMBER() OVER (ORDER BY representative_seqhash_id) as cluster_num,\n",
    "                    COUNT(*) as size\n",
    "                FROM temp_clusters\n",
    "                GROUP BY representative_seqhash_id\n",
    "            )\n",
    "            INSERT INTO clusters (cluster_id, representative_seqhash_id, size)\n",
    "            SELECT \n",
    "                'CLUSTER_' || cluster_num as cluster_id,\n",
    "                representative_seqhash_id,\n",
    "                size\n",
    "            FROM cluster_info\n",
    "            \"\"\")\n",
    "            \n",
    "            # Insert cluster members\n",
    "            self.con.execute(\"\"\"\n",
    "            INSERT INTO cluster_members (seqhash_id, cluster_id)\n",
    "            SELECT \n",
    "                tc.seqhash_id,\n",
    "                c.cluster_id\n",
    "            FROM temp_clusters tc\n",
    "            JOIN clusters c ON tc.representative_seqhash_id = c.representative_seqhash_id\n",
    "            \"\"\")\n",
    "            \n",
    "            # Update representative status\n",
    "            self.con.execute(\"\"\"\n",
    "            UPDATE sequences\n",
    "            SET is_representative = TRUE\n",
    "            WHERE seqhash_id IN (SELECT representative_seqhash_id FROM clusters)\n",
    "            \"\"\")\n",
    "            \n",
    "        finally:\n",
    "            self.con.execute(\"DROP TABLE IF EXISTS temp_clusters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDBQuery:\n",
    "    \"\"\"Handles database queries and analysis.\"\"\"\n",
    "    def __init__(self, db_path: str):\n",
    "        self.db_path = db_path\n",
    "        self.con = duckdb.connect(db_path)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def __enter__(self):\n",
    "        \"\"\"Context manager entry\"\"\"\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Context manager exit\"\"\"\n",
    "        self.con.close()\n",
    "\n",
    "    def get_organism_summary(self) -> pd.DataFrame:\n",
    "        \"\"\"Get summary of sequence counts per organism.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            m.organism,\n",
    "            COUNT(DISTINCT m.sample_id) as sample_count,\n",
    "            COUNT(DISTINCT s.seqhash_id) as total_sequences,\n",
    "            ROUND(AVG(s.length), 2) as avg_sequence_length,\n",
    "            COUNT(DISTINCT CASE WHEN a.seqhash_id IS NOT NULL THEN s.seqhash_id END) as annotated_sequences,\n",
    "            ROUND(COUNT(DISTINCT CASE WHEN a.seqhash_id IS NOT NULL THEN s.seqhash_id END) * 100.0 / \n",
    "                  COUNT(DISTINCT s.seqhash_id), 2) as percent_annotated,\n",
    "            COUNT(DISTINCT CASE WHEN cm.seqhash_id IS NOT NULL THEN s.seqhash_id END) as sequences_in_clusters,\n",
    "            STRING_AGG(DISTINCT m.bioproject, '; ') as bioprojects\n",
    "        FROM sra_metadata m\n",
    "        JOIN sequences s ON s.sample_id = m.sample_id\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        LEFT JOIN cluster_members cm ON s.seqhash_id = cm.seqhash_id\n",
    "        WHERE m.organism IS NOT NULL\n",
    "        GROUP BY m.organism\n",
    "        ORDER BY total_sequences DESC\n",
    "        \"\"\"\n",
    "        return self.con.execute(query).fetchdf()\n",
    "\n",
    "    def get_sample_with_metadata(self, sample_id: str) -> pd.DataFrame:\n",
    "        \"\"\"Get complete sample information including SRA metadata.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            m.*,\n",
    "            COUNT(DISTINCT s.seqhash_id) as total_sequences,\n",
    "            COUNT(DISTINCT CASE WHEN a.seqhash_id IS NOT NULL THEN s.seqhash_id END) as annotated_sequences,\n",
    "            COUNT(DISTINCT CASE WHEN g.seqhash_id IS NOT NULL THEN s.seqhash_id END) as sequences_with_go,\n",
    "            COUNT(DISTINCT CASE WHEN e.seqhash_id IS NOT NULL THEN s.seqhash_id END) as sequences_with_ec,\n",
    "            COUNT(DISTINCT CASE WHEN cm.seqhash_id IS NOT NULL THEN s.seqhash_id END) as sequences_in_clusters\n",
    "        FROM sra_metadata m\n",
    "        JOIN sequences s ON s.sample_id = m.sample_id\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        LEFT JOIN go_terms g ON s.seqhash_id = g.seqhash_id\n",
    "        LEFT JOIN ec_numbers e ON s.seqhash_id = e.seqhash_id\n",
    "        LEFT JOIN cluster_members cm ON s.seqhash_id = cm.seqhash_id\n",
    "        WHERE m.sample_id = ?\n",
    "        GROUP BY m.sample_id, m.organism, m.study_title, m.study_abstract, \n",
    "                 m.bioproject, m.biosample, m.library_strategy, m.library_source,\n",
    "                 m.library_selection, m.library_layout, m.instrument, \n",
    "                 m.run_spots, m.run_bases, m.run_published\n",
    "        \"\"\"\n",
    "        return self.con.execute(query, [sample_id]).fetchdf()\n",
    "\n",
    "    def get_organism_summary(self) -> pd.DataFrame:\n",
    "        \"\"\"Get summary of sequence counts per organism.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            m.organism,\n",
    "            COUNT(DISTINCT m.sample_id) as sample_count,\n",
    "            COUNT(DISTINCT s.seqhash_id) as total_sequences,\n",
    "            COUNT(DISTINCT CASE WHEN a.seqhash_id IS NOT NULL THEN s.seqhash_id END) as annotated_sequences,\n",
    "            COUNT(DISTINCT CASE WHEN g.seqhash_id IS NOT NULL THEN s.seqhash_id END) as sequences_with_go,\n",
    "            COUNT(DISTINCT CASE WHEN e.seqhash_id IS NOT NULL THEN s.seqhash_id END) as sequences_with_ec,\n",
    "            COUNT(DISTINCT CASE WHEN cm.seqhash_id IS NOT NULL THEN s.seqhash_id END) as sequences_in_clusters,\n",
    "            STRING_AGG(DISTINCT m.bioproject, '; ') as bioprojects\n",
    "        FROM sra_metadata m\n",
    "        JOIN sequences s ON s.sample_id = m.sample_id\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        LEFT JOIN go_terms g ON s.seqhash_id = g.seqhash_id\n",
    "        LEFT JOIN ec_numbers e ON s.seqhash_id = e.seqhash_id\n",
    "        LEFT JOIN cluster_members cm ON s.seqhash_id = cm.seqhash_id\n",
    "        WHERE m.organism IS NOT NULL\n",
    "        GROUP BY m.organism\n",
    "        ORDER BY total_sequences DESC\n",
    "        \"\"\"\n",
    "        return self.con.execute(query).fetchdf()\n",
    "    \n",
    "    def get_sequence_by_id(self, seqhash_id: str) -> dict:\n",
    "        \"\"\"Retrieve complete information for a specific sequence.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            s.*,\n",
    "            a.seed_ortholog,\n",
    "            a.evalue,\n",
    "            a.score,\n",
    "            a.eggnog_ogs,\n",
    "            a.description,\n",
    "            a.preferred_name,\n",
    "            a.cog_category,\n",
    "            STRING_AGG(DISTINCT g.go_term, '; ') as go_terms,\n",
    "            STRING_AGG(DISTINCT e.ec_number, '; ') as ec_numbers,\n",
    "            k.kegg_ko,\n",
    "            k.kegg_pathway,\n",
    "            k.kegg_module,\n",
    "            c.cluster_id,\n",
    "            c.size as cluster_size\n",
    "        FROM sequences s\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        LEFT JOIN go_terms g ON s.seqhash_id = g.seqhash_id\n",
    "        LEFT JOIN ec_numbers e ON s.seqhash_id = e.seqhash_id\n",
    "        LEFT JOIN kegg_info k ON s.seqhash_id = k.seqhash_id\n",
    "        LEFT JOIN cluster_members cm ON s.seqhash_id = cm.seqhash_id\n",
    "        LEFT JOIN clusters c ON cm.cluster_id = c.cluster_id\n",
    "        WHERE s.seqhash_id = ?\n",
    "        GROUP BY s.seqhash_id, s.sequence, s.sample_id, s.assembly_date, \n",
    "                 s.is_representative, s.length, a.seed_ortholog, a.evalue, \n",
    "                 a.score, a.eggnog_ogs, a.description, a.preferred_name,\n",
    "                 a.cog_category, k.kegg_ko, k.kegg_pathway, k.kegg_module,\n",
    "                 c.cluster_id, c.size\n",
    "        \"\"\"\n",
    "        result = self.con.execute(query, [seqhash_id]).fetchdf()\n",
    "        return result.to_dict('records')[0] if not result.empty else None\n",
    "\n",
    "    def search_sequences(self, \n",
    "                        sample_id: Optional[str] = None,\n",
    "                        min_length: Optional[int] = None,\n",
    "                        max_length: Optional[int] = None,\n",
    "                        has_annotation: Optional[bool] = None,\n",
    "                        description_contains: Optional[str] = None,\n",
    "                        go_term: Optional[str] = None,\n",
    "                        ec_number: Optional[str] = None,\n",
    "                        is_representative: Optional[bool] = None,\n",
    "                        min_cluster_size: Optional[int] = None,\n",
    "                        limit: int = 100) -> pd.DataFrame:\n",
    "        \"\"\"Search sequences with multiple criteria.\"\"\"\n",
    "        conditions = [\"1=1\"]\n",
    "        params = []\n",
    "        \n",
    "        if sample_id:\n",
    "            conditions.append(\"s.sample_id = ?\")\n",
    "            params.append(sample_id)\n",
    "            \n",
    "        if min_length:\n",
    "            conditions.append(\"s.length >= ?\")\n",
    "            params.append(min_length)\n",
    "            \n",
    "        if max_length:\n",
    "            conditions.append(\"s.length <= ?\")\n",
    "            params.append(max_length)\n",
    "            \n",
    "        if has_annotation is not None:\n",
    "            if has_annotation:\n",
    "                conditions.append(\"a.seqhash_id IS NOT NULL\")\n",
    "            else:\n",
    "                conditions.append(\"a.seqhash_id IS NULL\")\n",
    "                \n",
    "        if description_contains:\n",
    "            conditions.append(\"LOWER(a.description) LIKE ?\")\n",
    "            params.append(f\"%{description_contains.lower()}%\")\n",
    "            \n",
    "        if go_term:\n",
    "            conditions.append(\"\"\"\n",
    "                EXISTS (\n",
    "                    SELECT 1 FROM go_terms g \n",
    "                    WHERE g.seqhash_id = s.seqhash_id \n",
    "                    AND g.go_term = ?\n",
    "                )\n",
    "            \"\"\")\n",
    "            params.append(go_term)\n",
    "            \n",
    "        if ec_number:\n",
    "            conditions.append(\"\"\"\n",
    "                EXISTS (\n",
    "                    SELECT 1 FROM ec_numbers e \n",
    "                    WHERE e.seqhash_id = s.seqhash_id \n",
    "                    AND e.ec_number = ?\n",
    "                )\n",
    "            \"\"\")\n",
    "            params.append(ec_number)\n",
    "            \n",
    "        if is_representative is not None:\n",
    "            conditions.append(\"s.is_representative = ?\")\n",
    "            params.append(is_representative)\n",
    "            \n",
    "        if min_cluster_size is not None:\n",
    "            conditions.append(\"\"\"\n",
    "                EXISTS (\n",
    "                    SELECT 1 FROM clusters c \n",
    "                    JOIN cluster_members cm ON c.cluster_id = cm.cluster_id\n",
    "                    WHERE cm.seqhash_id = s.seqhash_id \n",
    "                    AND c.size >= ?\n",
    "                )\n",
    "            \"\"\")\n",
    "            params.append(min_cluster_size)\n",
    "            \n",
    "        query = f\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            s.seqhash_id,\n",
    "            s.sample_id,\n",
    "            s.length,\n",
    "            s.is_representative,\n",
    "            a.description,\n",
    "            a.preferred_name,\n",
    "            a.cog_category,\n",
    "            c.cluster_id,\n",
    "            c.size as cluster_size\n",
    "        FROM sequences s\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        LEFT JOIN cluster_members cm ON s.seqhash_id = cm.seqhash_id\n",
    "        LEFT JOIN clusters c ON cm.cluster_id = c.cluster_id\n",
    "        WHERE {' AND '.join(conditions)}\n",
    "        LIMIT ?\n",
    "        \"\"\"\n",
    "        params.append(limit)\n",
    "        \n",
    "        return self.con.execute(query, params).fetchdf()\n",
    "\n",
    "    def get_sample_stats(self, sample_id: Optional[str] = None) -> pd.DataFrame:\n",
    "        \"\"\"Get statistics for all samples or a specific sample.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            s.sample_id,\n",
    "            COUNT(DISTINCT s.seqhash_id) as total_sequences,\n",
    "            AVG(s.length) as avg_length,\n",
    "            MIN(s.length) as min_length,\n",
    "            MAX(s.length) as max_length,\n",
    "            COUNT(DISTINCT a.seqhash_id) as annotated_sequences,\n",
    "            COUNT(DISTINCT g.seqhash_id) as sequences_with_go,\n",
    "            COUNT(DISTINCT e.seqhash_id) as sequences_with_ec,\n",
    "            COUNT(DISTINCT CASE WHEN s.is_representative THEN s.seqhash_id END) as representative_sequences,\n",
    "            COUNT(DISTINCT cm.cluster_id) as clusters\n",
    "        FROM sequences s\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        LEFT JOIN go_terms g ON s.seqhash_id = g.seqhash_id\n",
    "        LEFT JOIN ec_numbers e ON s.seqhash_id = e.seqhash_id\n",
    "        LEFT JOIN cluster_members cm ON s.seqhash_id = cm.seqhash_id\n",
    "        \"\"\"\n",
    "        if sample_id:\n",
    "            query += \" WHERE s.sample_id = ?\"\n",
    "            return self.con.execute(query + \" GROUP BY s.sample_id\", [sample_id]).fetchdf()\n",
    "        return self.con.execute(query + \" GROUP BY s.sample_id\").fetchdf()\n",
    "\n",
    "    def get_cluster_info(self, cluster_id: str) -> pd.DataFrame:\n",
    "        \"\"\"Get detailed information about a specific cluster.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            s.seqhash_id,\n",
    "            s.sample_id,\n",
    "            s.length,\n",
    "            s.is_representative,\n",
    "            a.description,\n",
    "            a.preferred_name,\n",
    "            a.cog_category,\n",
    "            STRING_AGG(DISTINCT g.go_term, '; ') as go_terms,\n",
    "            STRING_AGG(DISTINCT e.ec_number, '; ') as ec_numbers\n",
    "        FROM cluster_members cm\n",
    "        JOIN sequences s ON cm.seqhash_id = s.seqhash_id\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        LEFT JOIN go_terms g ON s.seqhash_id = g.seqhash_id\n",
    "        LEFT JOIN ec_numbers e ON s.seqhash_id = e.seqhash_id\n",
    "        WHERE cm.cluster_id = ?\n",
    "        GROUP BY s.seqhash_id, s.sample_id, s.length, s.is_representative,\n",
    "                 a.description, a.preferred_name, a.cog_category\n",
    "        \"\"\"\n",
    "        return self.con.execute(query, [cluster_id]).fetchdf()\n",
    "\n",
    "    def get_cluster_stats(self) -> pd.DataFrame:\n",
    "        \"\"\"Get summary statistics about clusters.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            COUNT(DISTINCT cluster_id) as total_clusters,\n",
    "            AVG(size) as avg_cluster_size,\n",
    "            MIN(size) as min_cluster_size,\n",
    "            MAX(size) as max_cluster_size,\n",
    "            APPROX_QUANTILE(size, 0.5) as median_cluster_size\n",
    "        FROM clusters\n",
    "        \"\"\"\n",
    "        return self.con.execute(query).fetchdf()\n",
    "\n",
    "    def get_go_term_summary(self, \n",
    "                          sample_id: Optional[str] = None, \n",
    "                          min_sequences: int = 5) -> pd.DataFrame:\n",
    "        \"\"\"Get summary of GO term frequencies.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            g.go_term,\n",
    "            COUNT(DISTINCT s.seqhash_id) as sequence_count\n",
    "        FROM sequences s\n",
    "        JOIN go_terms g ON s.seqhash_id = g.seqhash_id\n",
    "        \"\"\"\n",
    "        if sample_id:\n",
    "            query += \" WHERE s.sample_id = ?\"\n",
    "            params = [sample_id]\n",
    "        else:\n",
    "            params = []\n",
    "            \n",
    "        query += f\"\"\"\n",
    "            GROUP BY g.go_term \n",
    "            HAVING COUNT(DISTINCT s.seqhash_id) >= {min_sequences} \n",
    "            ORDER BY sequence_count DESC\n",
    "        \"\"\"\n",
    "        return self.con.execute(query, params).fetchdf()\n",
    "\n",
    "    def get_ec_number_summary(self, \n",
    "                            sample_id: Optional[str] = None, \n",
    "                            min_sequences: int = 5) -> pd.DataFrame:\n",
    "        \"\"\"Get summary of EC number frequencies.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            e.ec_number,\n",
    "            COUNT(DISTINCT s.seqhash_id) as sequence_count\n",
    "        FROM sequences s\n",
    "        JOIN ec_numbers e ON s.seqhash_id = e.seqhash_id\n",
    "        \"\"\"\n",
    "        if sample_id:\n",
    "            query += \" WHERE s.sample_id = ?\"\n",
    "            params = [sample_id]\n",
    "        else:\n",
    "            params = []\n",
    "            \n",
    "        query += f\"\"\"\n",
    "            GROUP BY e.ec_number \n",
    "            HAVING COUNT(DISTINCT s.seqhash_id) >= {min_sequences} \n",
    "            ORDER BY sequence_count DESC\n",
    "        \"\"\"\n",
    "        return self.con.execute(query, params).fetchdf()\n",
    "\n",
    "    def compare_samples(self, sample_ids: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"Compare statistics between multiple samples.\"\"\"\n",
    "        sample_list = \", \".join([f\"'{s}'\" for s in sample_ids])\n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            s.sample_id,\n",
    "            COUNT(DISTINCT s.seqhash_id) as total_sequences,\n",
    "            COUNT(DISTINCT a.seqhash_id) as annotated_sequences,\n",
    "            COUNT(DISTINCT g.seqhash_id) as sequences_with_go,\n",
    "            COUNT(DISTINCT e.seqhash_id) as sequences_with_ec,\n",
    "            COUNT(DISTINCT cm.cluster_id) as clusters,\n",
    "            AVG(s.length) as avg_length,\n",
    "            COUNT(DISTINCT CASE WHEN s.is_representative THEN s.seqhash_id END) as representative_sequences\n",
    "        FROM sequences s\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        LEFT JOIN go_terms g ON s.seqhash_id = g.seqhash_id\n",
    "        LEFT JOIN ec_numbers e ON s.seqhash_id = e.seqhash_id\n",
    "        LEFT JOIN cluster_members cm ON s.seqhash_id = cm.seqhash_id\n",
    "        WHERE s.sample_id IN ({sample_list})\n",
    "        GROUP BY s.sample_id\n",
    "        \"\"\"\n",
    "        return self.con.execute(query).fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Found 77 cached entries\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Define paths and sample list\n",
    "base_dir = Path('/mnt/data2/planter_outputs')\n",
    "db_path = \"/mnt/data2/planter_outputs/planter.duckdb\"\n",
    "sample_list = [\n",
    "    'ERR9123871', 'ERR9123872', 'ERR9123874', 'ERR9123875', 'ERR9123876', \n",
    "    'ERR9123877', 'ERR9123878', 'ERR9123879', 'ERR9123880', 'ERR9123881', \n",
    "    'ERR9123882', 'SRR10444679', 'SRR10444680', 'SRR10444681', 'SRR10444682', \n",
    "    'SRR10444683', 'SRR10444684', 'SRR11011255', 'SRR11011256', 'SRR11011257', \n",
    "    'SRR11011258', 'SRR11011259', 'SRR11011260', 'SRR12068547', 'SRR128113', \n",
    "    'SRR128114', 'SRR13765006', 'SRR14292007', 'SRR14292008', 'SRR18070778', \n",
    "    'SRR18070779', 'SRR18070780', 'SRR18070781', 'SRR18070782', 'SRR18070783', \n",
    "    'SRR18070784', 'SRR18070785', 'SRR18070786', 'SRR18070787', 'SRR18070788', \n",
    "    'SRR18070789', 'SRR18070790', 'SRR18070791', 'SRR18070792', 'SRR18070793', \n",
    "    'SRR18070794', 'SRR18070795', 'SRR18735292', 'SRR19034772', 'SRR19034773', \n",
    "    'SRR19619612', 'SRR19619613', 'SRR19619614', 'SRR22271585', 'SRR22271586', \n",
    "    'SRR22271587', 'SRR22271588', 'SRR22271589', 'SRR22904707', 'SRR24974225', \n",
    "    'SRR24974226', 'SRR24974227', 'SRR24974228', 'SRR25582085', 'SRR29366264', \n",
    "    'SRR29366265', 'SRR29366266', 'SRR5489198', 'SRR5992919', 'SRR5992920', \n",
    "    'SRR6048009', 'SRR8859643', 'SRR8859644', 'SRR8859645', \n",
    "    'SRR8859646', 'SRR8859647', 'SRR8859648'\n",
    "]\n",
    "\n",
    "# First, collect metadata (can be done separately)\n",
    "metadata_collector = SRAMetadataCollector()\n",
    "metadata_df = metadata_collector.collect_metadata(\n",
    "    sample_list,\n",
    "    cache_path=\"sra_metadata_cache.csv\"  # Optional cache\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>organism</th>\n",
       "      <th>study_title</th>\n",
       "      <th>study_abstract</th>\n",
       "      <th>bioproject</th>\n",
       "      <th>biosample</th>\n",
       "      <th>library_strategy</th>\n",
       "      <th>library_source</th>\n",
       "      <th>library_selection</th>\n",
       "      <th>library_layout</th>\n",
       "      <th>instrument</th>\n",
       "      <th>run_spots</th>\n",
       "      <th>run_bases</th>\n",
       "      <th>run_published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ERR9123871</td>\n",
       "      <td>Silene latifolia subsp. alba</td>\n",
       "      <td>Chemical genetics in Silene latifolia elucidat...</td>\n",
       "      <td>Dioecious plants possess diverse sex determina...</td>\n",
       "      <td>PRJEB36078</td>\n",
       "      <td>SAMEA7773503</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>ILLUMINA</td>\n",
       "      <td>75922486</td>\n",
       "      <td>12147597760</td>\n",
       "      <td>2022-05-13 05:01:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sample_id                      organism  \\\n",
       "0  ERR9123871  Silene latifolia subsp. alba   \n",
       "\n",
       "                                         study_title  \\\n",
       "0  Chemical genetics in Silene latifolia elucidat...   \n",
       "\n",
       "                                      study_abstract  bioproject  \\\n",
       "0  Dioecious plants possess diverse sex determina...  PRJEB36078   \n",
       "\n",
       "      biosample library_strategy  library_source library_selection  \\\n",
       "0  SAMEA7773503          RNA-Seq  TRANSCRIPTOMIC              cDNA   \n",
       "\n",
       "  library_layout instrument  run_spots    run_bases        run_published  \n",
       "0         PAIRED   ILLUMINA   75922486  12147597760  2022-05-13 05:01:40  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SequenceDBBuilder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Use the builder class with context manager\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mSequenceDBBuilder\u001b[49m(db_path) \u001b[38;5;28;01mas\u001b[39;00m builder:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Initialize fresh database\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     builder\u001b[38;5;241m.\u001b[39minit_database()\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Load the metadata into the database\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SequenceDBBuilder' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use the builder class with context manager\n",
    "with SequenceDBBuilder(db_path) as builder:\n",
    "    # Initialize fresh database\n",
    "    builder.init_database()\n",
    "    \n",
    "    # Load the metadata into the database\n",
    "    builder.load_sra_metadata(metadata_df)  # Add this line!\n",
    "\n",
    "    # Process each sample\n",
    "    for sample_id in sample_list:\n",
    "        try:\n",
    "            logger.info(f\"Processing sample: {sample_id}\")\n",
    "            duplicates = builder.load_sample_data(base_dir, sample_id)\n",
    "            if duplicates:\n",
    "                logger.info(f\"Found {len(duplicates)} duplicate sequences in {sample_id}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing sample {sample_id}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Get summary after loading\n",
    "    logger.info(\"\\nDatabase Summary:\")\n",
    "    summary_query = \"\"\"\n",
    "    SELECT \n",
    "        COUNT(DISTINCT seqhash_id) as total_sequences,\n",
    "        COUNT(DISTINCT sample_id) as total_samples\n",
    "    FROM sequences\n",
    "    \"\"\"\n",
    "    summary = builder.con.execute(summary_query).fetchone()\n",
    "    logger.info(f\"Total sequences: {summary[0]}\")\n",
    "    logger.info(f\"Total samples: {summary[1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sequence summary by organism:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>organism</th>\n",
       "      <th>sample_count</th>\n",
       "      <th>total_sequences</th>\n",
       "      <th>annotated_sequences</th>\n",
       "      <th>sequences_with_go</th>\n",
       "      <th>sequences_with_ec</th>\n",
       "      <th>sequences_in_clusters</th>\n",
       "      <th>bioprojects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silene latifolia subsp. alba</td>\n",
       "      <td>11</td>\n",
       "      <td>300466</td>\n",
       "      <td>280127</td>\n",
       "      <td>153639</td>\n",
       "      <td>66403</td>\n",
       "      <td>0</td>\n",
       "      <td>PRJEB36078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Xanthoria parietina</td>\n",
       "      <td>6</td>\n",
       "      <td>289959</td>\n",
       "      <td>205284</td>\n",
       "      <td>68980</td>\n",
       "      <td>47053</td>\n",
       "      <td>0</td>\n",
       "      <td>PRJNA584075; PRJNA584074; PRJNA584073; PRJNA58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Matricaria chamomilla var. recutita</td>\n",
       "      <td>6</td>\n",
       "      <td>240845</td>\n",
       "      <td>222539</td>\n",
       "      <td>125021</td>\n",
       "      <td>53751</td>\n",
       "      <td>0</td>\n",
       "      <td>PRJNA382469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Digitalis purpurea</td>\n",
       "      <td>7</td>\n",
       "      <td>234863</td>\n",
       "      <td>220513</td>\n",
       "      <td>127801</td>\n",
       "      <td>54686</td>\n",
       "      <td>0</td>\n",
       "      <td>PRJNA985863; PRJNA80007; PRJNA929980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gyalolechia flavorubescens</td>\n",
       "      <td>18</td>\n",
       "      <td>220334</td>\n",
       "      <td>168318</td>\n",
       "      <td>75492</td>\n",
       "      <td>38886</td>\n",
       "      <td>0</td>\n",
       "      <td>PRJNA210248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cladonia metacorallifera</td>\n",
       "      <td>5</td>\n",
       "      <td>99512</td>\n",
       "      <td>78266</td>\n",
       "      <td>32907</td>\n",
       "      <td>16271</td>\n",
       "      <td>0</td>\n",
       "      <td>PRJNA891905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Acarospora socialis</td>\n",
       "      <td>3</td>\n",
       "      <td>89037</td>\n",
       "      <td>69740</td>\n",
       "      <td>22927</td>\n",
       "      <td>17159</td>\n",
       "      <td>0</td>\n",
       "      <td>PRJNA1013257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Usnea undulata</td>\n",
       "      <td>2</td>\n",
       "      <td>73897</td>\n",
       "      <td>54075</td>\n",
       "      <td>16726</td>\n",
       "      <td>12718</td>\n",
       "      <td>0</td>\n",
       "      <td>PRJNA530379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Usnea sinensis</td>\n",
       "      <td>2</td>\n",
       "      <td>64067</td>\n",
       "      <td>48224</td>\n",
       "      <td>15753</td>\n",
       "      <td>11273</td>\n",
       "      <td>0</td>\n",
       "      <td>PRJNA530379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alliaria petiolata</td>\n",
       "      <td>1</td>\n",
       "      <td>61932</td>\n",
       "      <td>56263</td>\n",
       "      <td>35216</td>\n",
       "      <td>14000</td>\n",
       "      <td>0</td>\n",
       "      <td>PRJNA702530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Umbilicaria muehlenbergii</td>\n",
       "      <td>2</td>\n",
       "      <td>61559</td>\n",
       "      <td>43613</td>\n",
       "      <td>21449</td>\n",
       "      <td>9989</td>\n",
       "      <td>0</td>\n",
       "      <td>PRJNA832023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Usnea baileyi</td>\n",
       "      <td>2</td>\n",
       "      <td>56083</td>\n",
       "      <td>41076</td>\n",
       "      <td>14242</td>\n",
       "      <td>9389</td>\n",
       "      <td>0</td>\n",
       "      <td>PRJNA530379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lobaria pulmonaria</td>\n",
       "      <td>1</td>\n",
       "      <td>42482</td>\n",
       "      <td>28068</td>\n",
       "      <td>11282</td>\n",
       "      <td>5469</td>\n",
       "      <td>0</td>\n",
       "      <td>PRJNA403314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cladonia macilenta</td>\n",
       "      <td>2</td>\n",
       "      <td>39372</td>\n",
       "      <td>31076</td>\n",
       "      <td>13190</td>\n",
       "      <td>6403</td>\n",
       "      <td>0</td>\n",
       "      <td>PRJNA723447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Zophobas atratus</td>\n",
       "      <td>2</td>\n",
       "      <td>38729</td>\n",
       "      <td>33055</td>\n",
       "      <td>24710</td>\n",
       "      <td>9408</td>\n",
       "      <td>0</td>\n",
       "      <td>PRJNA400859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Usnea florida</td>\n",
       "      <td>1</td>\n",
       "      <td>29557</td>\n",
       "      <td>21959</td>\n",
       "      <td>9742</td>\n",
       "      <td>4776</td>\n",
       "      <td>0</td>\n",
       "      <td>PRJNA372893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Rusavskia elegans</td>\n",
       "      <td>1</td>\n",
       "      <td>16314</td>\n",
       "      <td>13028</td>\n",
       "      <td>8012</td>\n",
       "      <td>2992</td>\n",
       "      <td>0</td>\n",
       "      <td>PRJNA916377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Piscinibacter sakaiensis</td>\n",
       "      <td>3</td>\n",
       "      <td>13310</td>\n",
       "      <td>11263</td>\n",
       "      <td>264</td>\n",
       "      <td>3115</td>\n",
       "      <td>0</td>\n",
       "      <td>PRJNA847936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Tenebrio molitor</td>\n",
       "      <td>1</td>\n",
       "      <td>12907</td>\n",
       "      <td>10656</td>\n",
       "      <td>8025</td>\n",
       "      <td>3204</td>\n",
       "      <td>0</td>\n",
       "      <td>PRJNA820846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mesoplasma florum</td>\n",
       "      <td>1</td>\n",
       "      <td>345</td>\n",
       "      <td>205</td>\n",
       "      <td>20</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>PRJNA641121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               organism  sample_count  total_sequences  \\\n",
       "0          Silene latifolia subsp. alba            11           300466   \n",
       "1                   Xanthoria parietina             6           289959   \n",
       "2   Matricaria chamomilla var. recutita             6           240845   \n",
       "3                    Digitalis purpurea             7           234863   \n",
       "4            Gyalolechia flavorubescens            18           220334   \n",
       "5              Cladonia metacorallifera             5            99512   \n",
       "6                   Acarospora socialis             3            89037   \n",
       "7                        Usnea undulata             2            73897   \n",
       "8                        Usnea sinensis             2            64067   \n",
       "9                    Alliaria petiolata             1            61932   \n",
       "10            Umbilicaria muehlenbergii             2            61559   \n",
       "11                        Usnea baileyi             2            56083   \n",
       "12                   Lobaria pulmonaria             1            42482   \n",
       "13                   Cladonia macilenta             2            39372   \n",
       "14                     Zophobas atratus             2            38729   \n",
       "15                        Usnea florida             1            29557   \n",
       "16                    Rusavskia elegans             1            16314   \n",
       "17             Piscinibacter sakaiensis             3            13310   \n",
       "18                     Tenebrio molitor             1            12907   \n",
       "19                    Mesoplasma florum             1              345   \n",
       "\n",
       "    annotated_sequences  sequences_with_go  sequences_with_ec  \\\n",
       "0                280127             153639              66403   \n",
       "1                205284              68980              47053   \n",
       "2                222539             125021              53751   \n",
       "3                220513             127801              54686   \n",
       "4                168318              75492              38886   \n",
       "5                 78266              32907              16271   \n",
       "6                 69740              22927              17159   \n",
       "7                 54075              16726              12718   \n",
       "8                 48224              15753              11273   \n",
       "9                 56263              35216              14000   \n",
       "10                43613              21449               9989   \n",
       "11                41076              14242               9389   \n",
       "12                28068              11282               5469   \n",
       "13                31076              13190               6403   \n",
       "14                33055              24710               9408   \n",
       "15                21959               9742               4776   \n",
       "16                13028               8012               2992   \n",
       "17                11263                264               3115   \n",
       "18                10656               8025               3204   \n",
       "19                  205                 20                 84   \n",
       "\n",
       "    sequences_in_clusters                                        bioprojects  \n",
       "0                       0                                         PRJEB36078  \n",
       "1                       0  PRJNA584075; PRJNA584074; PRJNA584073; PRJNA58...  \n",
       "2                       0                                        PRJNA382469  \n",
       "3                       0               PRJNA985863; PRJNA80007; PRJNA929980  \n",
       "4                       0                                        PRJNA210248  \n",
       "5                       0                                        PRJNA891905  \n",
       "6                       0                                       PRJNA1013257  \n",
       "7                       0                                        PRJNA530379  \n",
       "8                       0                                        PRJNA530379  \n",
       "9                       0                                        PRJNA702530  \n",
       "10                      0                                        PRJNA832023  \n",
       "11                      0                                        PRJNA530379  \n",
       "12                      0                                        PRJNA403314  \n",
       "13                      0                                        PRJNA723447  \n",
       "14                      0                                        PRJNA400859  \n",
       "15                      0                                        PRJNA372893  \n",
       "16                      0                                        PRJNA916377  \n",
       "17                      0                                        PRJNA847936  \n",
       "18                      0                                        PRJNA820846  \n",
       "19                      0                                        PRJNA641121  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample details:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>organism</th>\n",
       "      <th>study_title</th>\n",
       "      <th>study_abstract</th>\n",
       "      <th>bioproject</th>\n",
       "      <th>biosample</th>\n",
       "      <th>library_strategy</th>\n",
       "      <th>library_source</th>\n",
       "      <th>library_selection</th>\n",
       "      <th>library_layout</th>\n",
       "      <th>instrument</th>\n",
       "      <th>run_spots</th>\n",
       "      <th>run_bases</th>\n",
       "      <th>run_published</th>\n",
       "      <th>total_sequences</th>\n",
       "      <th>annotated_sequences</th>\n",
       "      <th>sequences_with_go</th>\n",
       "      <th>sequences_with_ec</th>\n",
       "      <th>sequences_in_clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRR14292007</td>\n",
       "      <td>Cladonia macilenta</td>\n",
       "      <td>Cladonia macilenta that produce biruloquinone</td>\n",
       "      <td>In this study, we identified a polyketide synt...</td>\n",
       "      <td>PRJNA723447</td>\n",
       "      <td>SAMN18818446</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ILLUMINA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>21454</td>\n",
       "      <td>16763</td>\n",
       "      <td>7034</td>\n",
       "      <td>3406</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sample_id            organism  \\\n",
       "0  SRR14292007  Cladonia macilenta   \n",
       "\n",
       "                                     study_title  \\\n",
       "0  Cladonia macilenta that produce biruloquinone   \n",
       "\n",
       "                                      study_abstract   bioproject  \\\n",
       "0  In this study, we identified a polyketide synt...  PRJNA723447   \n",
       "\n",
       "      biosample library_strategy library_source library_selection  \\\n",
       "0  SAMN18818446             None           None              None   \n",
       "\n",
       "  library_layout instrument run_spots run_bases run_published  \\\n",
       "0           None   ILLUMINA      None      None          None   \n",
       "\n",
       "   total_sequences  annotated_sequences  sequences_with_go  sequences_with_ec  \\\n",
       "0            21454                16763               7034               3406   \n",
       "\n",
       "   sequences_in_clusters  \n",
       "0                      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sequence details:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'seqhash_id': 'v1_DLS_61ac870c5c1ec555228430b3b7c633a221dbc5b48f9bb1f64ca0ee5b2451748c.p3',\n",
       " 'sequence': 'MASILQTNSLVVSQATPASPWAHKYRGATVEDLDPPPALSSKPTDSISTALLNAYERDYTHLTVVSEDTRALLGYLNIPRLKELLKNGTVNESDYVEKAMQKFRRRGNVYKVITMDTPLEELEAFFNGGVDGNGPQDFAVVTDGSRRFVLGVATKGDLEEFVKRRPA*',\n",
       " 'sample_id': 'SRR8859648',\n",
       " 'assembly_date': Timestamp('2024-11-20 19:16:23.806861'),\n",
       " 'is_representative': False,\n",
       " 'length': 168,\n",
       " 'seed_ortholog': '61459.XP_007779632.1',\n",
       " 'evalue': 8.99e-82,\n",
       " 'score': 245.0,\n",
       " 'eggnog_ogs': '2E0C8@1|root,2S7T3@2759|Eukaryota,3A2TJ@33154|Opisthokonta,3P34X@4751|Fungi,3QV03@4890|Ascomycota,20GSS@147545|Eurotiomycetes,3MWTA@451870|Chaetothyriomycetidae',\n",
       " 'description': 'Cystathionine beta-synthase',\n",
       " 'preferred_name': '-',\n",
       " 'cog_category': 'S',\n",
       " 'go_terms': None,\n",
       " 'ec_numbers': None,\n",
       " 'kegg_ko': None,\n",
       " 'kegg_pathway': None,\n",
       " 'kegg_module': None,\n",
       " 'cluster_id': None,\n",
       " 'cluster_size': nan}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Query with metadata\n",
    "db_path = '/mnt/data2/planter_outputs/planter2.duckdb'\n",
    "with SequenceDBQuery(db_path) as db:\n",
    "    # Get overall organism summary\n",
    "    organism_summary = db.get_organism_summary()\n",
    "    print(\"\\nSequence summary by organism:\")\n",
    "    display(organism_summary)\n",
    "    \n",
    "    # Get complete sample info\n",
    "    sample_info = db.get_sample_with_metadata(\"SRR14292007\")\n",
    "    print(\"\\nSample details:\")\n",
    "    display(sample_info)\n",
    "\n",
    "\n",
    "    seq_info = db.get_sequence_by_id(\"v1_DLS_61ac870c5c1ec555228430b3b7c633a221dbc5b48f9bb1f64ca0ee5b2451748c.p3\")\n",
    "    print(\"\\nSequence details:\")\n",
    "    display(seq_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def clean_database(con: duckdb.DuckDBPyConnection):\n",
    "    \"\"\"Drop all existing tables\"\"\"\n",
    "    logger.info(\"Cleaning up any existing tables...\")\n",
    "    \n",
    "    cleanup_sql = \"\"\"\n",
    "    DROP TABLE IF EXISTS cluster_members;\n",
    "    DROP TABLE IF EXISTS clusters;\n",
    "    DROP TABLE IF EXISTS kegg_info;\n",
    "    DROP TABLE IF EXISTS ec_numbers;\n",
    "    DROP TABLE IF EXISTS go_terms;\n",
    "    DROP TABLE IF EXISTS annotations;\n",
    "    DROP TABLE IF EXISTS sequences;\n",
    "    DROP TABLE IF EXISTS temp_annotations;\n",
    "    DROP TABLE IF EXISTS temp_clusters;\n",
    "    \"\"\"\n",
    "    con.execute(cleanup_sql)\n",
    "\n",
    "def init_database(db_path: str):\n",
    "    \"\"\"Initialize database with clean schema.\"\"\"\n",
    "    # Create new connection\n",
    "    con = duckdb.connect(db_path)\n",
    "    \n",
    "    # Clean up any existing tables\n",
    "    clean_database(con)\n",
    "    \n",
    "    schema_sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS sequences (\n",
    "        seqhash_id VARCHAR PRIMARY KEY,\n",
    "        sequence VARCHAR NOT NULL,\n",
    "        sample_id VARCHAR NOT NULL,\n",
    "        assembly_date TIMESTAMP NOT NULL,\n",
    "        is_representative BOOLEAN NOT NULL DEFAULT FALSE,\n",
    "        length INTEGER NOT NULL\n",
    "    );\n",
    "\n",
    "    CREATE TABLE IF NOT EXISTS annotations (\n",
    "        seqhash_id VARCHAR PRIMARY KEY,\n",
    "        seed_ortholog VARCHAR,\n",
    "        evalue DOUBLE,\n",
    "        score DOUBLE,\n",
    "        eggnog_ogs VARCHAR,\n",
    "        max_annot_lvl VARCHAR,\n",
    "        cog_category VARCHAR,\n",
    "        description VARCHAR,\n",
    "        preferred_name VARCHAR,\n",
    "        sample_id VARCHAR NOT NULL\n",
    "    );\n",
    "\n",
    "    CREATE TABLE IF NOT EXISTS go_terms (\n",
    "        seqhash_id VARCHAR NOT NULL,\n",
    "        go_term VARCHAR NOT NULL,\n",
    "        PRIMARY KEY (seqhash_id, go_term)\n",
    "    );\n",
    "\n",
    "    CREATE TABLE IF NOT EXISTS ec_numbers (\n",
    "        seqhash_id VARCHAR NOT NULL,\n",
    "        ec_number VARCHAR NOT NULL,\n",
    "        PRIMARY KEY (seqhash_id, ec_number)\n",
    "    );\n",
    "\n",
    "    CREATE TABLE IF NOT EXISTS kegg_info (\n",
    "        seqhash_id VARCHAR PRIMARY KEY,\n",
    "        kegg_ko VARCHAR,\n",
    "        kegg_pathway VARCHAR,\n",
    "        kegg_module VARCHAR,\n",
    "        kegg_reaction VARCHAR,\n",
    "        kegg_rclass VARCHAR\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    con.execute(schema_sql)\n",
    "    return con\n",
    "\n",
    "def load_sample_data(con: duckdb.DuckDBPyConnection, \n",
    "                    base_dir: Path,\n",
    "                    sample_id: str):\n",
    "    \"\"\"Load data for a single sample, tracking duplicates.\"\"\"\n",
    "    logger.info(f\"\\nProcessing sample: {sample_id}\")\n",
    "    \n",
    "    try:\n",
    "        # Keep track of duplicates\n",
    "        duplicates = []\n",
    "        \n",
    "        # Define paths\n",
    "        sequence_path = base_dir / sample_id / f'transdecoder/{sample_id}.pep'\n",
    "        annotation_path = base_dir / sample_id / f'eggnog/{sample_id}.emapper.annotations'\n",
    "        \n",
    "        # Check which sequences are already in the database\n",
    "        sequences = []\n",
    "        existing_seqs = set(con.execute(\"SELECT seqhash_id FROM sequences\").df()['seqhash_id'])\n",
    "        \n",
    "        # Load sequences\n",
    "        logger.info(f\"Loading sequences from {sequence_path}\")\n",
    "        skipped_count = 0\n",
    "        for record in SeqIO.parse(sequence_path, \"fasta\"):\n",
    "            seqhash_id = record.id.split()[0]\n",
    "            \n",
    "            if seqhash_id in existing_seqs:\n",
    "                duplicates.append({\n",
    "                    'seqhash_id': seqhash_id,\n",
    "                    'sample_id': sample_id,\n",
    "                    'length': len(record.seq)\n",
    "                })\n",
    "                skipped_count += 1\n",
    "                continue\n",
    "                \n",
    "            sequences.append({\n",
    "                'seqhash_id': seqhash_id,\n",
    "                'sequence': str(record.seq),\n",
    "                'sample_id': sample_id,\n",
    "                'assembly_date': datetime.now(),\n",
    "                'is_representative': False,\n",
    "                'length': len(record.seq)\n",
    "            })\n",
    "            \n",
    "            if len(sequences) % 1000 == 0:\n",
    "                logger.info(f\"Read {len(sequences)} new sequences...\")\n",
    "        \n",
    "        # Load new sequences\n",
    "        if sequences:\n",
    "            df = pd.DataFrame(sequences)\n",
    "            con.execute(\"INSERT INTO sequences SELECT * FROM df\")\n",
    "        \n",
    "        logger.info(f\"Loaded {len(sequences)} new sequences for {sample_id}\")\n",
    "        if skipped_count > 0:\n",
    "            logger.info(f\"Skipped {skipped_count} duplicate sequences\")\n",
    "            logger.info(\"First few duplicates:\")\n",
    "            for dup in duplicates[:5]:\n",
    "                existing_sample = con.execute(\"\"\"\n",
    "                    SELECT sample_id FROM sequences \n",
    "                    WHERE seqhash_id = ?\n",
    "                \"\"\", [dup['seqhash_id']]).fetchone()[0]\n",
    "                logger.info(f\"  Sequence {dup['seqhash_id']} already exists in sample {existing_sample}\")\n",
    "        \n",
    "        # Clean up before loading annotations\n",
    "        con.execute(\"DROP TABLE IF EXISTS temp_annotations\")\n",
    "        \n",
    "        # Load annotations\n",
    "        logger.info(f\"Loading annotations from {annotation_path}\")\n",
    "        \n",
    "        column_names = [\n",
    "            'query', 'seed_ortholog', 'evalue', 'score', 'eggNOG_OGs', \n",
    "            'max_annot_lvl', 'COG_category', 'Description', 'Preferred_name',\n",
    "            'GOs', 'EC', 'KEGG_ko', 'KEGG_Pathway', 'KEGG_Module', \n",
    "            'KEGG_Reaction', 'KEGG_rclass', 'BRITE', 'KEGG_TC', 'CAZy',\n",
    "            'BiGG_Reaction', 'PFAMs'\n",
    "        ]\n",
    "        \n",
    "        columns_def = \", \".join([f'\"{name}\" VARCHAR' for name in column_names])\n",
    "        con.execute(f\"CREATE TABLE temp_annotations ({columns_def})\")\n",
    "        \n",
    "        # Load annotation data\n",
    "        con.execute(f\"\"\"\n",
    "            INSERT INTO temp_annotations\n",
    "            SELECT * FROM read_csv_auto(\n",
    "                '{annotation_path}',\n",
    "                sep='\\t',\n",
    "                header=False,\n",
    "                names={column_names},\n",
    "                comment='#'\n",
    "            )\n",
    "        \"\"\")\n",
    "        \n",
    "        # Process main annotations (only for non-duplicate sequences)\n",
    "        con.execute(f\"\"\"\n",
    "            INSERT INTO annotations\n",
    "            SELECT \n",
    "                query as seqhash_id,\n",
    "                seed_ortholog,\n",
    "                TRY_CAST(evalue AS DOUBLE) as evalue,\n",
    "                TRY_CAST(score AS DOUBLE) as score,\n",
    "                \"eggNOG_OGs\" as eggnog_ogs,\n",
    "                max_annot_lvl,\n",
    "                \"COG_category\" as cog_category,\n",
    "                \"Description\" as description,\n",
    "                \"Preferred_name\" as preferred_name,\n",
    "                '{sample_id}' as sample_id\n",
    "            FROM temp_annotations\n",
    "            WHERE query NOT IN (SELECT seqhash_id FROM annotations)\n",
    "        \"\"\")\n",
    "        \n",
    "        # Process GO terms\n",
    "        con.execute(f\"\"\"\n",
    "            INSERT INTO go_terms\n",
    "            SELECT DISTINCT\n",
    "                query as seqhash_id,\n",
    "                UNNEST(STRING_SPLIT(NULLIF(\"GOs\", '-'), ',')) as go_term\n",
    "            FROM temp_annotations\n",
    "            WHERE query NOT IN (SELECT seqhash_id FROM go_terms)\n",
    "            AND \"GOs\" IS NOT NULL AND \"GOs\" != '-'\n",
    "        \"\"\")\n",
    "        \n",
    "        # Process EC numbers\n",
    "        con.execute(f\"\"\"\n",
    "            INSERT INTO ec_numbers\n",
    "            SELECT DISTINCT\n",
    "                query as seqhash_id,\n",
    "                UNNEST(STRING_SPLIT(NULLIF(\"EC\", '-'), ',')) as ec_number\n",
    "            FROM temp_annotations\n",
    "            WHERE query NOT IN (SELECT seqhash_id FROM ec_numbers)\n",
    "            AND \"EC\" IS NOT NULL AND \"EC\" != '-'\n",
    "        \"\"\")\n",
    "        \n",
    "        return duplicates\n",
    "        \n",
    "    finally:\n",
    "        # Clean up temporary tables\n",
    "        logger.info(\"Cleaning up temporary tables...\")\n",
    "        con.execute(\"DROP TABLE IF EXISTS temp_annotations\")\n",
    "        con.execute(\"DROP TABLE IF EXISTS temp_go\")\n",
    "        con.execute(\"DROP TABLE IF EXISTS temp_ec\")\n",
    "\n",
    "def get_database_summary(con):\n",
    "    \"\"\"Get summary statistics with unambiguous column references.\"\"\"\n",
    "    return con.execute(\"\"\"\n",
    "        SELECT \n",
    "            s.sample_id,  -- Specifically use sequences table's sample_id\n",
    "            COUNT(DISTINCT s.seqhash_id) as sequence_count,\n",
    "            COUNT(DISTINCT a.seqhash_id) as annotated_count,\n",
    "            COUNT(DISTINCT g.seqhash_id) as with_go_terms,\n",
    "            COUNT(DISTINCT e.seqhash_id) as with_ec_numbers\n",
    "        FROM sequences s\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        LEFT JOIN go_terms g ON s.seqhash_id = g.seqhash_id\n",
    "        LEFT JOIN ec_numbers e ON s.seqhash_id = e.seqhash_id\n",
    "        GROUP BY s.sample_id\n",
    "        ORDER BY s.sample_id\n",
    "    \"\"\").df()\n",
    "\n",
    "def build_initial_database(db_path: str, base_dir: Path, sample_list: list):\n",
    "    \"\"\"Build initial database from a list of samples.\"\"\"\n",
    "    logger.info(f\"Building database at {db_path} from {len(sample_list)} samples\")\n",
    "    \n",
    "    # Remove existing database if it exists\n",
    "    if Path(db_path).exists():\n",
    "        logger.info(f\"Removing existing database: {db_path}\")\n",
    "        Path(db_path).unlink()\n",
    "    \n",
    "    # Initialize database\n",
    "    con = init_database(db_path)\n",
    "    \n",
    "    # Track duplicates across all samples\n",
    "    all_duplicates = {}\n",
    "    \n",
    "    # Process each sample\n",
    "    for sample_id in sample_list:\n",
    "        try:\n",
    "            duplicates = load_sample_data(con, base_dir, sample_id)\n",
    "            if duplicates:\n",
    "                all_duplicates[sample_id] = duplicates\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing sample {sample_id}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Log summary statistics\n",
    "    logger.info(\"\\nDatabase Summary:\")\n",
    "    sample_stats = get_database_summary(con)\n",
    "    print(sample_stats)\n",
    "    \n",
    "    if all_duplicates:\n",
    "        logger.info(\"\\nDuplicate Summary:\")\n",
    "        for sample_id, dups in all_duplicates.items():\n",
    "            logger.info(f\"{sample_id}: {len(dups)} duplicate sequences\")\n",
    "            \n",
    "        # Optional: show some duplicate details\n",
    "        logger.info(\"\\nExample duplicates (first few):\")\n",
    "        for sample_id, dups in all_duplicates.items():\n",
    "            logger.info(f\"\\nDuplicates in {sample_id}:\")\n",
    "            for dup in dups[:5]:  # Show first 5 duplicates for each sample\n",
    "                existing_sample = con.execute(\"\"\"\n",
    "                    SELECT sample_id \n",
    "                    FROM sequences \n",
    "                    WHERE seqhash_id = ?\n",
    "                \"\"\", [dup['seqhash_id']]).fetchone()[0]\n",
    "                logger.info(f\"  {dup['seqhash_id']} (length: {dup['length']}) - first found in {existing_sample}\")\n",
    "    \n",
    "    return con"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Building database at /mnt/data2/planter_outputs/planter.duckdb from 77 samples\n",
      "INFO:__main__:Cleaning up any existing tables...\n",
      "INFO:__main__:\n",
      "Processing sample: ERR9123871\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/ERR9123871/transdecoder/ERR9123871.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Loaded 30281 new sequences for ERR9123871\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/ERR9123871/eggnog/ERR9123871.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: ERR9123872\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/ERR9123872/transdecoder/ERR9123872.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Loaded 26342 new sequences for ERR9123872\n",
      "INFO:__main__:Skipped 9 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_108900dfd519627a4e0ffbd0c80e4268eb3384d860e3fb796fdda887ad18f03c.p1 already exists in sample ERR9123871\n",
      "INFO:__main__:  Sequence v1_DLS_172183323642e5314aefffc2722cb3e563948b7adce112fbeb555d68aeed64e8.p1 already exists in sample ERR9123871\n",
      "INFO:__main__:  Sequence v1_DLS_1c0b7a8d06a514f717258ad1d05d43d4984f479ef87288421da49af8932e9530.p1 already exists in sample ERR9123871\n",
      "INFO:__main__:  Sequence v1_DLS_63a93ecaf0cfecf790bb146bc94f97d48e00e4336609ec5158b319e294b487b0.p1 already exists in sample ERR9123871\n",
      "INFO:__main__:  Sequence v1_DLS_6a1bdfc8cd6570dc637d19389f901d032de28c23593292de8465cd6bbbd857ff.p1 already exists in sample ERR9123871\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/ERR9123872/eggnog/ERR9123872.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: ERR9123874\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/ERR9123874/transdecoder/ERR9123874.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Loaded 26649 new sequences for ERR9123874\n",
      "INFO:__main__:Skipped 5 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_3ea505807f1f886432d4e6d6acb72bfdb129844afdae83d27f37a7b3e78bfc63.p1 already exists in sample ERR9123872\n",
      "INFO:__main__:  Sequence v1_DLS_46f2df41aa51e653e99cfec46ea1c6e41ee64f4b5f85b8efccfcb52d2d70154c.p1 already exists in sample ERR9123871\n",
      "INFO:__main__:  Sequence v1_DLS_67cc90422831ad1477a4ac8cf9c8dcbbea161e43082ce0ce6ac3931f80efb283.p1 already exists in sample ERR9123872\n",
      "INFO:__main__:  Sequence v1_DLS_a32fca4f942423956667f7bf91a4319bbbf6452e63149d3094dd78b3e41a8f8c.p1 already exists in sample ERR9123872\n",
      "INFO:__main__:  Sequence v1_DLS_bfccc88f7f7df54788694c497b9059a3087c5b1d37a78d117ad0f97a8fec657f.p1 already exists in sample ERR9123871\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/ERR9123874/eggnog/ERR9123874.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: ERR9123875\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/ERR9123875/transdecoder/ERR9123875.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Loaded 26224 new sequences for ERR9123875\n",
      "INFO:__main__:Skipped 23 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_13a40711c372a136aaad1cac4e8ea0a95e524f2078f41f8c7fb766bd4de3a33f.p1 already exists in sample ERR9123874\n",
      "INFO:__main__:  Sequence v1_DLS_1b27594303486bbbd35b7ab5e4a5d9eb9efd01e16f95507ffbf7b6f7a37dd916.p1 already exists in sample ERR9123871\n",
      "INFO:__main__:  Sequence v1_DLS_1dd91f3c17330afc49cab5c786f0d8727fc9dfd8741d52a40927c250681662a4.p1 already exists in sample ERR9123874\n",
      "INFO:__main__:  Sequence v1_DLS_2046c5ed7951937e2661313c3b3faadaa729e3221ace65c9350bb14f70a9209c.p1 already exists in sample ERR9123872\n",
      "INFO:__main__:  Sequence v1_DLS_496b904de055f4c22a5f3999e8af45e2dd3f51e57d736656240022c3af925c1c.p1 already exists in sample ERR9123871\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/ERR9123875/eggnog/ERR9123875.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: ERR9123876\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/ERR9123876/transdecoder/ERR9123876.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Loaded 26284 new sequences for ERR9123876\n",
      "INFO:__main__:Skipped 29 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_06d4c674879a46aa91010b8ed4e1602b5e15fe970419c04e47b85a6628389e9a.p1 already exists in sample ERR9123874\n",
      "INFO:__main__:  Sequence v1_DLS_12daf990426ff698ffb06d1ea3d57b0786c946d33522f55b3f7dfd7d8ba1aaa6.p1 already exists in sample ERR9123875\n",
      "INFO:__main__:  Sequence v1_DLS_130f6ca6dda9609019b339b669ebc38631b90669b3030e0ce0371f79d9c9227b.p1 already exists in sample ERR9123872\n",
      "INFO:__main__:  Sequence v1_DLS_13d7134879ea4c315e06d95198804257e590364ff1a2419e8edab907ede7b608.p1 already exists in sample ERR9123871\n",
      "INFO:__main__:  Sequence v1_DLS_1b1711ada850c27229e14f995e5f8825e83c41f799c0c4975c50d0ffa219ea5f.p1 already exists in sample ERR9123871\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/ERR9123876/eggnog/ERR9123876.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: ERR9123877\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/ERR9123877/transdecoder/ERR9123877.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Loaded 27560 new sequences for ERR9123877\n",
      "INFO:__main__:Skipped 29 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_0dce92366abb0d7b752b000ed45de8cf2d94fd2ab4e438d5a91b66e27f84d258.p1 already exists in sample ERR9123872\n",
      "INFO:__main__:  Sequence v1_DLS_1e1ce7004b26f996ce288519625ae5159034ff28562bd9b47bbf9e1f389a9eaa.p1 already exists in sample ERR9123871\n",
      "INFO:__main__:  Sequence v1_DLS_2ed223600606d6cb1119968055e42027c70e3d07a05d06f6cc5a0a2f910a072f.p1 already exists in sample ERR9123875\n",
      "INFO:__main__:  Sequence v1_DLS_3f1431992dfd2142e6748ee3f88cdedfa9a630085a253d569d58fd5a313ffd93.p1 already exists in sample ERR9123876\n",
      "INFO:__main__:  Sequence v1_DLS_498352a795de1497399bc1cf05283262179c1fff7b9f95469b956e8dcec86771.p1 already exists in sample ERR9123871\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/ERR9123877/eggnog/ERR9123877.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: ERR9123878\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/ERR9123878/transdecoder/ERR9123878.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Loaded 23320 new sequences for ERR9123878\n",
      "INFO:__main__:Skipped 5 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_075d5508c71eb810f01a66db1c0c425d51e680569d05ad79b8c87c1c890463b9.p1 already exists in sample ERR9123874\n",
      "INFO:__main__:  Sequence v1_DLS_07c35796e38c3733997a40a575a7f0f600ab319fc46b71d6f014fa6105ad47cf.p1 already exists in sample ERR9123877\n",
      "INFO:__main__:  Sequence v1_DLS_32a02f2bf3ba64c12781690a70a3176b979e84d43ef29888039f94310a48b3d1.p1 already exists in sample ERR9123872\n",
      "INFO:__main__:  Sequence v1_DLS_8e87c28497abafc27562f114cc7e6e05f63f6dfc3f88b2187afd963a0090fb43.p1 already exists in sample ERR9123875\n",
      "INFO:__main__:  Sequence v1_DLS_a43816c0d3ca401fe04eac2ffdc15b2bf4f09672ff918f8ebb884e13806f779f.p1 already exists in sample ERR9123877\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/ERR9123878/eggnog/ERR9123878.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: ERR9123879\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/ERR9123879/transdecoder/ERR9123879.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Loaded 28766 new sequences for ERR9123879\n",
      "INFO:__main__:Skipped 44 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_0eea4bae30f96d8d94970302bab7f1b74d48a67d009d8c9cf7e1389ac28396c3.p1 already exists in sample ERR9123872\n",
      "INFO:__main__:  Sequence v1_DLS_10727a4e9130c7a3919ee56c1600af883c4a775f20224900576e0acb09dc50e2.p1 already exists in sample ERR9123877\n",
      "INFO:__main__:  Sequence v1_DLS_1126e0eb3fee2854837f41359464db4df2994d71796735bac5411c4cc5493d87.p1 already exists in sample ERR9123877\n",
      "INFO:__main__:  Sequence v1_DLS_13bcdaef37dcc5e0854fb0352ef457232a74e2dfe8989f27cb41f5b02e000c6a.p1 already exists in sample ERR9123871\n",
      "INFO:__main__:  Sequence v1_DLS_144dd02f9e860d5ed2f23408a33071c635cdb45b411f81d4c630ff7d2d68e43b.p1 already exists in sample ERR9123877\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/ERR9123879/eggnog/ERR9123879.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: ERR9123880\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/ERR9123880/transdecoder/ERR9123880.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Loaded 29432 new sequences for ERR9123880\n",
      "INFO:__main__:Skipped 43 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_046308c053c991c8f5fe2a93b0c0bdba30cd8d12e659dc574779eacb635d42c8.p1 already exists in sample ERR9123876\n",
      "INFO:__main__:  Sequence v1_DLS_1126e0eb3fee2854837f41359464db4df2994d71796735bac5411c4cc5493d87.p1 already exists in sample ERR9123877\n",
      "INFO:__main__:  Sequence v1_DLS_1f4a80fee4f453c49a707fc98aa1ffea927bfdfb4a09524043d9ee029b1b6b6f.p1 already exists in sample ERR9123879\n",
      "INFO:__main__:  Sequence v1_DLS_23e79146529bf78d80196e8a04c3c9a04d40f17c0a4b5d8f90565a4b0782d9ae.p1 already exists in sample ERR9123871\n",
      "INFO:__main__:  Sequence v1_DLS_289a772d82c00dbd463528f458971fcd9b6bebfa82135b1316331a9f0f2fa5f5.p1 already exists in sample ERR9123879\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/ERR9123880/eggnog/ERR9123880.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: ERR9123881\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/ERR9123881/transdecoder/ERR9123881.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Loaded 28476 new sequences for ERR9123881\n",
      "INFO:__main__:Skipped 47 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_03d3745fa517c78247d909adcebec60725149775eeb404d9cc4919847497da07.p1 already exists in sample ERR9123880\n",
      "INFO:__main__:  Sequence v1_DLS_17078b32cd735c1d05a136fa02e69900a1ba8aabdf8d6c58d663bd8a660c1962.p1 already exists in sample ERR9123880\n",
      "INFO:__main__:  Sequence v1_DLS_17bba1ad05c14e389cf7b6d5e2a521b01063790d737a1ce3e0066768a728f0d9.p1 already exists in sample ERR9123880\n",
      "INFO:__main__:  Sequence v1_DLS_297fc47af79a59229b7930a530abbe0661af38c36eca0b959147409469278915.p1 already exists in sample ERR9123877\n",
      "INFO:__main__:  Sequence v1_DLS_2eb03ed2d71d8c2f66d245239b09cc13e709cc1c03f6c03f29faa1eaef87847e.p1 already exists in sample ERR9123880\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/ERR9123881/eggnog/ERR9123881.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: ERR9123882\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/ERR9123882/transdecoder/ERR9123882.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Loaded 27132 new sequences for ERR9123882\n",
      "INFO:__main__:Skipped 69 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_0165b35cf93e800314f22fe111ebc101a6f43e77f37d461bc52477fda0474041.p1 already exists in sample ERR9123874\n",
      "INFO:__main__:  Sequence v1_DLS_0bcd3ec6bf41a2c3e99322f8e2930b477b847227927805e1e867b450e8192334.p1 already exists in sample ERR9123880\n",
      "INFO:__main__:  Sequence v1_DLS_10e9af6a0098657c97039076e587a502f14b9acc1d34801e97a979c65c155859.p1 already exists in sample ERR9123874\n",
      "INFO:__main__:  Sequence v1_DLS_11d18241eb9ba9d18ba9c962804f8254ec00c7acc3467d7ea4973a76b86b9eaa.p1 already exists in sample ERR9123880\n",
      "INFO:__main__:  Sequence v1_DLS_16c578a9c9d24d3a327a87732a973b27a726d15eb02bc810a1bd78d58867258f.p1 already exists in sample ERR9123880\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/ERR9123882/eggnog/ERR9123882.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR10444679\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR10444679/transdecoder/SRR10444679.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Read 31000 new sequences...\n",
      "INFO:__main__:Read 32000 new sequences...\n",
      "INFO:__main__:Read 33000 new sequences...\n",
      "INFO:__main__:Read 34000 new sequences...\n",
      "INFO:__main__:Read 35000 new sequences...\n",
      "INFO:__main__:Read 36000 new sequences...\n",
      "INFO:__main__:Read 37000 new sequences...\n",
      "INFO:__main__:Read 38000 new sequences...\n",
      "INFO:__main__:Read 39000 new sequences...\n",
      "INFO:__main__:Read 40000 new sequences...\n",
      "INFO:__main__:Read 41000 new sequences...\n",
      "INFO:__main__:Read 42000 new sequences...\n",
      "INFO:__main__:Read 43000 new sequences...\n",
      "INFO:__main__:Read 44000 new sequences...\n",
      "INFO:__main__:Read 45000 new sequences...\n",
      "INFO:__main__:Read 46000 new sequences...\n",
      "INFO:__main__:Read 47000 new sequences...\n",
      "INFO:__main__:Read 48000 new sequences...\n",
      "INFO:__main__:Read 49000 new sequences...\n",
      "INFO:__main__:Read 50000 new sequences...\n",
      "INFO:__main__:Read 51000 new sequences...\n",
      "INFO:__main__:Read 52000 new sequences...\n",
      "INFO:__main__:Read 53000 new sequences...\n",
      "INFO:__main__:Read 54000 new sequences...\n",
      "INFO:__main__:Read 55000 new sequences...\n",
      "INFO:__main__:Read 56000 new sequences...\n",
      "INFO:__main__:Read 57000 new sequences...\n",
      "INFO:__main__:Read 58000 new sequences...\n",
      "INFO:__main__:Read 59000 new sequences...\n",
      "INFO:__main__:Read 60000 new sequences...\n",
      "INFO:__main__:Read 61000 new sequences...\n",
      "INFO:__main__:Read 62000 new sequences...\n",
      "INFO:__main__:Read 63000 new sequences...\n",
      "INFO:__main__:Read 64000 new sequences...\n",
      "INFO:__main__:Read 65000 new sequences...\n",
      "INFO:__main__:Read 66000 new sequences...\n",
      "INFO:__main__:Read 67000 new sequences...\n",
      "INFO:__main__:Read 68000 new sequences...\n",
      "INFO:__main__:Read 69000 new sequences...\n",
      "INFO:__main__:Read 70000 new sequences...\n",
      "INFO:__main__:Read 71000 new sequences...\n",
      "INFO:__main__:Read 72000 new sequences...\n",
      "INFO:__main__:Read 73000 new sequences...\n",
      "INFO:__main__:Loaded 73972 new sequences for SRR10444679\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR10444679/eggnog/SRR10444679.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR10444680\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR10444680/transdecoder/SRR10444680.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Read 31000 new sequences...\n",
      "INFO:__main__:Read 32000 new sequences...\n",
      "INFO:__main__:Read 33000 new sequences...\n",
      "INFO:__main__:Read 34000 new sequences...\n",
      "INFO:__main__:Read 35000 new sequences...\n",
      "INFO:__main__:Read 36000 new sequences...\n",
      "INFO:__main__:Read 37000 new sequences...\n",
      "INFO:__main__:Read 38000 new sequences...\n",
      "INFO:__main__:Read 39000 new sequences...\n",
      "INFO:__main__:Read 40000 new sequences...\n",
      "INFO:__main__:Read 41000 new sequences...\n",
      "INFO:__main__:Read 42000 new sequences...\n",
      "INFO:__main__:Read 43000 new sequences...\n",
      "INFO:__main__:Read 44000 new sequences...\n",
      "INFO:__main__:Read 45000 new sequences...\n",
      "INFO:__main__:Read 46000 new sequences...\n",
      "INFO:__main__:Read 47000 new sequences...\n",
      "INFO:__main__:Read 48000 new sequences...\n",
      "INFO:__main__:Read 49000 new sequences...\n",
      "INFO:__main__:Read 50000 new sequences...\n",
      "INFO:__main__:Read 51000 new sequences...\n",
      "INFO:__main__:Read 52000 new sequences...\n",
      "INFO:__main__:Read 53000 new sequences...\n",
      "INFO:__main__:Read 54000 new sequences...\n",
      "INFO:__main__:Read 55000 new sequences...\n",
      "INFO:__main__:Read 56000 new sequences...\n",
      "INFO:__main__:Read 57000 new sequences...\n",
      "INFO:__main__:Read 58000 new sequences...\n",
      "INFO:__main__:Read 59000 new sequences...\n",
      "INFO:__main__:Read 60000 new sequences...\n",
      "INFO:__main__:Read 61000 new sequences...\n",
      "INFO:__main__:Read 62000 new sequences...\n",
      "INFO:__main__:Read 63000 new sequences...\n",
      "INFO:__main__:Read 64000 new sequences...\n",
      "INFO:__main__:Read 65000 new sequences...\n",
      "INFO:__main__:Read 66000 new sequences...\n",
      "INFO:__main__:Read 67000 new sequences...\n",
      "INFO:__main__:Read 68000 new sequences...\n",
      "INFO:__main__:Read 69000 new sequences...\n",
      "INFO:__main__:Read 70000 new sequences...\n",
      "INFO:__main__:Read 71000 new sequences...\n",
      "INFO:__main__:Read 72000 new sequences...\n",
      "INFO:__main__:Loaded 72136 new sequences for SRR10444680\n",
      "INFO:__main__:Skipped 7 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_0da9a915d1495c7e6a9d27cb789ccc6752726fafb8f666762ea0098797912ce3.p2 already exists in sample SRR10444679\n",
      "INFO:__main__:  Sequence v1_DLS_0da9a915d1495c7e6a9d27cb789ccc6752726fafb8f666762ea0098797912ce3.p1 already exists in sample SRR10444679\n",
      "INFO:__main__:  Sequence v1_DLS_0f2c7e4c9a495f738fdc82670daebb63fffaf01b5faacff53b1d40c1b64b6f02.p1 already exists in sample SRR10444679\n",
      "INFO:__main__:  Sequence v1_DLS_106d4ba3acb22bdb0f8980c0366c0df46af5550d8ae4104a3977502f7274fdcb.p1 already exists in sample SRR10444679\n",
      "INFO:__main__:  Sequence v1_DLS_b9bb7ea23873c111a47b3dad8c1880fd899bf3e3f1fb7d889493eb2d3703c6fd.p1 already exists in sample SRR10444679\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR10444680/eggnog/SRR10444680.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR10444681\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR10444681/transdecoder/SRR10444681.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Read 31000 new sequences...\n",
      "INFO:__main__:Read 32000 new sequences...\n",
      "INFO:__main__:Read 33000 new sequences...\n",
      "INFO:__main__:Read 34000 new sequences...\n",
      "INFO:__main__:Read 35000 new sequences...\n",
      "INFO:__main__:Read 36000 new sequences...\n",
      "INFO:__main__:Read 37000 new sequences...\n",
      "INFO:__main__:Read 38000 new sequences...\n",
      "INFO:__main__:Read 39000 new sequences...\n",
      "INFO:__main__:Read 40000 new sequences...\n",
      "INFO:__main__:Read 41000 new sequences...\n",
      "INFO:__main__:Read 42000 new sequences...\n",
      "INFO:__main__:Read 43000 new sequences...\n",
      "INFO:__main__:Read 44000 new sequences...\n",
      "INFO:__main__:Read 45000 new sequences...\n",
      "INFO:__main__:Read 46000 new sequences...\n",
      "INFO:__main__:Read 47000 new sequences...\n",
      "INFO:__main__:Read 48000 new sequences...\n",
      "INFO:__main__:Read 49000 new sequences...\n",
      "INFO:__main__:Read 50000 new sequences...\n",
      "INFO:__main__:Read 51000 new sequences...\n",
      "INFO:__main__:Read 52000 new sequences...\n",
      "INFO:__main__:Read 53000 new sequences...\n",
      "INFO:__main__:Read 54000 new sequences...\n",
      "INFO:__main__:Read 55000 new sequences...\n",
      "INFO:__main__:Read 56000 new sequences...\n",
      "INFO:__main__:Read 57000 new sequences...\n",
      "INFO:__main__:Read 58000 new sequences...\n",
      "INFO:__main__:Read 59000 new sequences...\n",
      "INFO:__main__:Read 60000 new sequences...\n",
      "INFO:__main__:Read 61000 new sequences...\n",
      "INFO:__main__:Read 62000 new sequences...\n",
      "INFO:__main__:Read 63000 new sequences...\n",
      "INFO:__main__:Read 64000 new sequences...\n",
      "INFO:__main__:Read 65000 new sequences...\n",
      "INFO:__main__:Read 66000 new sequences...\n",
      "INFO:__main__:Read 67000 new sequences...\n",
      "INFO:__main__:Read 68000 new sequences...\n",
      "INFO:__main__:Read 69000 new sequences...\n",
      "INFO:__main__:Read 70000 new sequences...\n",
      "INFO:__main__:Loaded 70543 new sequences for SRR10444681\n",
      "INFO:__main__:Skipped 30 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_05510854c8ced16fa50496b871344b91bb46048e081b0520e386379fa1494386.p1 already exists in sample SRR10444680\n",
      "INFO:__main__:  Sequence v1_DLS_0a31cd1bca3e9eeb2630c446f38a663b6341675bffc99bad11044f636e2ead27.p1 already exists in sample SRR10444680\n",
      "INFO:__main__:  Sequence v1_DLS_130ed7aeac55f7c2fe8ecad9c37dbb0993201b177f2130346f2e8b66209eded7.p1 already exists in sample SRR10444680\n",
      "INFO:__main__:  Sequence v1_DLS_14c2815de1c6a7e5274be353897acccf277a655855e33d722adad4b3c71a588f.p1 already exists in sample SRR10444680\n",
      "INFO:__main__:  Sequence v1_DLS_18d16777628a82ffe0a1922a034f161820e6100a0dea9253714ca9716f603eab.p1 already exists in sample SRR10444680\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR10444681/eggnog/SRR10444681.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR10444682\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR10444682/transdecoder/SRR10444682.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Loaded 24544 new sequences for SRR10444682\n",
      "INFO:__main__:Skipped 12 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_30ab2d97f4daa90793350e577030f12fb1adf2ab4147c36679765970edcfbf16.p3 already exists in sample SRR10444679\n",
      "INFO:__main__:  Sequence v1_DLS_6039dd6bf28b9eb4d97c7a230a0842c0b7a5af6c0bbf0dd8f25282d7c66dede7.p1 already exists in sample SRR10444680\n",
      "INFO:__main__:  Sequence v1_DLS_6039dd6bf28b9eb4d97c7a230a0842c0b7a5af6c0bbf0dd8f25282d7c66dede7.p2 already exists in sample SRR10444680\n",
      "INFO:__main__:  Sequence v1_DLS_6f7e503f0761df55de36800ed117d0dabc62f72ec5bb375a12a6dcb5ba9cf967.p1 already exists in sample SRR10444681\n",
      "INFO:__main__:  Sequence v1_DLS_7b209d26efcf188c97f7159321f1fea980e961a93bd0966df507f7e22b92d621.p1 already exists in sample SRR10444679\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR10444682/eggnog/SRR10444682.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR10444683\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR10444683/transdecoder/SRR10444683.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Loaded 23882 new sequences for SRR10444683\n",
      "INFO:__main__:Skipped 112 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_01b454b614476422e62d521b6b2d7344ca2389736a9bb003315b59145f9e20e1.p1 already exists in sample SRR10444682\n",
      "INFO:__main__:  Sequence v1_DLS_01b454b614476422e62d521b6b2d7344ca2389736a9bb003315b59145f9e20e1.p2 already exists in sample SRR10444682\n",
      "INFO:__main__:  Sequence v1_DLS_0377ebf3d0965fc11ae07efb7718b3021fd4fac25fa660c54ac39b3866bc592e.p1 already exists in sample SRR10444682\n",
      "INFO:__main__:  Sequence v1_DLS_052d968e5eb86d061a4a64581c5228ff6f3fcb3ec3d1eb058904616bd9d57472.p1 already exists in sample SRR10444682\n",
      "INFO:__main__:  Sequence v1_DLS_052d968e5eb86d061a4a64581c5228ff6f3fcb3ec3d1eb058904616bd9d57472.p2 already exists in sample SRR10444682\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR10444683/eggnog/SRR10444683.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR10444684\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR10444684/transdecoder/SRR10444684.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Loaded 24882 new sequences for SRR10444684\n",
      "INFO:__main__:Skipped 214 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_026c2e624183fe00a6f6e1589a62d2fe7227982d9bf55b0f904d301ebaff9b7c.p1 already exists in sample SRR10444683\n",
      "INFO:__main__:  Sequence v1_DLS_031b2280541b318daa2df1304d1a2485d7874293d5f2fc145465b0b414aabe34.p4 already exists in sample SRR10444682\n",
      "INFO:__main__:  Sequence v1_DLS_031b2280541b318daa2df1304d1a2485d7874293d5f2fc145465b0b414aabe34.p7 already exists in sample SRR10444682\n",
      "INFO:__main__:  Sequence v1_DLS_031b2280541b318daa2df1304d1a2485d7874293d5f2fc145465b0b414aabe34.p1 already exists in sample SRR10444682\n",
      "INFO:__main__:  Sequence v1_DLS_031b2280541b318daa2df1304d1a2485d7874293d5f2fc145465b0b414aabe34.p3 already exists in sample SRR10444682\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR10444684/eggnog/SRR10444684.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR11011255\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR11011255/transdecoder/SRR11011255.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Read 31000 new sequences...\n",
      "INFO:__main__:Read 32000 new sequences...\n",
      "INFO:__main__:Read 33000 new sequences...\n",
      "INFO:__main__:Read 34000 new sequences...\n",
      "INFO:__main__:Read 35000 new sequences...\n",
      "INFO:__main__:Read 36000 new sequences...\n",
      "INFO:__main__:Read 37000 new sequences...\n",
      "INFO:__main__:Read 38000 new sequences...\n",
      "INFO:__main__:Loaded 38986 new sequences for SRR11011255\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR11011255/eggnog/SRR11011255.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR11011256\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR11011256/transdecoder/SRR11011256.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Read 31000 new sequences...\n",
      "INFO:__main__:Read 32000 new sequences...\n",
      "INFO:__main__:Read 33000 new sequences...\n",
      "INFO:__main__:Read 34000 new sequences...\n",
      "INFO:__main__:Read 35000 new sequences...\n",
      "INFO:__main__:Read 36000 new sequences...\n",
      "INFO:__main__:Read 37000 new sequences...\n",
      "INFO:__main__:Read 38000 new sequences...\n",
      "INFO:__main__:Read 39000 new sequences...\n",
      "INFO:__main__:Read 40000 new sequences...\n",
      "INFO:__main__:Loaded 40190 new sequences for SRR11011256\n",
      "INFO:__main__:Skipped 12 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_1904f122baf96b824fd4f52643ba71854c904662d31d3896ca66c2732ce9bbb8.p1 already exists in sample SRR11011255\n",
      "INFO:__main__:  Sequence v1_DLS_20ff6523d54d6659478bdd6a527bdfc173b1d233238239a0dc07fe06c03ac3f8.p1 already exists in sample SRR11011255\n",
      "INFO:__main__:  Sequence v1_DLS_21ff3a7291d17645dc3072685875e83fb77f760ae7218bf9db021cd51c0dfa59.p1 already exists in sample SRR11011255\n",
      "INFO:__main__:  Sequence v1_DLS_2aa8716e2af29e377f76608a4c0a03c6b392f90723fa0d4dbce57ccc0f555eec.p1 already exists in sample SRR11011255\n",
      "INFO:__main__:  Sequence v1_DLS_3c0eee0779afcba59745edc722b9e5aa2201ea41a7dab61478073c3aeadf6f70.p1 already exists in sample SRR11011255\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR11011256/eggnog/SRR11011256.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR11011257\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR11011257/transdecoder/SRR11011257.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Read 31000 new sequences...\n",
      "INFO:__main__:Read 32000 new sequences...\n",
      "INFO:__main__:Read 33000 new sequences...\n",
      "INFO:__main__:Read 34000 new sequences...\n",
      "INFO:__main__:Read 35000 new sequences...\n",
      "INFO:__main__:Read 36000 new sequences...\n",
      "INFO:__main__:Read 37000 new sequences...\n",
      "INFO:__main__:Read 38000 new sequences...\n",
      "INFO:__main__:Read 39000 new sequences...\n",
      "INFO:__main__:Loaded 39229 new sequences for SRR11011257\n",
      "INFO:__main__:Skipped 8 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_039cb1f8461d59ad465717c587795ca262174fae8615049a20b0233d9347f696.p2 already exists in sample SRR11011255\n",
      "INFO:__main__:  Sequence v1_DLS_1cce5b0b8ab7d2758aa6fb8d6c83cb658757ba3cf75ef2ca31651c6e0576cf5b.p1 already exists in sample SRR11011255\n",
      "INFO:__main__:  Sequence v1_DLS_73954990b0760053227956bb54a71961edbb4dfa028890e0f813ad999a6da723.p1 already exists in sample SRR11011256\n",
      "INFO:__main__:  Sequence v1_DLS_76c898b9313e804df23e747c949e703b8e193400aa378c191068b5a0b50390d5.p1 already exists in sample SRR11011256\n",
      "INFO:__main__:  Sequence v1_DLS_c1cfa31aca7e591ecdef16ba231b204e464598bee35021d610de9e88bd3fab70.p1 already exists in sample SRR11011255\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR11011257/eggnog/SRR11011257.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR11011258\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR11011258/transdecoder/SRR11011258.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Read 31000 new sequences...\n",
      "INFO:__main__:Read 32000 new sequences...\n",
      "INFO:__main__:Read 33000 new sequences...\n",
      "INFO:__main__:Read 34000 new sequences...\n",
      "INFO:__main__:Read 35000 new sequences...\n",
      "INFO:__main__:Read 36000 new sequences...\n",
      "INFO:__main__:Read 37000 new sequences...\n",
      "INFO:__main__:Read 38000 new sequences...\n",
      "INFO:__main__:Read 39000 new sequences...\n",
      "INFO:__main__:Read 40000 new sequences...\n",
      "INFO:__main__:Loaded 40243 new sequences for SRR11011258\n",
      "INFO:__main__:Skipped 8 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_17dc143b274f3c9273a6fc084e6608be4e885eb9a48d99b8338904c0c5b5807c.p1 already exists in sample SRR11011256\n",
      "INFO:__main__:  Sequence v1_DLS_2573e91ed386ba3728b233bd5fa63b9a05c375538fb93ffb8b570355322ac853.p1 already exists in sample SRR11011257\n",
      "INFO:__main__:  Sequence v1_DLS_33e7636a6188791f1c4d6825ab2661479f823d728277bc6b683308ef2fc25642.p1 already exists in sample SRR11011256\n",
      "INFO:__main__:  Sequence v1_DLS_4324f4a650e1a09681964e1310217c2c6aecbe22c94e929425881ef35bdbb8ba.p1 already exists in sample SRR11011257\n",
      "INFO:__main__:  Sequence v1_DLS_569615ac8a1bede5cc987d9fcd61030c6769d46c9bc43b3168cd0f7fcc2f9b87.p1 already exists in sample SRR11011257\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR11011258/eggnog/SRR11011258.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR11011259\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR11011259/transdecoder/SRR11011259.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Read 31000 new sequences...\n",
      "INFO:__main__:Read 32000 new sequences...\n",
      "INFO:__main__:Read 33000 new sequences...\n",
      "INFO:__main__:Read 34000 new sequences...\n",
      "INFO:__main__:Read 35000 new sequences...\n",
      "INFO:__main__:Read 36000 new sequences...\n",
      "INFO:__main__:Read 37000 new sequences...\n",
      "INFO:__main__:Read 38000 new sequences...\n",
      "INFO:__main__:Read 39000 new sequences...\n",
      "INFO:__main__:Read 40000 new sequences...\n",
      "INFO:__main__:Loaded 40270 new sequences for SRR11011259\n",
      "INFO:__main__:Skipped 20 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_02d104040979bad1a3471126faf8409807b1b6b67c897fb8b1b29dfe4a8f9c2b.p1 already exists in sample SRR11011256\n",
      "INFO:__main__:  Sequence v1_DLS_35061a8bff33378b28873a85b5b5896766cdb035b706d4ca8aecb5e434645cac.p1 already exists in sample SRR11011258\n",
      "INFO:__main__:  Sequence v1_DLS_3550bf5f98cffa55aee948cd8a1bb5e2402231b66d6cbd1b08e694d62e9cbf8d.p1 already exists in sample SRR11011258\n",
      "INFO:__main__:  Sequence v1_DLS_3b2a6af7436b7ff1d607d2eb3199cf23d1615833bfa3796bad8933f8a8a50438.p1 already exists in sample SRR11011255\n",
      "INFO:__main__:  Sequence v1_DLS_57703ffaf627bd3075b013db1cc13d42dc03135a9f9525cc0f5f19e181c6935e.p1 already exists in sample SRR11011255\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR11011259/eggnog/SRR11011259.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR11011260\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR11011260/transdecoder/SRR11011260.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Read 31000 new sequences...\n",
      "INFO:__main__:Read 32000 new sequences...\n",
      "INFO:__main__:Read 33000 new sequences...\n",
      "INFO:__main__:Read 34000 new sequences...\n",
      "INFO:__main__:Read 35000 new sequences...\n",
      "INFO:__main__:Read 36000 new sequences...\n",
      "INFO:__main__:Read 37000 new sequences...\n",
      "INFO:__main__:Read 38000 new sequences...\n",
      "INFO:__main__:Read 39000 new sequences...\n",
      "INFO:__main__:Read 40000 new sequences...\n",
      "INFO:__main__:Read 41000 new sequences...\n",
      "INFO:__main__:Loaded 41927 new sequences for SRR11011260\n",
      "INFO:__main__:Skipped 18 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_06427a04a08b42ac8631e162b914323c406d5394b34b12776b7e8b86951fdf62.p1 already exists in sample SRR11011257\n",
      "INFO:__main__:  Sequence v1_DLS_1447dc46bd6234fe20fa953f9b4f890b48517c971ca0c3170026f31392c0ee83.p1 already exists in sample SRR11011259\n",
      "INFO:__main__:  Sequence v1_DLS_1c525e123a9ecfecc3a49c0431901158de9ac475e9c804a4df3d31fb552fab95.p1 already exists in sample SRR11011258\n",
      "INFO:__main__:  Sequence v1_DLS_2258f7e741d4b0f13a9a3a81b31dc3ba221495bcaa064e72bb4d305acab756bd.p1 already exists in sample SRR11011259\n",
      "INFO:__main__:  Sequence v1_DLS_5864773bec92d0948bd85302833afd7108894db11039bbfa807776f3031d6efa.p1 already exists in sample SRR11011258\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR11011260/eggnog/SRR11011260.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR12068547\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR12068547/transdecoder/SRR12068547.pep\n",
      "INFO:__main__:Loaded 345 new sequences for SRR12068547\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR12068547/eggnog/SRR12068547.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR128113\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR128113/transdecoder/SRR128113.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Loaded 21324 new sequences for SRR128113\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR128113/eggnog/SRR128113.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR128114\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR128114/transdecoder/SRR128114.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Loaded 21608 new sequences for SRR128114\n",
      "INFO:__main__:Skipped 5 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_210f74741b33d52584e13e771bfde08260aa382b437a4aa44e1a5072284d658b.p1 already exists in sample SRR128113\n",
      "INFO:__main__:  Sequence v1_DLS_2223594a0d7ae1ffc0821831931cfd197ff35ee8adf301a3be4e7433a5a04843.p1 already exists in sample SRR128113\n",
      "INFO:__main__:  Sequence v1_DLS_607994b7eeeecacf5a000334bc052694db281470d3d4562c2d186c321ec0d20a.p1 already exists in sample SRR128113\n",
      "INFO:__main__:  Sequence v1_DLS_a52c69c4aabb3b81661b20b1aa9b338f04f89e371444cf2e743752b3eaa2c0fc.p1 already exists in sample SRR128113\n",
      "INFO:__main__:  Sequence v1_DLS_a8f6ec4858d10d1940d853474dd44408a712a91aa1e3056a4314e02e2a223f34.p1 already exists in sample SRR128113\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR128114/eggnog/SRR128114.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR13765006\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR13765006/transdecoder/SRR13765006.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Read 31000 new sequences...\n",
      "INFO:__main__:Read 32000 new sequences...\n",
      "INFO:__main__:Read 33000 new sequences...\n",
      "INFO:__main__:Read 34000 new sequences...\n",
      "INFO:__main__:Read 35000 new sequences...\n",
      "INFO:__main__:Read 36000 new sequences...\n",
      "INFO:__main__:Read 37000 new sequences...\n",
      "INFO:__main__:Read 38000 new sequences...\n",
      "INFO:__main__:Read 39000 new sequences...\n",
      "INFO:__main__:Read 40000 new sequences...\n",
      "INFO:__main__:Read 41000 new sequences...\n",
      "INFO:__main__:Read 42000 new sequences...\n",
      "INFO:__main__:Read 43000 new sequences...\n",
      "INFO:__main__:Read 44000 new sequences...\n",
      "INFO:__main__:Read 45000 new sequences...\n",
      "INFO:__main__:Read 46000 new sequences...\n",
      "INFO:__main__:Read 47000 new sequences...\n",
      "INFO:__main__:Read 48000 new sequences...\n",
      "INFO:__main__:Read 49000 new sequences...\n",
      "INFO:__main__:Read 50000 new sequences...\n",
      "INFO:__main__:Read 51000 new sequences...\n",
      "INFO:__main__:Read 52000 new sequences...\n",
      "INFO:__main__:Read 53000 new sequences...\n",
      "INFO:__main__:Read 54000 new sequences...\n",
      "INFO:__main__:Read 55000 new sequences...\n",
      "INFO:__main__:Read 56000 new sequences...\n",
      "INFO:__main__:Read 57000 new sequences...\n",
      "INFO:__main__:Read 58000 new sequences...\n",
      "INFO:__main__:Read 59000 new sequences...\n",
      "INFO:__main__:Read 60000 new sequences...\n",
      "INFO:__main__:Read 61000 new sequences...\n",
      "INFO:__main__:Loaded 61932 new sequences for SRR13765006\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR13765006/eggnog/SRR13765006.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR14292007\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR14292007/transdecoder/SRR14292007.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Loaded 21454 new sequences for SRR14292007\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR14292007/eggnog/SRR14292007.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR14292008\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR14292008/transdecoder/SRR14292008.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Loaded 17918 new sequences for SRR14292008\n",
      "INFO:__main__:Skipped 29 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_0ef89a6a1fff73b4089edb96019eb3bf04da7bea9b451c503dd9904020525efe.p1 already exists in sample SRR14292007\n",
      "INFO:__main__:  Sequence v1_DLS_0ef89a6a1fff73b4089edb96019eb3bf04da7bea9b451c503dd9904020525efe.p3 already exists in sample SRR14292007\n",
      "INFO:__main__:  Sequence v1_DLS_11a6da79bd562868bb161794c3ad8f7f314b1a4655dca8a09c922675b0aaf2e6.p1 already exists in sample SRR14292007\n",
      "INFO:__main__:  Sequence v1_DLS_1a13b091b645af96424f874066bc908d9c071fd1ebab67cbce1114570f3a3030.p1 already exists in sample SRR14292007\n",
      "INFO:__main__:  Sequence v1_DLS_218960b6b48c3ad168776672ba8461a4175b78904ca792845d3c895a4b038e2d.p1 already exists in sample SRR14292007\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR14292008/eggnog/SRR14292008.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR18070778\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR18070778/transdecoder/SRR18070778.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Loaded 7504 new sequences for SRR18070778\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR18070778/eggnog/SRR18070778.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR18070779\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR18070779/transdecoder/SRR18070779.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Loaded 8706 new sequences for SRR18070779\n",
      "INFO:__main__:Skipped 10 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_31b64fb55994eda51b0633aeb25135f9d22215c95d9684bfff1219a6104e92f2.p1 already exists in sample SRR18070778\n",
      "INFO:__main__:  Sequence v1_DLS_4fd245352b8ebc7c2b04694234f8e901d781635b75f38102c3b2c4105c08de03.p1 already exists in sample SRR18070778\n",
      "INFO:__main__:  Sequence v1_DLS_64e9f42c4febd885163dc7bbab08a1edd3e50e584108b7432576c46b85217aa1.p1 already exists in sample SRR18070778\n",
      "INFO:__main__:  Sequence v1_DLS_6aa4a7d8fc80c6e08a749c4fa209624eecceb673e6c9494a16844b0807aa6e8c.p1 already exists in sample SRR18070778\n",
      "INFO:__main__:  Sequence v1_DLS_7732ae1a5061744dffe45b372bbf814d1deb4e0746d97b25691cb925c2345135.p1 already exists in sample SRR18070778\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR18070779/eggnog/SRR18070779.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR18070780\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR18070780/transdecoder/SRR18070780.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Loaded 6822 new sequences for SRR18070780\n",
      "INFO:__main__:Skipped 6 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_109a9ceff157eafb7f94c6b7ab6d9535fd5874de7dc45241bf091704ad057a29.p1 already exists in sample SRR18070779\n",
      "INFO:__main__:  Sequence v1_DLS_32b33d98065dc8428f6a1b0959bc2fa70f222a5c7f1bbb3a4d3b614cc4ba09d6.p1 already exists in sample SRR18070778\n",
      "INFO:__main__:  Sequence v1_DLS_4bf07f9aae2afce1c8f9f0ca1ef3179a424701fd01c014646bb96735d92f977d.p1 already exists in sample SRR18070779\n",
      "INFO:__main__:  Sequence v1_DLS_8303a22db85be951ef1420b3211bb02e8f816e54b882f73ef4cf197238285ffe.p1 already exists in sample SRR18070779\n",
      "INFO:__main__:  Sequence v1_DLS_9d1da8f85da2df12f3c97986c05ad69df90276362a2b3df5914acb21b44306b2.p1 already exists in sample SRR18070779\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR18070780/eggnog/SRR18070780.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR18070781\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR18070781/transdecoder/SRR18070781.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Loaded 9212 new sequences for SRR18070781\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR18070781/eggnog/SRR18070781.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR18070782\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR18070782/transdecoder/SRR18070782.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Loaded 21532 new sequences for SRR18070782\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR18070782/eggnog/SRR18070782.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR18070783\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR18070783/transdecoder/SRR18070783.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Loaded 10654 new sequences for SRR18070783\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR18070783/eggnog/SRR18070783.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR18070784\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR18070784/transdecoder/SRR18070784.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Loaded 21725 new sequences for SRR18070784\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR18070784/eggnog/SRR18070784.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR18070785\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR18070785/transdecoder/SRR18070785.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Loaded 23806 new sequences for SRR18070785\n",
      "INFO:__main__:Skipped 86 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_002688d1ea60f4bd1ddb2d6701f13f594f67eeb5f0c570c184b8287cb1cb13b3.p2 already exists in sample SRR18070784\n",
      "INFO:__main__:  Sequence v1_DLS_002688d1ea60f4bd1ddb2d6701f13f594f67eeb5f0c570c184b8287cb1cb13b3.p9 already exists in sample SRR18070784\n",
      "INFO:__main__:  Sequence v1_DLS_002688d1ea60f4bd1ddb2d6701f13f594f67eeb5f0c570c184b8287cb1cb13b3.p1 already exists in sample SRR18070784\n",
      "INFO:__main__:  Sequence v1_DLS_113ba8c06ec712748d3c00df6451b11ae8083d228f0e91adb47d53d01f4da1d1.p1 already exists in sample SRR18070784\n",
      "INFO:__main__:  Sequence v1_DLS_113ba8c06ec712748d3c00df6451b11ae8083d228f0e91adb47d53d01f4da1d1.p2 already exists in sample SRR18070784\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR18070785/eggnog/SRR18070785.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR18070786\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR18070786/transdecoder/SRR18070786.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Loaded 21690 new sequences for SRR18070786\n",
      "INFO:__main__:Skipped 177 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_017fbf3a4add63cff9f242a7626b03e3a2a29f9e4bb363596deb91da1246be3f.p1 already exists in sample SRR18070784\n",
      "INFO:__main__:  Sequence v1_DLS_03637dc84b61ec13bf4a1c9a3d39125d3f9c9744b0c29bc0f75a0caa12d45ee3.p2 already exists in sample SRR18070784\n",
      "INFO:__main__:  Sequence v1_DLS_03637dc84b61ec13bf4a1c9a3d39125d3f9c9744b0c29bc0f75a0caa12d45ee3.p1 already exists in sample SRR18070784\n",
      "INFO:__main__:  Sequence v1_DLS_07ce54c52bffdbadf634074024ece05a64d0ee518a0f7ff8feeb8304bf93a8d4.p1 already exists in sample SRR18070785\n",
      "INFO:__main__:  Sequence v1_DLS_098f5e996cd7abb219cb117a471281f5df6f5d4deeedc9214c9a3336aa81e026.p1 already exists in sample SRR18070785\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR18070786/eggnog/SRR18070786.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR18070787\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR18070787/transdecoder/SRR18070787.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Loaded 21241 new sequences for SRR18070787\n",
      "INFO:__main__:Skipped 195 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_0155e0f16c007171568c2aeb0af6ac474b64ef734e0e584efcaeac734ddc4c16.p1 already exists in sample SRR18070786\n",
      "INFO:__main__:  Sequence v1_DLS_04bdc62f832d01ad913b16f8263d4e54f646e2952c5bb3801116f237198d8967.p2 already exists in sample SRR18070786\n",
      "INFO:__main__:  Sequence v1_DLS_07b59e542970ca073c37af963245420c40ccbbd75eeac88f6854e288b3cfde5e.p2 already exists in sample SRR18070785\n",
      "INFO:__main__:  Sequence v1_DLS_07b59e542970ca073c37af963245420c40ccbbd75eeac88f6854e288b3cfde5e.p1 already exists in sample SRR18070785\n",
      "INFO:__main__:  Sequence v1_DLS_07ce54c52bffdbadf634074024ece05a64d0ee518a0f7ff8feeb8304bf93a8d4.p1 already exists in sample SRR18070785\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR18070787/eggnog/SRR18070787.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR18070788\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR18070788/transdecoder/SRR18070788.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Loaded 19935 new sequences for SRR18070788\n",
      "INFO:__main__:Skipped 103 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_08ef4b758a78395c4986fa653727a5afeb1ad02992fe4721b58a04a72e967db5.p1 already exists in sample SRR18070787\n",
      "INFO:__main__:  Sequence v1_DLS_0b3d16a29976359eccc73937437cff997fce6e0243bd138b4376cdbb17ccfef9.p2 already exists in sample SRR18070785\n",
      "INFO:__main__:  Sequence v1_DLS_0e62d7695a62d91196fe389ff7c6c94aecb14d69512dfb9fe086ad553fa8902f.p1 already exists in sample SRR18070784\n",
      "INFO:__main__:  Sequence v1_DLS_128d24c07f0b563357a058515bbe8443bf6c8ef9be5d0ba2c4a61b0e4d5ff015.p1 already exists in sample SRR18070787\n",
      "INFO:__main__:  Sequence v1_DLS_128d24c07f0b563357a058515bbe8443bf6c8ef9be5d0ba2c4a61b0e4d5ff015.p3 already exists in sample SRR18070787\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR18070788/eggnog/SRR18070788.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR18070789\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR18070789/transdecoder/SRR18070789.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Loaded 9846 new sequences for SRR18070789\n",
      "INFO:__main__:Skipped 34 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_11043e910f7897171a9a86741162b36b444935490133ab659a1bae1c30d30860.p1 already exists in sample SRR18070779\n",
      "INFO:__main__:  Sequence v1_DLS_158826012bbb774ad83b17937d6866d2bd34bc6bc868ea4164fa85395b89ac18.p1 already exists in sample SRR18070779\n",
      "INFO:__main__:  Sequence v1_DLS_158826012bbb774ad83b17937d6866d2bd34bc6bc868ea4164fa85395b89ac18.p2 already exists in sample SRR18070779\n",
      "INFO:__main__:  Sequence v1_DLS_176385416e1b558379d8213589ba016abad3ededde21a87b5aa650ead7184c22.p1 already exists in sample SRR18070779\n",
      "INFO:__main__:  Sequence v1_DLS_1919cce724ee4c987d8dc305165aea1c1c3b8c5b12a098d6f61488f5a56c564c.p1 already exists in sample SRR18070778\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR18070789/eggnog/SRR18070789.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR18070790\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR18070790/transdecoder/SRR18070790.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Loaded 6867 new sequences for SRR18070790\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR18070790/eggnog/SRR18070790.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR18070791\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR18070791/transdecoder/SRR18070791.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Loaded 2994 new sequences for SRR18070791\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR18070791/eggnog/SRR18070791.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR18070792\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR18070792/transdecoder/SRR18070792.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Loaded 6061 new sequences for SRR18070792\n",
      "INFO:__main__:Skipped 2 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_b3de4ccd40f7c9c114f13325a2dac991da78f802172206504b474c78a5eb6f4e.p1 already exists in sample SRR18070788\n",
      "INFO:__main__:  Sequence v1_DLS_b3de4ccd40f7c9c114f13325a2dac991da78f802172206504b474c78a5eb6f4e.p2 already exists in sample SRR18070788\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR18070792/eggnog/SRR18070792.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR18070793\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR18070793/transdecoder/SRR18070793.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Loaded 5223 new sequences for SRR18070793\n",
      "INFO:__main__:Skipped 1 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_462287f58489fbe44cb3253b8b74862a0263d437f1923f423a26a422cc6ff27e.p1 already exists in sample SRR18070792\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR18070793/eggnog/SRR18070793.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR18070794\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR18070794/transdecoder/SRR18070794.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Loaded 5004 new sequences for SRR18070794\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR18070794/eggnog/SRR18070794.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR18070795\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR18070795/transdecoder/SRR18070795.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Loaded 11512 new sequences for SRR18070795\n",
      "INFO:__main__:Skipped 28 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_0f1ca3117ad468ad62699a5a098558e6d82cd6a3aa6a4612838bb39754ab87be.p1 already exists in sample SRR18070780\n",
      "INFO:__main__:  Sequence v1_DLS_0fdb65628bfa8522554ac09366e57489516ff767e64528de7fbd28bc127cf993.p1 already exists in sample SRR18070789\n",
      "INFO:__main__:  Sequence v1_DLS_1a7f26c561725c119d289fcfecea98d822410e95987fa8d98326d72aa14eeb04.p1 already exists in sample SRR18070789\n",
      "INFO:__main__:  Sequence v1_DLS_1ecbfdb97641e7b42568d3595f907b8533889d22f0c7b2291cf243e051b5af49.p1 already exists in sample SRR18070789\n",
      "INFO:__main__:  Sequence v1_DLS_28c2b91f77124c279d204a3d2a9896f8e700ca420af7af25224850a70e1a5b08.p1 already exists in sample SRR18070780\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR18070795/eggnog/SRR18070795.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR18735292\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR18735292/transdecoder/SRR18735292.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Loaded 12907 new sequences for SRR18735292\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR18735292/eggnog/SRR18735292.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR19034772\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR19034772/transdecoder/SRR19034772.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Read 31000 new sequences...\n",
      "INFO:__main__:Loaded 31147 new sequences for SRR19034772\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR19034772/eggnog/SRR19034772.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR19034773\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR19034773/transdecoder/SRR19034773.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Loaded 30412 new sequences for SRR19034773\n",
      "INFO:__main__:Skipped 184 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_0437ef69284a4fa4ffa8ae56c9f5afda5f314bec8a2b21fb69cf52c0444dab86.p1 already exists in sample SRR19034772\n",
      "INFO:__main__:  Sequence v1_DLS_08739a172cdabb36649ea4fb0a241cbb224827bac559ec03b7e85f2cfe4ec913.p1 already exists in sample SRR19034772\n",
      "INFO:__main__:  Sequence v1_DLS_08ae774694aadbff2ec1bed64bad355dd45d11d474132910d28a4126bfe1d659.p3 already exists in sample SRR19034772\n",
      "INFO:__main__:  Sequence v1_DLS_08ae774694aadbff2ec1bed64bad355dd45d11d474132910d28a4126bfe1d659.p7 already exists in sample SRR19034772\n",
      "INFO:__main__:  Sequence v1_DLS_08ae774694aadbff2ec1bed64bad355dd45d11d474132910d28a4126bfe1d659.p4 already exists in sample SRR19034772\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR19034773/eggnog/SRR19034773.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR19619612\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR19619612/transdecoder/SRR19619612.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Loaded 4582 new sequences for SRR19619612\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR19619612/eggnog/SRR19619612.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR19619613\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR19619613/transdecoder/SRR19619613.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Loaded 4290 new sequences for SRR19619613\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR19619613/eggnog/SRR19619613.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR19619614\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR19619614/transdecoder/SRR19619614.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Loaded 4438 new sequences for SRR19619614\n",
      "INFO:__main__:Skipped 22 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_a1d10469e78fbebe9380f19d27669435e9fcae6b23d2338e15454fa8d8a4dec5.p41 already exists in sample SRR19619612\n",
      "INFO:__main__:  Sequence v1_DLS_a1d10469e78fbebe9380f19d27669435e9fcae6b23d2338e15454fa8d8a4dec5.p47 already exists in sample SRR19619612\n",
      "INFO:__main__:  Sequence v1_DLS_a1d10469e78fbebe9380f19d27669435e9fcae6b23d2338e15454fa8d8a4dec5.p36 already exists in sample SRR19619612\n",
      "INFO:__main__:  Sequence v1_DLS_a1d10469e78fbebe9380f19d27669435e9fcae6b23d2338e15454fa8d8a4dec5.p1 already exists in sample SRR19619612\n",
      "INFO:__main__:  Sequence v1_DLS_a1d10469e78fbebe9380f19d27669435e9fcae6b23d2338e15454fa8d8a4dec5.p15 already exists in sample SRR19619612\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR19619614/eggnog/SRR19619614.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR22271585\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR22271585/transdecoder/SRR22271585.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Loaded 20487 new sequences for SRR22271585\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR22271585/eggnog/SRR22271585.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR22271586\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR22271586/transdecoder/SRR22271586.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Loaded 19862 new sequences for SRR22271586\n",
      "INFO:__main__:Skipped 30 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_11513857c4cfcbe5645113858a25d423d2ac2f5f07e11e164cf72dccd35faee4.p1 already exists in sample SRR22271585\n",
      "INFO:__main__:  Sequence v1_DLS_4abc44d23116377241074ff757d55ed036533a9f58c77ffae63f029c53b35296.p1 already exists in sample SRR22271585\n",
      "INFO:__main__:  Sequence v1_DLS_4f48be298c504ac63e1b72815031882cc58f8fb694d4a842b335063e1e0f21b0.p3 already exists in sample SRR22271585\n",
      "INFO:__main__:  Sequence v1_DLS_4f48be298c504ac63e1b72815031882cc58f8fb694d4a842b335063e1e0f21b0.p1 already exists in sample SRR22271585\n",
      "INFO:__main__:  Sequence v1_DLS_4f48be298c504ac63e1b72815031882cc58f8fb694d4a842b335063e1e0f21b0.p2 already exists in sample SRR22271585\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR22271586/eggnog/SRR22271586.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR22271587\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR22271587/transdecoder/SRR22271587.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Loaded 21318 new sequences for SRR22271587\n",
      "INFO:__main__:Skipped 57 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_06c9e46e7f020c466956fdbc769f45902687abe4809b70b48a4fd9cf2a9e9154.p1 already exists in sample SRR22271585\n",
      "INFO:__main__:  Sequence v1_DLS_12090a24921ab0701736cce11f89143161ab22da93c9d6526e5d334068e5f9ed.p2 already exists in sample SRR22271585\n",
      "INFO:__main__:  Sequence v1_DLS_12090a24921ab0701736cce11f89143161ab22da93c9d6526e5d334068e5f9ed.p1 already exists in sample SRR22271585\n",
      "INFO:__main__:  Sequence v1_DLS_1a2821d286f249307860851864591e281478fc6a6a6b68adeb76d97263609366.p4 already exists in sample SRR22271585\n",
      "INFO:__main__:  Sequence v1_DLS_1a2821d286f249307860851864591e281478fc6a6a6b68adeb76d97263609366.p1 already exists in sample SRR22271585\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR22271587/eggnog/SRR22271587.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR22271588\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR22271588/transdecoder/SRR22271588.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Loaded 19316 new sequences for SRR22271588\n",
      "INFO:__main__:Skipped 120 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_03d5c9352cdd7837c9313146a79d75cf3bb0f01b897964b01e126bff563e947e.p1 already exists in sample SRR22271587\n",
      "INFO:__main__:  Sequence v1_DLS_0666c0c7f72f6be52d02f4ab6063e00877ba8215c8d92e8294301ec55106d59f.p1 already exists in sample SRR22271585\n",
      "INFO:__main__:  Sequence v1_DLS_0666c0c7f72f6be52d02f4ab6063e00877ba8215c8d92e8294301ec55106d59f.p2 already exists in sample SRR22271585\n",
      "INFO:__main__:  Sequence v1_DLS_06c9e46e7f020c466956fdbc769f45902687abe4809b70b48a4fd9cf2a9e9154.p1 already exists in sample SRR22271585\n",
      "INFO:__main__:  Sequence v1_DLS_070d46c859d9a459342dea07d206f8347ae2a92eba259e918d949fbf7fa3aad1.p1 already exists in sample SRR22271585\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR22271588/eggnog/SRR22271588.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR22271589\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR22271589/transdecoder/SRR22271589.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Loaded 18529 new sequences for SRR22271589\n",
      "INFO:__main__:Skipped 114 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_00904fbb71f82b0581f00d10d07fe36f84bebb516ff8e63488b3fa5b24f98447.p1 already exists in sample SRR22271586\n",
      "INFO:__main__:  Sequence v1_DLS_03669ebff571da529147b4e491b03e79ef924c7fa6a73edf9c638659029017eb.p1 already exists in sample SRR22271586\n",
      "INFO:__main__:  Sequence v1_DLS_06772dd1850ad90e2400b05ffd4c07a8a9266066d3b62eef3555f13b4b677c9a.p1 already exists in sample SRR22271588\n",
      "INFO:__main__:  Sequence v1_DLS_06c9e46e7f020c466956fdbc769f45902687abe4809b70b48a4fd9cf2a9e9154.p1 already exists in sample SRR22271585\n",
      "INFO:__main__:  Sequence v1_DLS_07c65a16f513782076a8088c059fc3482b778e6c92919731fb2f76ef7027d65a.p1 already exists in sample SRR22271585\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR22271589/eggnog/SRR22271589.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR22904707\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR22904707/transdecoder/SRR22904707.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Loaded 16314 new sequences for SRR22904707\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR22904707/eggnog/SRR22904707.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR24974225\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR24974225/transdecoder/SRR24974225.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Read 31000 new sequences...\n",
      "INFO:__main__:Read 32000 new sequences...\n",
      "INFO:__main__:Read 33000 new sequences...\n",
      "INFO:__main__:Read 34000 new sequences...\n",
      "INFO:__main__:Read 35000 new sequences...\n",
      "INFO:__main__:Read 36000 new sequences...\n",
      "INFO:__main__:Read 37000 new sequences...\n",
      "INFO:__main__:Read 38000 new sequences...\n",
      "INFO:__main__:Read 39000 new sequences...\n",
      "INFO:__main__:Read 40000 new sequences...\n",
      "INFO:__main__:Read 41000 new sequences...\n",
      "INFO:__main__:Loaded 41111 new sequences for SRR24974225\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR24974225/eggnog/SRR24974225.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR24974226\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR24974226/transdecoder/SRR24974226.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Read 31000 new sequences...\n",
      "INFO:__main__:Read 32000 new sequences...\n",
      "INFO:__main__:Read 33000 new sequences...\n",
      "INFO:__main__:Read 34000 new sequences...\n",
      "INFO:__main__:Read 35000 new sequences...\n",
      "INFO:__main__:Read 36000 new sequences...\n",
      "INFO:__main__:Read 37000 new sequences...\n",
      "INFO:__main__:Read 38000 new sequences...\n",
      "INFO:__main__:Read 39000 new sequences...\n",
      "INFO:__main__:Loaded 39139 new sequences for SRR24974226\n",
      "INFO:__main__:Skipped 5 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_120e5e17e4d139bd54c20d0b00232433b6c6d55cef7596f37e1975aa6201fc17.p1 already exists in sample SRR24974225\n",
      "INFO:__main__:  Sequence v1_DLS_19ba1099e4b9423991cd571039cc4d9e9487b6779a9fd29f185b6fcac6756884.p1 already exists in sample SRR24974225\n",
      "INFO:__main__:  Sequence v1_DLS_70cef8e7ff3e965d587ed9c083e20db5fcbcd274772b1942358708d18210d19a.p1 already exists in sample SRR24974225\n",
      "INFO:__main__:  Sequence v1_DLS_a928e9ce14dbad9477e449fda5c950e6cd448b446e9ef948ee2fd6197e659843.p1 already exists in sample SRR24974225\n",
      "INFO:__main__:  Sequence v1_DLS_d3c415854d9da1c7c4f8f349a47498b9419d2e2ba692790406af927ee078b54f.p1 already exists in sample SRR24974225\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR24974226/eggnog/SRR24974226.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR24974227\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR24974227/transdecoder/SRR24974227.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Read 31000 new sequences...\n",
      "INFO:__main__:Read 32000 new sequences...\n",
      "INFO:__main__:Read 33000 new sequences...\n",
      "INFO:__main__:Read 34000 new sequences...\n",
      "INFO:__main__:Read 35000 new sequences...\n",
      "INFO:__main__:Read 36000 new sequences...\n",
      "INFO:__main__:Read 37000 new sequences...\n",
      "INFO:__main__:Read 38000 new sequences...\n",
      "INFO:__main__:Loaded 38751 new sequences for SRR24974227\n",
      "INFO:__main__:Skipped 7 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_16c0d7b7306f69c9298ea9863ab104261ca73c7c9a82b121e0c80b118fb70502.p1 already exists in sample SRR24974226\n",
      "INFO:__main__:  Sequence v1_DLS_2c332ab051bbad202553478cc49a14be0127ccaa371621e6939f77132a533277.p1 already exists in sample SRR24974225\n",
      "INFO:__main__:  Sequence v1_DLS_3f08a1ad2ceae4010354dba854f6405c7cf7007e62f2661d2e395e50a12536cc.p1 already exists in sample SRR24974225\n",
      "INFO:__main__:  Sequence v1_DLS_ac63c33328a5db04466e81f4afda5d5ac563fccb1c81f1f574879d85142088d8.p1 already exists in sample SRR24974226\n",
      "INFO:__main__:  Sequence v1_DLS_c0966322a1f919e5ca73e28248d759f23862b8a88aab2e3e3e7351e37c55c868.p1 already exists in sample SRR24974226\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR24974227/eggnog/SRR24974227.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR24974228\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR24974228/transdecoder/SRR24974228.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Read 31000 new sequences...\n",
      "INFO:__main__:Read 32000 new sequences...\n",
      "INFO:__main__:Read 33000 new sequences...\n",
      "INFO:__main__:Read 34000 new sequences...\n",
      "INFO:__main__:Loaded 34163 new sequences for SRR24974228\n",
      "INFO:__main__:Skipped 6 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_0b2aeb34222cc3a1fdce15216f33be84d34c6f2c2a0d2dab6ca5d3858f420d7e.p1 already exists in sample SRR24974227\n",
      "INFO:__main__:  Sequence v1_DLS_1fdd96b23bd463d65d8ceaa584901845269d3dde18cf821e1c80e02a86d9a711.p1 already exists in sample SRR24974225\n",
      "INFO:__main__:  Sequence v1_DLS_4673a6a2e1427ae8ba296763c153eb08f5d7ebc2c9e6675b973be22e2994b2bf.p2 already exists in sample SRR24974226\n",
      "INFO:__main__:  Sequence v1_DLS_6742677c1e815d789f95617e0c2ce5b7f2a717bc56e2b793ff7674d9e37bd224.p1 already exists in sample SRR24974225\n",
      "INFO:__main__:  Sequence v1_DLS_e48a432b96d00c550d2b1a32ecdd4176d827f3bbeabbcc73004a2d933cc02553.p1 already exists in sample SRR24974226\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR24974228/eggnog/SRR24974228.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR25582085\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR25582085/transdecoder/SRR25582085.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Read 31000 new sequences...\n",
      "INFO:__main__:Read 32000 new sequences...\n",
      "INFO:__main__:Read 33000 new sequences...\n",
      "INFO:__main__:Read 34000 new sequences...\n",
      "INFO:__main__:Read 35000 new sequences...\n",
      "INFO:__main__:Read 36000 new sequences...\n",
      "INFO:__main__:Read 37000 new sequences...\n",
      "INFO:__main__:Read 38000 new sequences...\n",
      "INFO:__main__:Loaded 38767 new sequences for SRR25582085\n",
      "INFO:__main__:Skipped 3 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_2d11b3ae742164bc89a84854bcea7ccc855dc3d075566231d7bb685469828813.p1 already exists in sample SRR24974228\n",
      "INFO:__main__:  Sequence v1_DLS_441765ccb23650452aff6e00e64a1ddfbafda31f05812d7a3bcadd7887ce818e.p1 already exists in sample SRR24974227\n",
      "INFO:__main__:  Sequence v1_DLS_6bcfe4bd79ce2776fbf04d3b3ed55f5be2c8c2dd5afb76073dee13fc933e8f09.p1 already exists in sample SRR24974227\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR25582085/eggnog/SRR25582085.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR29366264\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR29366264/transdecoder/SRR29366264.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Loaded 23018 new sequences for SRR29366264\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR29366264/eggnog/SRR29366264.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR29366265\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR29366265/transdecoder/SRR29366265.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Read 31000 new sequences...\n",
      "INFO:__main__:Read 32000 new sequences...\n",
      "INFO:__main__:Read 33000 new sequences...\n",
      "INFO:__main__:Loaded 33502 new sequences for SRR29366265\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR29366265/eggnog/SRR29366265.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR29366266\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR29366266/transdecoder/SRR29366266.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Read 31000 new sequences...\n",
      "INFO:__main__:Read 32000 new sequences...\n",
      "INFO:__main__:Loaded 32517 new sequences for SRR29366266\n",
      "INFO:__main__:Skipped 2 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_a5bb9d9b2fb245639f4ff881433a222b02f4de7aed86e0d9deab79cb7392b8b7.p1 already exists in sample SRR29366264\n",
      "INFO:__main__:  Sequence v1_DLS_be79c04382ac1334ec49535fb1b1794656a3de4b7260348adee22a0ae8e6e8ff.p1 already exists in sample SRR29366265\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR29366266/eggnog/SRR29366266.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR5489198\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR5489198/transdecoder/SRR5489198.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Loaded 29557 new sequences for SRR5489198\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR5489198/eggnog/SRR5489198.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR5992919\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR5992919/transdecoder/SRR5992919.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Loaded 12738 new sequences for SRR5992919\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR5992919/eggnog/SRR5992919.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR5992920\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR5992920/transdecoder/SRR5992920.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Loaded 25991 new sequences for SRR5992920\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR5992920/eggnog/SRR5992920.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR6048009\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR6048009/transdecoder/SRR6048009.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Read 31000 new sequences...\n",
      "INFO:__main__:Read 32000 new sequences...\n",
      "INFO:__main__:Read 33000 new sequences...\n",
      "INFO:__main__:Read 34000 new sequences...\n",
      "INFO:__main__:Read 35000 new sequences...\n",
      "INFO:__main__:Read 36000 new sequences...\n",
      "INFO:__main__:Read 37000 new sequences...\n",
      "INFO:__main__:Read 38000 new sequences...\n",
      "INFO:__main__:Read 39000 new sequences...\n",
      "INFO:__main__:Read 40000 new sequences...\n",
      "INFO:__main__:Read 41000 new sequences...\n",
      "INFO:__main__:Read 42000 new sequences...\n",
      "INFO:__main__:Loaded 42482 new sequences for SRR6048009\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR6048009/eggnog/SRR6048009.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR8859643\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR8859643/transdecoder/SRR8859643.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Loaded 27819 new sequences for SRR8859643\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR8859643/eggnog/SRR8859643.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR8859644\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR8859644/transdecoder/SRR8859644.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Loaded 28264 new sequences for SRR8859644\n",
      "INFO:__main__:Skipped 24 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_1725506cf472c985a052f420e90bc6509c9987e1195cb20b9c06d6d5d75da46d.p3 already exists in sample SRR8859643\n",
      "INFO:__main__:  Sequence v1_DLS_1725506cf472c985a052f420e90bc6509c9987e1195cb20b9c06d6d5d75da46d.p1 already exists in sample SRR8859643\n",
      "INFO:__main__:  Sequence v1_DLS_192b9fa62d6fc57ef1c7c296d49a1ca046dc7e116817702df03091f95401e872.p1 already exists in sample SRR8859643\n",
      "INFO:__main__:  Sequence v1_DLS_1ddb12279ff0a56204d4bfb7ecb5f8f4e747677c46f6fe3407593ee09f161df8.p1 already exists in sample SRR8859643\n",
      "INFO:__main__:  Sequence v1_DLS_2943198632a393465ab7f88dbca5692f5b36913401422386fb85c002e01e506b.p1 already exists in sample SRR8859643\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR8859644/eggnog/SRR8859644.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR8859645\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR8859645/transdecoder/SRR8859645.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Loaded 30587 new sequences for SRR8859645\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR8859645/eggnog/SRR8859645.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR8859646\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR8859646/transdecoder/SRR8859646.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Read 31000 new sequences...\n",
      "INFO:__main__:Read 32000 new sequences...\n",
      "INFO:__main__:Read 33000 new sequences...\n",
      "INFO:__main__:Loaded 33480 new sequences for SRR8859646\n",
      "INFO:__main__:Skipped 17 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_0a97641d6de7be1ace060f4a5e4380a357bec8c8a77e1afa67956b6e70556053.p1 already exists in sample SRR8859645\n",
      "INFO:__main__:  Sequence v1_DLS_33554fb69884a27b70c21a8368253f930676d4505751c6d60d87f3471ecb1f38.p1 already exists in sample SRR8859645\n",
      "INFO:__main__:  Sequence v1_DLS_33554fb69884a27b70c21a8368253f930676d4505751c6d60d87f3471ecb1f38.p2 already exists in sample SRR8859645\n",
      "INFO:__main__:  Sequence v1_DLS_47a15b655b8f4eaef87b35862983eb5d6edd505fe3fe5b7dbae0037799788216.p2 already exists in sample SRR8859645\n",
      "INFO:__main__:  Sequence v1_DLS_47a15b655b8f4eaef87b35862983eb5d6edd505fe3fe5b7dbae0037799788216.p1 already exists in sample SRR8859645\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR8859646/eggnog/SRR8859646.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR8859647\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR8859647/transdecoder/SRR8859647.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Read 31000 new sequences...\n",
      "INFO:__main__:Read 32000 new sequences...\n",
      "INFO:__main__:Read 33000 new sequences...\n",
      "INFO:__main__:Read 34000 new sequences...\n",
      "INFO:__main__:Read 35000 new sequences...\n",
      "INFO:__main__:Read 36000 new sequences...\n",
      "INFO:__main__:Read 37000 new sequences...\n",
      "INFO:__main__:Loaded 37443 new sequences for SRR8859647\n",
      "INFO:__main__:Skipped 6 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_5e3582bbece820894e18cc19e98edbeaaaa20c5195fe8224d00b454056b76ea0.p1 already exists in sample SRR8859645\n",
      "INFO:__main__:  Sequence v1_DLS_62640764bfb2af2954ebfac87e949b271956cbafab751ee9a6fd7fb723a208c7.p2 already exists in sample SRR8859645\n",
      "INFO:__main__:  Sequence v1_DLS_62640764bfb2af2954ebfac87e949b271956cbafab751ee9a6fd7fb723a208c7.p1 already exists in sample SRR8859645\n",
      "INFO:__main__:  Sequence v1_DLS_7d45d360e5cde22ee872c4effd39b3de9fac99162083f32216441121cb6161ae.p1 already exists in sample SRR8859644\n",
      "INFO:__main__:  Sequence v1_DLS_7f5637d2d665ef8c94afa85662cbf1808293a5327122e739a70dc0a7255b9103.p1 already exists in sample SRR8859645\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR8859647/eggnog/SRR8859647.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Processing sample: SRR8859648\n",
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR8859648/transdecoder/SRR8859648.pep\n",
      "INFO:__main__:Read 1000 new sequences...\n",
      "INFO:__main__:Read 2000 new sequences...\n",
      "INFO:__main__:Read 3000 new sequences...\n",
      "INFO:__main__:Read 4000 new sequences...\n",
      "INFO:__main__:Read 5000 new sequences...\n",
      "INFO:__main__:Read 6000 new sequences...\n",
      "INFO:__main__:Read 7000 new sequences...\n",
      "INFO:__main__:Read 8000 new sequences...\n",
      "INFO:__main__:Read 9000 new sequences...\n",
      "INFO:__main__:Read 10000 new sequences...\n",
      "INFO:__main__:Read 11000 new sequences...\n",
      "INFO:__main__:Read 12000 new sequences...\n",
      "INFO:__main__:Read 13000 new sequences...\n",
      "INFO:__main__:Read 14000 new sequences...\n",
      "INFO:__main__:Read 15000 new sequences...\n",
      "INFO:__main__:Read 16000 new sequences...\n",
      "INFO:__main__:Read 17000 new sequences...\n",
      "INFO:__main__:Read 18000 new sequences...\n",
      "INFO:__main__:Read 19000 new sequences...\n",
      "INFO:__main__:Read 20000 new sequences...\n",
      "INFO:__main__:Read 21000 new sequences...\n",
      "INFO:__main__:Read 22000 new sequences...\n",
      "INFO:__main__:Read 23000 new sequences...\n",
      "INFO:__main__:Read 24000 new sequences...\n",
      "INFO:__main__:Read 25000 new sequences...\n",
      "INFO:__main__:Read 26000 new sequences...\n",
      "INFO:__main__:Read 27000 new sequences...\n",
      "INFO:__main__:Read 28000 new sequences...\n",
      "INFO:__main__:Read 29000 new sequences...\n",
      "INFO:__main__:Read 30000 new sequences...\n",
      "INFO:__main__:Read 31000 new sequences...\n",
      "INFO:__main__:Read 32000 new sequences...\n",
      "INFO:__main__:Read 33000 new sequences...\n",
      "INFO:__main__:Read 34000 new sequences...\n",
      "INFO:__main__:Read 35000 new sequences...\n",
      "INFO:__main__:Read 36000 new sequences...\n",
      "INFO:__main__:Loaded 36454 new sequences for SRR8859648\n",
      "INFO:__main__:Skipped 36 duplicate sequences\n",
      "INFO:__main__:First few duplicates:\n",
      "INFO:__main__:  Sequence v1_DLS_0b8362a240a202f40b4b59a043f3560b8d3478693d3e026d864e5628b047ca18.p1 already exists in sample SRR8859647\n",
      "INFO:__main__:  Sequence v1_DLS_0bc33017b5bb16c0b8405a8322ac3f0d7a66547081630db0d735c22778e55e00.p1 already exists in sample SRR8859647\n",
      "INFO:__main__:  Sequence v1_DLS_159d1cf29970b78993d00b0ead7bfb127ef502bb0da481d61b1d7a2797c760a6.p1 already exists in sample SRR8859647\n",
      "INFO:__main__:  Sequence v1_DLS_172d3e51ed5bf2db7ec2c8279459780090cb3aebb1c089d29271bc34d0c31921.p2 already exists in sample SRR8859647\n",
      "INFO:__main__:  Sequence v1_DLS_172d3e51ed5bf2db7ec2c8279459780090cb3aebb1c089d29271bc34d0c31921.p1 already exists in sample SRR8859647\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR8859648/eggnog/SRR8859648.emapper.annotations\n",
      "INFO:__main__:Cleaning up temporary tables...\n",
      "INFO:__main__:\n",
      "Database Summary:\n",
      "INFO:__main__:\n",
      "Duplicate Summary:\n",
      "INFO:__main__:ERR9123872: 9 duplicate sequences\n",
      "INFO:__main__:ERR9123874: 5 duplicate sequences\n",
      "INFO:__main__:ERR9123875: 23 duplicate sequences\n",
      "INFO:__main__:ERR9123876: 29 duplicate sequences\n",
      "INFO:__main__:ERR9123877: 29 duplicate sequences\n",
      "INFO:__main__:ERR9123878: 5 duplicate sequences\n",
      "INFO:__main__:ERR9123879: 44 duplicate sequences\n",
      "INFO:__main__:ERR9123880: 43 duplicate sequences\n",
      "INFO:__main__:ERR9123881: 47 duplicate sequences\n",
      "INFO:__main__:ERR9123882: 69 duplicate sequences\n",
      "INFO:__main__:SRR10444680: 7 duplicate sequences\n",
      "INFO:__main__:SRR10444681: 30 duplicate sequences\n",
      "INFO:__main__:SRR10444682: 12 duplicate sequences\n",
      "INFO:__main__:SRR10444683: 112 duplicate sequences\n",
      "INFO:__main__:SRR10444684: 214 duplicate sequences\n",
      "INFO:__main__:SRR11011256: 12 duplicate sequences\n",
      "INFO:__main__:SRR11011257: 8 duplicate sequences\n",
      "INFO:__main__:SRR11011258: 8 duplicate sequences\n",
      "INFO:__main__:SRR11011259: 20 duplicate sequences\n",
      "INFO:__main__:SRR11011260: 18 duplicate sequences\n",
      "INFO:__main__:SRR128114: 5 duplicate sequences\n",
      "INFO:__main__:SRR14292008: 29 duplicate sequences\n",
      "INFO:__main__:SRR18070779: 10 duplicate sequences\n",
      "INFO:__main__:SRR18070780: 6 duplicate sequences\n",
      "INFO:__main__:SRR18070785: 86 duplicate sequences\n",
      "INFO:__main__:SRR18070786: 177 duplicate sequences\n",
      "INFO:__main__:SRR18070787: 195 duplicate sequences\n",
      "INFO:__main__:SRR18070788: 103 duplicate sequences\n",
      "INFO:__main__:SRR18070789: 34 duplicate sequences\n",
      "INFO:__main__:SRR18070792: 2 duplicate sequences\n",
      "INFO:__main__:SRR18070793: 1 duplicate sequences\n",
      "INFO:__main__:SRR18070795: 28 duplicate sequences\n",
      "INFO:__main__:SRR19034773: 184 duplicate sequences\n",
      "INFO:__main__:SRR19619614: 22 duplicate sequences\n",
      "INFO:__main__:SRR22271586: 30 duplicate sequences\n",
      "INFO:__main__:SRR22271587: 57 duplicate sequences\n",
      "INFO:__main__:SRR22271588: 120 duplicate sequences\n",
      "INFO:__main__:SRR22271589: 114 duplicate sequences\n",
      "INFO:__main__:SRR24974226: 5 duplicate sequences\n",
      "INFO:__main__:SRR24974227: 7 duplicate sequences\n",
      "INFO:__main__:SRR24974228: 6 duplicate sequences\n",
      "INFO:__main__:SRR25582085: 3 duplicate sequences\n",
      "INFO:__main__:SRR29366266: 2 duplicate sequences\n",
      "INFO:__main__:SRR8859644: 24 duplicate sequences\n",
      "INFO:__main__:SRR8859646: 17 duplicate sequences\n",
      "INFO:__main__:SRR8859647: 6 duplicate sequences\n",
      "INFO:__main__:SRR8859648: 36 duplicate sequences\n",
      "INFO:__main__:\n",
      "Example duplicates (first few):\n",
      "INFO:__main__:\n",
      "Duplicates in ERR9123872:\n",
      "INFO:__main__:  v1_DLS_108900dfd519627a4e0ffbd0c80e4268eb3384d860e3fb796fdda887ad18f03c.p1 (length: 377) - first found in ERR9123871\n",
      "INFO:__main__:  v1_DLS_172183323642e5314aefffc2722cb3e563948b7adce112fbeb555d68aeed64e8.p1 (length: 117) - first found in ERR9123871\n",
      "INFO:__main__:  v1_DLS_1c0b7a8d06a514f717258ad1d05d43d4984f479ef87288421da49af8932e9530.p1 (length: 125) - first found in ERR9123871\n",
      "INFO:__main__:  v1_DLS_63a93ecaf0cfecf790bb146bc94f97d48e00e4336609ec5158b319e294b487b0.p1 (length: 105) - first found in ERR9123871\n",
      "INFO:__main__:  v1_DLS_6a1bdfc8cd6570dc637d19389f901d032de28c23593292de8465cd6bbbd857ff.p1 (length: 308) - first found in ERR9123871\n",
      "INFO:__main__:\n",
      "Duplicates in ERR9123874:\n",
      "INFO:__main__:  v1_DLS_3ea505807f1f886432d4e6d6acb72bfdb129844afdae83d27f37a7b3e78bfc63.p1 (length: 349) - first found in ERR9123872\n",
      "INFO:__main__:  v1_DLS_46f2df41aa51e653e99cfec46ea1c6e41ee64f4b5f85b8efccfcb52d2d70154c.p1 (length: 224) - first found in ERR9123871\n",
      "INFO:__main__:  v1_DLS_67cc90422831ad1477a4ac8cf9c8dcbbea161e43082ce0ce6ac3931f80efb283.p1 (length: 106) - first found in ERR9123872\n",
      "INFO:__main__:  v1_DLS_a32fca4f942423956667f7bf91a4319bbbf6452e63149d3094dd78b3e41a8f8c.p1 (length: 315) - first found in ERR9123872\n",
      "INFO:__main__:  v1_DLS_bfccc88f7f7df54788694c497b9059a3087c5b1d37a78d117ad0f97a8fec657f.p1 (length: 169) - first found in ERR9123871\n",
      "INFO:__main__:\n",
      "Duplicates in ERR9123875:\n",
      "INFO:__main__:  v1_DLS_13a40711c372a136aaad1cac4e8ea0a95e524f2078f41f8c7fb766bd4de3a33f.p1 (length: 545) - first found in ERR9123874\n",
      "INFO:__main__:  v1_DLS_1b27594303486bbbd35b7ab5e4a5d9eb9efd01e16f95507ffbf7b6f7a37dd916.p1 (length: 443) - first found in ERR9123871\n",
      "INFO:__main__:  v1_DLS_1dd91f3c17330afc49cab5c786f0d8727fc9dfd8741d52a40927c250681662a4.p1 (length: 188) - first found in ERR9123874\n",
      "INFO:__main__:  v1_DLS_2046c5ed7951937e2661313c3b3faadaa729e3221ace65c9350bb14f70a9209c.p1 (length: 287) - first found in ERR9123872\n",
      "INFO:__main__:  v1_DLS_496b904de055f4c22a5f3999e8af45e2dd3f51e57d736656240022c3af925c1c.p1 (length: 244) - first found in ERR9123871\n",
      "INFO:__main__:\n",
      "Duplicates in ERR9123876:\n",
      "INFO:__main__:  v1_DLS_06d4c674879a46aa91010b8ed4e1602b5e15fe970419c04e47b85a6628389e9a.p1 (length: 332) - first found in ERR9123874\n",
      "INFO:__main__:  v1_DLS_12daf990426ff698ffb06d1ea3d57b0786c946d33522f55b3f7dfd7d8ba1aaa6.p1 (length: 642) - first found in ERR9123875\n",
      "INFO:__main__:  v1_DLS_130f6ca6dda9609019b339b669ebc38631b90669b3030e0ce0371f79d9c9227b.p1 (length: 235) - first found in ERR9123872\n",
      "INFO:__main__:  v1_DLS_13d7134879ea4c315e06d95198804257e590364ff1a2419e8edab907ede7b608.p1 (length: 253) - first found in ERR9123871\n",
      "INFO:__main__:  v1_DLS_1b1711ada850c27229e14f995e5f8825e83c41f799c0c4975c50d0ffa219ea5f.p1 (length: 242) - first found in ERR9123871\n",
      "INFO:__main__:\n",
      "Duplicates in ERR9123877:\n",
      "INFO:__main__:  v1_DLS_0dce92366abb0d7b752b000ed45de8cf2d94fd2ab4e438d5a91b66e27f84d258.p1 (length: 104) - first found in ERR9123872\n",
      "INFO:__main__:  v1_DLS_1e1ce7004b26f996ce288519625ae5159034ff28562bd9b47bbf9e1f389a9eaa.p1 (length: 328) - first found in ERR9123871\n",
      "INFO:__main__:  v1_DLS_2ed223600606d6cb1119968055e42027c70e3d07a05d06f6cc5a0a2f910a072f.p1 (length: 489) - first found in ERR9123875\n",
      "INFO:__main__:  v1_DLS_3f1431992dfd2142e6748ee3f88cdedfa9a630085a253d569d58fd5a313ffd93.p1 (length: 159) - first found in ERR9123876\n",
      "INFO:__main__:  v1_DLS_498352a795de1497399bc1cf05283262179c1fff7b9f95469b956e8dcec86771.p1 (length: 193) - first found in ERR9123871\n",
      "INFO:__main__:\n",
      "Duplicates in ERR9123878:\n",
      "INFO:__main__:  v1_DLS_075d5508c71eb810f01a66db1c0c425d51e680569d05ad79b8c87c1c890463b9.p1 (length: 261) - first found in ERR9123874\n",
      "INFO:__main__:  v1_DLS_07c35796e38c3733997a40a575a7f0f600ab319fc46b71d6f014fa6105ad47cf.p1 (length: 1033) - first found in ERR9123877\n",
      "INFO:__main__:  v1_DLS_32a02f2bf3ba64c12781690a70a3176b979e84d43ef29888039f94310a48b3d1.p1 (length: 331) - first found in ERR9123872\n",
      "INFO:__main__:  v1_DLS_8e87c28497abafc27562f114cc7e6e05f63f6dfc3f88b2187afd963a0090fb43.p1 (length: 462) - first found in ERR9123875\n",
      "INFO:__main__:  v1_DLS_a43816c0d3ca401fe04eac2ffdc15b2bf4f09672ff918f8ebb884e13806f779f.p1 (length: 293) - first found in ERR9123877\n",
      "INFO:__main__:\n",
      "Duplicates in ERR9123879:\n",
      "INFO:__main__:  v1_DLS_0eea4bae30f96d8d94970302bab7f1b74d48a67d009d8c9cf7e1389ac28396c3.p1 (length: 235) - first found in ERR9123872\n",
      "INFO:__main__:  v1_DLS_10727a4e9130c7a3919ee56c1600af883c4a775f20224900576e0acb09dc50e2.p1 (length: 171) - first found in ERR9123877\n",
      "INFO:__main__:  v1_DLS_1126e0eb3fee2854837f41359464db4df2994d71796735bac5411c4cc5493d87.p1 (length: 1102) - first found in ERR9123877\n",
      "INFO:__main__:  v1_DLS_13bcdaef37dcc5e0854fb0352ef457232a74e2dfe8989f27cb41f5b02e000c6a.p1 (length: 496) - first found in ERR9123871\n",
      "INFO:__main__:  v1_DLS_144dd02f9e860d5ed2f23408a33071c635cdb45b411f81d4c630ff7d2d68e43b.p1 (length: 146) - first found in ERR9123877\n",
      "INFO:__main__:\n",
      "Duplicates in ERR9123880:\n",
      "INFO:__main__:  v1_DLS_046308c053c991c8f5fe2a93b0c0bdba30cd8d12e659dc574779eacb635d42c8.p1 (length: 397) - first found in ERR9123876\n",
      "INFO:__main__:  v1_DLS_1126e0eb3fee2854837f41359464db4df2994d71796735bac5411c4cc5493d87.p1 (length: 1102) - first found in ERR9123877\n",
      "INFO:__main__:  v1_DLS_1f4a80fee4f453c49a707fc98aa1ffea927bfdfb4a09524043d9ee029b1b6b6f.p1 (length: 317) - first found in ERR9123879\n",
      "INFO:__main__:  v1_DLS_23e79146529bf78d80196e8a04c3c9a04d40f17c0a4b5d8f90565a4b0782d9ae.p1 (length: 177) - first found in ERR9123871\n",
      "INFO:__main__:  v1_DLS_289a772d82c00dbd463528f458971fcd9b6bebfa82135b1316331a9f0f2fa5f5.p1 (length: 343) - first found in ERR9123879\n",
      "INFO:__main__:\n",
      "Duplicates in ERR9123881:\n",
      "INFO:__main__:  v1_DLS_03d3745fa517c78247d909adcebec60725149775eeb404d9cc4919847497da07.p1 (length: 268) - first found in ERR9123880\n",
      "INFO:__main__:  v1_DLS_17078b32cd735c1d05a136fa02e69900a1ba8aabdf8d6c58d663bd8a660c1962.p1 (length: 166) - first found in ERR9123880\n",
      "INFO:__main__:  v1_DLS_17bba1ad05c14e389cf7b6d5e2a521b01063790d737a1ce3e0066768a728f0d9.p1 (length: 150) - first found in ERR9123880\n",
      "INFO:__main__:  v1_DLS_297fc47af79a59229b7930a530abbe0661af38c36eca0b959147409469278915.p1 (length: 518) - first found in ERR9123877\n",
      "INFO:__main__:  v1_DLS_2eb03ed2d71d8c2f66d245239b09cc13e709cc1c03f6c03f29faa1eaef87847e.p1 (length: 378) - first found in ERR9123880\n",
      "INFO:__main__:\n",
      "Duplicates in ERR9123882:\n",
      "INFO:__main__:  v1_DLS_0165b35cf93e800314f22fe111ebc101a6f43e77f37d461bc52477fda0474041.p1 (length: 378) - first found in ERR9123874\n",
      "INFO:__main__:  v1_DLS_0bcd3ec6bf41a2c3e99322f8e2930b477b847227927805e1e867b450e8192334.p1 (length: 126) - first found in ERR9123880\n",
      "INFO:__main__:  v1_DLS_10e9af6a0098657c97039076e587a502f14b9acc1d34801e97a979c65c155859.p1 (length: 257) - first found in ERR9123874\n",
      "INFO:__main__:  v1_DLS_11d18241eb9ba9d18ba9c962804f8254ec00c7acc3467d7ea4973a76b86b9eaa.p1 (length: 177) - first found in ERR9123880\n",
      "INFO:__main__:  v1_DLS_16c578a9c9d24d3a327a87732a973b27a726d15eb02bc810a1bd78d58867258f.p1 (length: 652) - first found in ERR9123880\n",
      "INFO:__main__:\n",
      "Duplicates in SRR10444680:\n",
      "INFO:__main__:  v1_DLS_0da9a915d1495c7e6a9d27cb789ccc6752726fafb8f666762ea0098797912ce3.p2 (length: 108) - first found in SRR10444679\n",
      "INFO:__main__:  v1_DLS_0da9a915d1495c7e6a9d27cb789ccc6752726fafb8f666762ea0098797912ce3.p1 (length: 169) - first found in SRR10444679\n",
      "INFO:__main__:  v1_DLS_0f2c7e4c9a495f738fdc82670daebb63fffaf01b5faacff53b1d40c1b64b6f02.p1 (length: 156) - first found in SRR10444679\n",
      "INFO:__main__:  v1_DLS_106d4ba3acb22bdb0f8980c0366c0df46af5550d8ae4104a3977502f7274fdcb.p1 (length: 257) - first found in SRR10444679\n",
      "INFO:__main__:  v1_DLS_b9bb7ea23873c111a47b3dad8c1880fd899bf3e3f1fb7d889493eb2d3703c6fd.p1 (length: 150) - first found in SRR10444679\n",
      "INFO:__main__:\n",
      "Duplicates in SRR10444681:\n",
      "INFO:__main__:  v1_DLS_05510854c8ced16fa50496b871344b91bb46048e081b0520e386379fa1494386.p1 (length: 532) - first found in SRR10444680\n",
      "INFO:__main__:  v1_DLS_0a31cd1bca3e9eeb2630c446f38a663b6341675bffc99bad11044f636e2ead27.p1 (length: 423) - first found in SRR10444680\n",
      "INFO:__main__:  v1_DLS_130ed7aeac55f7c2fe8ecad9c37dbb0993201b177f2130346f2e8b66209eded7.p1 (length: 143) - first found in SRR10444680\n",
      "INFO:__main__:  v1_DLS_14c2815de1c6a7e5274be353897acccf277a655855e33d722adad4b3c71a588f.p1 (length: 1721) - first found in SRR10444680\n",
      "INFO:__main__:  v1_DLS_18d16777628a82ffe0a1922a034f161820e6100a0dea9253714ca9716f603eab.p1 (length: 181) - first found in SRR10444680\n",
      "INFO:__main__:\n",
      "Duplicates in SRR10444682:\n",
      "INFO:__main__:  v1_DLS_30ab2d97f4daa90793350e577030f12fb1adf2ab4147c36679765970edcfbf16.p3 (length: 117) - first found in SRR10444679\n",
      "INFO:__main__:  v1_DLS_6039dd6bf28b9eb4d97c7a230a0842c0b7a5af6c0bbf0dd8f25282d7c66dede7.p1 (length: 248) - first found in SRR10444680\n",
      "INFO:__main__:  v1_DLS_6039dd6bf28b9eb4d97c7a230a0842c0b7a5af6c0bbf0dd8f25282d7c66dede7.p2 (length: 216) - first found in SRR10444680\n",
      "INFO:__main__:  v1_DLS_6f7e503f0761df55de36800ed117d0dabc62f72ec5bb375a12a6dcb5ba9cf967.p1 (length: 597) - first found in SRR10444681\n",
      "INFO:__main__:  v1_DLS_7b209d26efcf188c97f7159321f1fea980e961a93bd0966df507f7e22b92d621.p1 (length: 160) - first found in SRR10444679\n",
      "INFO:__main__:\n",
      "Duplicates in SRR10444683:\n",
      "INFO:__main__:  v1_DLS_01b454b614476422e62d521b6b2d7344ca2389736a9bb003315b59145f9e20e1.p1 (length: 344) - first found in SRR10444682\n",
      "INFO:__main__:  v1_DLS_01b454b614476422e62d521b6b2d7344ca2389736a9bb003315b59145f9e20e1.p2 (length: 334) - first found in SRR10444682\n",
      "INFO:__main__:  v1_DLS_0377ebf3d0965fc11ae07efb7718b3021fd4fac25fa660c54ac39b3866bc592e.p1 (length: 235) - first found in SRR10444682\n",
      "INFO:__main__:  v1_DLS_052d968e5eb86d061a4a64581c5228ff6f3fcb3ec3d1eb058904616bd9d57472.p1 (length: 320) - first found in SRR10444682\n",
      "INFO:__main__:  v1_DLS_052d968e5eb86d061a4a64581c5228ff6f3fcb3ec3d1eb058904616bd9d57472.p2 (length: 192) - first found in SRR10444682\n",
      "INFO:__main__:\n",
      "Duplicates in SRR10444684:\n",
      "INFO:__main__:  v1_DLS_026c2e624183fe00a6f6e1589a62d2fe7227982d9bf55b0f904d301ebaff9b7c.p1 (length: 112) - first found in SRR10444683\n",
      "INFO:__main__:  v1_DLS_031b2280541b318daa2df1304d1a2485d7874293d5f2fc145465b0b414aabe34.p4 (length: 120) - first found in SRR10444682\n",
      "INFO:__main__:  v1_DLS_031b2280541b318daa2df1304d1a2485d7874293d5f2fc145465b0b414aabe34.p7 (length: 100) - first found in SRR10444682\n",
      "INFO:__main__:  v1_DLS_031b2280541b318daa2df1304d1a2485d7874293d5f2fc145465b0b414aabe34.p1 (length: 217) - first found in SRR10444682\n",
      "INFO:__main__:  v1_DLS_031b2280541b318daa2df1304d1a2485d7874293d5f2fc145465b0b414aabe34.p3 (length: 159) - first found in SRR10444682\n",
      "INFO:__main__:\n",
      "Duplicates in SRR11011256:\n",
      "INFO:__main__:  v1_DLS_1904f122baf96b824fd4f52643ba71854c904662d31d3896ca66c2732ce9bbb8.p1 (length: 621) - first found in SRR11011255\n",
      "INFO:__main__:  v1_DLS_20ff6523d54d6659478bdd6a527bdfc173b1d233238239a0dc07fe06c03ac3f8.p1 (length: 161) - first found in SRR11011255\n",
      "INFO:__main__:  v1_DLS_21ff3a7291d17645dc3072685875e83fb77f760ae7218bf9db021cd51c0dfa59.p1 (length: 195) - first found in SRR11011255\n",
      "INFO:__main__:  v1_DLS_2aa8716e2af29e377f76608a4c0a03c6b392f90723fa0d4dbce57ccc0f555eec.p1 (length: 342) - first found in SRR11011255\n",
      "INFO:__main__:  v1_DLS_3c0eee0779afcba59745edc722b9e5aa2201ea41a7dab61478073c3aeadf6f70.p1 (length: 573) - first found in SRR11011255\n",
      "INFO:__main__:\n",
      "Duplicates in SRR11011257:\n",
      "INFO:__main__:  v1_DLS_039cb1f8461d59ad465717c587795ca262174fae8615049a20b0233d9347f696.p2 (length: 138) - first found in SRR11011255\n",
      "INFO:__main__:  v1_DLS_1cce5b0b8ab7d2758aa6fb8d6c83cb658757ba3cf75ef2ca31651c6e0576cf5b.p1 (length: 154) - first found in SRR11011255\n",
      "INFO:__main__:  v1_DLS_73954990b0760053227956bb54a71961edbb4dfa028890e0f813ad999a6da723.p1 (length: 269) - first found in SRR11011256\n",
      "INFO:__main__:  v1_DLS_76c898b9313e804df23e747c949e703b8e193400aa378c191068b5a0b50390d5.p1 (length: 434) - first found in SRR11011256\n",
      "INFO:__main__:  v1_DLS_c1cfa31aca7e591ecdef16ba231b204e464598bee35021d610de9e88bd3fab70.p1 (length: 242) - first found in SRR11011255\n",
      "INFO:__main__:\n",
      "Duplicates in SRR11011258:\n",
      "INFO:__main__:  v1_DLS_17dc143b274f3c9273a6fc084e6608be4e885eb9a48d99b8338904c0c5b5807c.p1 (length: 577) - first found in SRR11011256\n",
      "INFO:__main__:  v1_DLS_2573e91ed386ba3728b233bd5fa63b9a05c375538fb93ffb8b570355322ac853.p1 (length: 309) - first found in SRR11011257\n",
      "INFO:__main__:  v1_DLS_33e7636a6188791f1c4d6825ab2661479f823d728277bc6b683308ef2fc25642.p1 (length: 176) - first found in SRR11011256\n",
      "INFO:__main__:  v1_DLS_4324f4a650e1a09681964e1310217c2c6aecbe22c94e929425881ef35bdbb8ba.p1 (length: 161) - first found in SRR11011257\n",
      "INFO:__main__:  v1_DLS_569615ac8a1bede5cc987d9fcd61030c6769d46c9bc43b3168cd0f7fcc2f9b87.p1 (length: 110) - first found in SRR11011257\n",
      "INFO:__main__:\n",
      "Duplicates in SRR11011259:\n",
      "INFO:__main__:  v1_DLS_02d104040979bad1a3471126faf8409807b1b6b67c897fb8b1b29dfe4a8f9c2b.p1 (length: 208) - first found in SRR11011256\n",
      "INFO:__main__:  v1_DLS_35061a8bff33378b28873a85b5b5896766cdb035b706d4ca8aecb5e434645cac.p1 (length: 155) - first found in SRR11011258\n",
      "INFO:__main__:  v1_DLS_3550bf5f98cffa55aee948cd8a1bb5e2402231b66d6cbd1b08e694d62e9cbf8d.p1 (length: 170) - first found in SRR11011258\n",
      "INFO:__main__:  v1_DLS_3b2a6af7436b7ff1d607d2eb3199cf23d1615833bfa3796bad8933f8a8a50438.p1 (length: 375) - first found in SRR11011255\n",
      "INFO:__main__:  v1_DLS_57703ffaf627bd3075b013db1cc13d42dc03135a9f9525cc0f5f19e181c6935e.p1 (length: 154) - first found in SRR11011255\n",
      "INFO:__main__:\n",
      "Duplicates in SRR11011260:\n",
      "INFO:__main__:  v1_DLS_06427a04a08b42ac8631e162b914323c406d5394b34b12776b7e8b86951fdf62.p1 (length: 374) - first found in SRR11011257\n",
      "INFO:__main__:  v1_DLS_1447dc46bd6234fe20fa953f9b4f890b48517c971ca0c3170026f31392c0ee83.p1 (length: 114) - first found in SRR11011259\n",
      "INFO:__main__:  v1_DLS_1c525e123a9ecfecc3a49c0431901158de9ac475e9c804a4df3d31fb552fab95.p1 (length: 103) - first found in SRR11011258\n",
      "INFO:__main__:  v1_DLS_2258f7e741d4b0f13a9a3a81b31dc3ba221495bcaa064e72bb4d305acab756bd.p1 (length: 102) - first found in SRR11011259\n",
      "INFO:__main__:  v1_DLS_5864773bec92d0948bd85302833afd7108894db11039bbfa807776f3031d6efa.p1 (length: 532) - first found in SRR11011258\n",
      "INFO:__main__:\n",
      "Duplicates in SRR128114:\n",
      "INFO:__main__:  v1_DLS_210f74741b33d52584e13e771bfde08260aa382b437a4aa44e1a5072284d658b.p1 (length: 237) - first found in SRR128113\n",
      "INFO:__main__:  v1_DLS_2223594a0d7ae1ffc0821831931cfd197ff35ee8adf301a3be4e7433a5a04843.p1 (length: 118) - first found in SRR128113\n",
      "INFO:__main__:  v1_DLS_607994b7eeeecacf5a000334bc052694db281470d3d4562c2d186c321ec0d20a.p1 (length: 158) - first found in SRR128113\n",
      "INFO:__main__:  v1_DLS_a52c69c4aabb3b81661b20b1aa9b338f04f89e371444cf2e743752b3eaa2c0fc.p1 (length: 133) - first found in SRR128113\n",
      "INFO:__main__:  v1_DLS_a8f6ec4858d10d1940d853474dd44408a712a91aa1e3056a4314e02e2a223f34.p1 (length: 110) - first found in SRR128113\n",
      "INFO:__main__:\n",
      "Duplicates in SRR14292008:\n",
      "INFO:__main__:  v1_DLS_0ef89a6a1fff73b4089edb96019eb3bf04da7bea9b451c503dd9904020525efe.p1 (length: 193) - first found in SRR14292007\n",
      "INFO:__main__:  v1_DLS_0ef89a6a1fff73b4089edb96019eb3bf04da7bea9b451c503dd9904020525efe.p3 (length: 116) - first found in SRR14292007\n",
      "INFO:__main__:  v1_DLS_11a6da79bd562868bb161794c3ad8f7f314b1a4655dca8a09c922675b0aaf2e6.p1 (length: 453) - first found in SRR14292007\n",
      "INFO:__main__:  v1_DLS_1a13b091b645af96424f874066bc908d9c071fd1ebab67cbce1114570f3a3030.p1 (length: 149) - first found in SRR14292007\n",
      "INFO:__main__:  v1_DLS_218960b6b48c3ad168776672ba8461a4175b78904ca792845d3c895a4b038e2d.p1 (length: 405) - first found in SRR14292007\n",
      "INFO:__main__:\n",
      "Duplicates in SRR18070779:\n",
      "INFO:__main__:  v1_DLS_31b64fb55994eda51b0633aeb25135f9d22215c95d9684bfff1219a6104e92f2.p1 (length: 434) - first found in SRR18070778\n",
      "INFO:__main__:  v1_DLS_4fd245352b8ebc7c2b04694234f8e901d781635b75f38102c3b2c4105c08de03.p1 (length: 185) - first found in SRR18070778\n",
      "INFO:__main__:  v1_DLS_64e9f42c4febd885163dc7bbab08a1edd3e50e584108b7432576c46b85217aa1.p1 (length: 228) - first found in SRR18070778\n",
      "INFO:__main__:  v1_DLS_6aa4a7d8fc80c6e08a749c4fa209624eecceb673e6c9494a16844b0807aa6e8c.p1 (length: 705) - first found in SRR18070778\n",
      "INFO:__main__:  v1_DLS_7732ae1a5061744dffe45b372bbf814d1deb4e0746d97b25691cb925c2345135.p1 (length: 357) - first found in SRR18070778\n",
      "INFO:__main__:\n",
      "Duplicates in SRR18070780:\n",
      "INFO:__main__:  v1_DLS_109a9ceff157eafb7f94c6b7ab6d9535fd5874de7dc45241bf091704ad057a29.p1 (length: 251) - first found in SRR18070779\n",
      "INFO:__main__:  v1_DLS_32b33d98065dc8428f6a1b0959bc2fa70f222a5c7f1bbb3a4d3b614cc4ba09d6.p1 (length: 416) - first found in SRR18070778\n",
      "INFO:__main__:  v1_DLS_4bf07f9aae2afce1c8f9f0ca1ef3179a424701fd01c014646bb96735d92f977d.p1 (length: 245) - first found in SRR18070779\n",
      "INFO:__main__:  v1_DLS_8303a22db85be951ef1420b3211bb02e8f816e54b882f73ef4cf197238285ffe.p1 (length: 332) - first found in SRR18070779\n",
      "INFO:__main__:  v1_DLS_9d1da8f85da2df12f3c97986c05ad69df90276362a2b3df5914acb21b44306b2.p1 (length: 401) - first found in SRR18070779\n",
      "INFO:__main__:\n",
      "Duplicates in SRR18070785:\n",
      "INFO:__main__:  v1_DLS_002688d1ea60f4bd1ddb2d6701f13f594f67eeb5f0c570c184b8287cb1cb13b3.p2 (length: 416) - first found in SRR18070784\n",
      "INFO:__main__:  v1_DLS_002688d1ea60f4bd1ddb2d6701f13f594f67eeb5f0c570c184b8287cb1cb13b3.p9 (length: 100) - first found in SRR18070784\n",
      "INFO:__main__:  v1_DLS_002688d1ea60f4bd1ddb2d6701f13f594f67eeb5f0c570c184b8287cb1cb13b3.p1 (length: 567) - first found in SRR18070784\n",
      "INFO:__main__:  v1_DLS_113ba8c06ec712748d3c00df6451b11ae8083d228f0e91adb47d53d01f4da1d1.p1 (length: 691) - first found in SRR18070784\n",
      "INFO:__main__:  v1_DLS_113ba8c06ec712748d3c00df6451b11ae8083d228f0e91adb47d53d01f4da1d1.p2 (length: 294) - first found in SRR18070784\n",
      "INFO:__main__:\n",
      "Duplicates in SRR18070786:\n",
      "INFO:__main__:  v1_DLS_017fbf3a4add63cff9f242a7626b03e3a2a29f9e4bb363596deb91da1246be3f.p1 (length: 218) - first found in SRR18070784\n",
      "INFO:__main__:  v1_DLS_03637dc84b61ec13bf4a1c9a3d39125d3f9c9744b0c29bc0f75a0caa12d45ee3.p2 (length: 249) - first found in SRR18070784\n",
      "INFO:__main__:  v1_DLS_03637dc84b61ec13bf4a1c9a3d39125d3f9c9744b0c29bc0f75a0caa12d45ee3.p1 (length: 398) - first found in SRR18070784\n",
      "INFO:__main__:  v1_DLS_07ce54c52bffdbadf634074024ece05a64d0ee518a0f7ff8feeb8304bf93a8d4.p1 (length: 220) - first found in SRR18070785\n",
      "INFO:__main__:  v1_DLS_098f5e996cd7abb219cb117a471281f5df6f5d4deeedc9214c9a3336aa81e026.p1 (length: 113) - first found in SRR18070785\n",
      "INFO:__main__:\n",
      "Duplicates in SRR18070787:\n",
      "INFO:__main__:  v1_DLS_0155e0f16c007171568c2aeb0af6ac474b64ef734e0e584efcaeac734ddc4c16.p1 (length: 100) - first found in SRR18070786\n",
      "INFO:__main__:  v1_DLS_04bdc62f832d01ad913b16f8263d4e54f646e2952c5bb3801116f237198d8967.p2 (length: 108) - first found in SRR18070786\n",
      "INFO:__main__:  v1_DLS_07b59e542970ca073c37af963245420c40ccbbd75eeac88f6854e288b3cfde5e.p2 (length: 249) - first found in SRR18070785\n",
      "INFO:__main__:  v1_DLS_07b59e542970ca073c37af963245420c40ccbbd75eeac88f6854e288b3cfde5e.p1 (length: 398) - first found in SRR18070785\n",
      "INFO:__main__:  v1_DLS_07ce54c52bffdbadf634074024ece05a64d0ee518a0f7ff8feeb8304bf93a8d4.p1 (length: 220) - first found in SRR18070785\n",
      "INFO:__main__:\n",
      "Duplicates in SRR18070788:\n",
      "INFO:__main__:  v1_DLS_08ef4b758a78395c4986fa653727a5afeb1ad02992fe4721b58a04a72e967db5.p1 (length: 159) - first found in SRR18070787\n",
      "INFO:__main__:  v1_DLS_0b3d16a29976359eccc73937437cff997fce6e0243bd138b4376cdbb17ccfef9.p2 (length: 153) - first found in SRR18070785\n",
      "INFO:__main__:  v1_DLS_0e62d7695a62d91196fe389ff7c6c94aecb14d69512dfb9fe086ad553fa8902f.p1 (length: 209) - first found in SRR18070784\n",
      "INFO:__main__:  v1_DLS_128d24c07f0b563357a058515bbe8443bf6c8ef9be5d0ba2c4a61b0e4d5ff015.p1 (length: 225) - first found in SRR18070787\n",
      "INFO:__main__:  v1_DLS_128d24c07f0b563357a058515bbe8443bf6c8ef9be5d0ba2c4a61b0e4d5ff015.p3 (length: 140) - first found in SRR18070787\n",
      "INFO:__main__:\n",
      "Duplicates in SRR18070789:\n",
      "INFO:__main__:  v1_DLS_11043e910f7897171a9a86741162b36b444935490133ab659a1bae1c30d30860.p1 (length: 146) - first found in SRR18070779\n",
      "INFO:__main__:  v1_DLS_158826012bbb774ad83b17937d6866d2bd34bc6bc868ea4164fa85395b89ac18.p1 (length: 319) - first found in SRR18070779\n",
      "INFO:__main__:  v1_DLS_158826012bbb774ad83b17937d6866d2bd34bc6bc868ea4164fa85395b89ac18.p2 (length: 279) - first found in SRR18070779\n",
      "INFO:__main__:  v1_DLS_176385416e1b558379d8213589ba016abad3ededde21a87b5aa650ead7184c22.p1 (length: 256) - first found in SRR18070779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sample_id  sequence_count  annotated_count  with_go_terms  \\\n",
      "0   ERR9123871           30281            27884          15140   \n",
      "1   ERR9123872           26342            24607          13512   \n",
      "2   ERR9123874           26649            25078          13739   \n",
      "3   ERR9123875           26224            24564          13484   \n",
      "4   ERR9123876           26284            24646          13704   \n",
      "..         ...             ...              ...            ...   \n",
      "72  SRR8859644           28264            20519           7207   \n",
      "73  SRR8859645           30587            22900           7348   \n",
      "74  SRR8859646           33480            25324           8405   \n",
      "75  SRR8859647           37443            28010           8949   \n",
      "76  SRR8859648           36454            26065           7777   \n",
      "\n",
      "    with_ec_numbers  \n",
      "0              6682  \n",
      "1              5928  \n",
      "2              5895  \n",
      "3              5794  \n",
      "4              5816  \n",
      "..              ...  \n",
      "72             4654  \n",
      "73             5363  \n",
      "74             5910  \n",
      "75             6572  \n",
      "76             6146  \n",
      "\n",
      "[77 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:  v1_DLS_1919cce724ee4c987d8dc305165aea1c1c3b8c5b12a098d6f61488f5a56c564c.p1 (length: 447) - first found in SRR18070778\n",
      "INFO:__main__:\n",
      "Duplicates in SRR18070792:\n",
      "INFO:__main__:  v1_DLS_b3de4ccd40f7c9c114f13325a2dac991da78f802172206504b474c78a5eb6f4e.p1 (length: 376) - first found in SRR18070788\n",
      "INFO:__main__:  v1_DLS_b3de4ccd40f7c9c114f13325a2dac991da78f802172206504b474c78a5eb6f4e.p2 (length: 223) - first found in SRR18070788\n",
      "INFO:__main__:\n",
      "Duplicates in SRR18070793:\n",
      "INFO:__main__:  v1_DLS_462287f58489fbe44cb3253b8b74862a0263d437f1923f423a26a422cc6ff27e.p1 (length: 152) - first found in SRR18070792\n",
      "INFO:__main__:\n",
      "Duplicates in SRR18070795:\n",
      "INFO:__main__:  v1_DLS_0f1ca3117ad468ad62699a5a098558e6d82cd6a3aa6a4612838bb39754ab87be.p1 (length: 174) - first found in SRR18070780\n",
      "INFO:__main__:  v1_DLS_0fdb65628bfa8522554ac09366e57489516ff767e64528de7fbd28bc127cf993.p1 (length: 272) - first found in SRR18070789\n",
      "INFO:__main__:  v1_DLS_1a7f26c561725c119d289fcfecea98d822410e95987fa8d98326d72aa14eeb04.p1 (length: 184) - first found in SRR18070789\n",
      "INFO:__main__:  v1_DLS_1ecbfdb97641e7b42568d3595f907b8533889d22f0c7b2291cf243e051b5af49.p1 (length: 706) - first found in SRR18070789\n",
      "INFO:__main__:  v1_DLS_28c2b91f77124c279d204a3d2a9896f8e700ca420af7af25224850a70e1a5b08.p1 (length: 331) - first found in SRR18070780\n",
      "INFO:__main__:\n",
      "Duplicates in SRR19034773:\n",
      "INFO:__main__:  v1_DLS_0437ef69284a4fa4ffa8ae56c9f5afda5f314bec8a2b21fb69cf52c0444dab86.p1 (length: 240) - first found in SRR19034772\n",
      "INFO:__main__:  v1_DLS_08739a172cdabb36649ea4fb0a241cbb224827bac559ec03b7e85f2cfe4ec913.p1 (length: 272) - first found in SRR19034772\n",
      "INFO:__main__:  v1_DLS_08ae774694aadbff2ec1bed64bad355dd45d11d474132910d28a4126bfe1d659.p3 (length: 161) - first found in SRR19034772\n",
      "INFO:__main__:  v1_DLS_08ae774694aadbff2ec1bed64bad355dd45d11d474132910d28a4126bfe1d659.p7 (length: 103) - first found in SRR19034772\n",
      "INFO:__main__:  v1_DLS_08ae774694aadbff2ec1bed64bad355dd45d11d474132910d28a4126bfe1d659.p4 (length: 152) - first found in SRR19034772\n",
      "INFO:__main__:\n",
      "Duplicates in SRR19619614:\n",
      "INFO:__main__:  v1_DLS_a1d10469e78fbebe9380f19d27669435e9fcae6b23d2338e15454fa8d8a4dec5.p41 (length: 169) - first found in SRR19619612\n",
      "INFO:__main__:  v1_DLS_a1d10469e78fbebe9380f19d27669435e9fcae6b23d2338e15454fa8d8a4dec5.p47 (length: 141) - first found in SRR19619612\n",
      "INFO:__main__:  v1_DLS_a1d10469e78fbebe9380f19d27669435e9fcae6b23d2338e15454fa8d8a4dec5.p36 (length: 200) - first found in SRR19619612\n",
      "INFO:__main__:  v1_DLS_a1d10469e78fbebe9380f19d27669435e9fcae6b23d2338e15454fa8d8a4dec5.p1 (length: 1183) - first found in SRR19619612\n",
      "INFO:__main__:  v1_DLS_a1d10469e78fbebe9380f19d27669435e9fcae6b23d2338e15454fa8d8a4dec5.p15 (length: 398) - first found in SRR19619612\n",
      "INFO:__main__:\n",
      "Duplicates in SRR22271586:\n",
      "INFO:__main__:  v1_DLS_11513857c4cfcbe5645113858a25d423d2ac2f5f07e11e164cf72dccd35faee4.p1 (length: 378) - first found in SRR22271585\n",
      "INFO:__main__:  v1_DLS_4abc44d23116377241074ff757d55ed036533a9f58c77ffae63f029c53b35296.p1 (length: 378) - first found in SRR22271585\n",
      "INFO:__main__:  v1_DLS_4f48be298c504ac63e1b72815031882cc58f8fb694d4a842b335063e1e0f21b0.p3 (length: 189) - first found in SRR22271585\n",
      "INFO:__main__:  v1_DLS_4f48be298c504ac63e1b72815031882cc58f8fb694d4a842b335063e1e0f21b0.p1 (length: 251) - first found in SRR22271585\n",
      "INFO:__main__:  v1_DLS_4f48be298c504ac63e1b72815031882cc58f8fb694d4a842b335063e1e0f21b0.p2 (length: 196) - first found in SRR22271585\n",
      "INFO:__main__:\n",
      "Duplicates in SRR22271587:\n",
      "INFO:__main__:  v1_DLS_06c9e46e7f020c466956fdbc769f45902687abe4809b70b48a4fd9cf2a9e9154.p1 (length: 272) - first found in SRR22271585\n",
      "INFO:__main__:  v1_DLS_12090a24921ab0701736cce11f89143161ab22da93c9d6526e5d334068e5f9ed.p2 (length: 240) - first found in SRR22271585\n",
      "INFO:__main__:  v1_DLS_12090a24921ab0701736cce11f89143161ab22da93c9d6526e5d334068e5f9ed.p1 (length: 441) - first found in SRR22271585\n",
      "INFO:__main__:  v1_DLS_1a2821d286f249307860851864591e281478fc6a6a6b68adeb76d97263609366.p4 (length: 106) - first found in SRR22271585\n",
      "INFO:__main__:  v1_DLS_1a2821d286f249307860851864591e281478fc6a6a6b68adeb76d97263609366.p1 (length: 338) - first found in SRR22271585\n",
      "INFO:__main__:\n",
      "Duplicates in SRR22271588:\n",
      "INFO:__main__:  v1_DLS_03d5c9352cdd7837c9313146a79d75cf3bb0f01b897964b01e126bff563e947e.p1 (length: 384) - first found in SRR22271587\n",
      "INFO:__main__:  v1_DLS_0666c0c7f72f6be52d02f4ab6063e00877ba8215c8d92e8294301ec55106d59f.p1 (length: 331) - first found in SRR22271585\n",
      "INFO:__main__:  v1_DLS_0666c0c7f72f6be52d02f4ab6063e00877ba8215c8d92e8294301ec55106d59f.p2 (length: 272) - first found in SRR22271585\n",
      "INFO:__main__:  v1_DLS_06c9e46e7f020c466956fdbc769f45902687abe4809b70b48a4fd9cf2a9e9154.p1 (length: 272) - first found in SRR22271585\n",
      "INFO:__main__:  v1_DLS_070d46c859d9a459342dea07d206f8347ae2a92eba259e918d949fbf7fa3aad1.p1 (length: 380) - first found in SRR22271585\n",
      "INFO:__main__:\n",
      "Duplicates in SRR22271589:\n",
      "INFO:__main__:  v1_DLS_00904fbb71f82b0581f00d10d07fe36f84bebb516ff8e63488b3fa5b24f98447.p1 (length: 350) - first found in SRR22271586\n",
      "INFO:__main__:  v1_DLS_03669ebff571da529147b4e491b03e79ef924c7fa6a73edf9c638659029017eb.p1 (length: 120) - first found in SRR22271586\n",
      "INFO:__main__:  v1_DLS_06772dd1850ad90e2400b05ffd4c07a8a9266066d3b62eef3555f13b4b677c9a.p1 (length: 488) - first found in SRR22271588\n",
      "INFO:__main__:  v1_DLS_06c9e46e7f020c466956fdbc769f45902687abe4809b70b48a4fd9cf2a9e9154.p1 (length: 272) - first found in SRR22271585\n",
      "INFO:__main__:  v1_DLS_07c65a16f513782076a8088c059fc3482b778e6c92919731fb2f76ef7027d65a.p1 (length: 562) - first found in SRR22271585\n",
      "INFO:__main__:\n",
      "Duplicates in SRR24974226:\n",
      "INFO:__main__:  v1_DLS_120e5e17e4d139bd54c20d0b00232433b6c6d55cef7596f37e1975aa6201fc17.p1 (length: 682) - first found in SRR24974225\n",
      "INFO:__main__:  v1_DLS_19ba1099e4b9423991cd571039cc4d9e9487b6779a9fd29f185b6fcac6756884.p1 (length: 315) - first found in SRR24974225\n",
      "INFO:__main__:  v1_DLS_70cef8e7ff3e965d587ed9c083e20db5fcbcd274772b1942358708d18210d19a.p1 (length: 392) - first found in SRR24974225\n",
      "INFO:__main__:  v1_DLS_a928e9ce14dbad9477e449fda5c950e6cd448b446e9ef948ee2fd6197e659843.p1 (length: 223) - first found in SRR24974225\n",
      "INFO:__main__:  v1_DLS_d3c415854d9da1c7c4f8f349a47498b9419d2e2ba692790406af927ee078b54f.p1 (length: 104) - first found in SRR24974225\n",
      "INFO:__main__:\n",
      "Duplicates in SRR24974227:\n",
      "INFO:__main__:  v1_DLS_16c0d7b7306f69c9298ea9863ab104261ca73c7c9a82b121e0c80b118fb70502.p1 (length: 623) - first found in SRR24974226\n",
      "INFO:__main__:  v1_DLS_2c332ab051bbad202553478cc49a14be0127ccaa371621e6939f77132a533277.p1 (length: 693) - first found in SRR24974225\n",
      "INFO:__main__:  v1_DLS_3f08a1ad2ceae4010354dba854f6405c7cf7007e62f2661d2e395e50a12536cc.p1 (length: 586) - first found in SRR24974225\n",
      "INFO:__main__:  v1_DLS_ac63c33328a5db04466e81f4afda5d5ac563fccb1c81f1f574879d85142088d8.p1 (length: 465) - first found in SRR24974226\n",
      "INFO:__main__:  v1_DLS_c0966322a1f919e5ca73e28248d759f23862b8a88aab2e3e3e7351e37c55c868.p1 (length: 210) - first found in SRR24974226\n",
      "INFO:__main__:\n",
      "Duplicates in SRR24974228:\n",
      "INFO:__main__:  v1_DLS_0b2aeb34222cc3a1fdce15216f33be84d34c6f2c2a0d2dab6ca5d3858f420d7e.p1 (length: 433) - first found in SRR24974227\n",
      "INFO:__main__:  v1_DLS_1fdd96b23bd463d65d8ceaa584901845269d3dde18cf821e1c80e02a86d9a711.p1 (length: 454) - first found in SRR24974225\n",
      "INFO:__main__:  v1_DLS_4673a6a2e1427ae8ba296763c153eb08f5d7ebc2c9e6675b973be22e2994b2bf.p2 (length: 105) - first found in SRR24974226\n",
      "INFO:__main__:  v1_DLS_6742677c1e815d789f95617e0c2ce5b7f2a717bc56e2b793ff7674d9e37bd224.p1 (length: 371) - first found in SRR24974225\n",
      "INFO:__main__:  v1_DLS_e48a432b96d00c550d2b1a32ecdd4176d827f3bbeabbcc73004a2d933cc02553.p1 (length: 195) - first found in SRR24974226\n",
      "INFO:__main__:\n",
      "Duplicates in SRR25582085:\n",
      "INFO:__main__:  v1_DLS_2d11b3ae742164bc89a84854bcea7ccc855dc3d075566231d7bb685469828813.p1 (length: 252) - first found in SRR24974228\n",
      "INFO:__main__:  v1_DLS_441765ccb23650452aff6e00e64a1ddfbafda31f05812d7a3bcadd7887ce818e.p1 (length: 272) - first found in SRR24974227\n",
      "INFO:__main__:  v1_DLS_6bcfe4bd79ce2776fbf04d3b3ed55f5be2c8c2dd5afb76073dee13fc933e8f09.p1 (length: 543) - first found in SRR24974227\n",
      "INFO:__main__:\n",
      "Duplicates in SRR29366266:\n",
      "INFO:__main__:  v1_DLS_a5bb9d9b2fb245639f4ff881433a222b02f4de7aed86e0d9deab79cb7392b8b7.p1 (length: 350) - first found in SRR29366264\n",
      "INFO:__main__:  v1_DLS_be79c04382ac1334ec49535fb1b1794656a3de4b7260348adee22a0ae8e6e8ff.p1 (length: 119) - first found in SRR29366265\n",
      "INFO:__main__:\n",
      "Duplicates in SRR8859644:\n",
      "INFO:__main__:  v1_DLS_1725506cf472c985a052f420e90bc6509c9987e1195cb20b9c06d6d5d75da46d.p3 (length: 110) - first found in SRR8859643\n",
      "INFO:__main__:  v1_DLS_1725506cf472c985a052f420e90bc6509c9987e1195cb20b9c06d6d5d75da46d.p1 (length: 276) - first found in SRR8859643\n",
      "INFO:__main__:  v1_DLS_192b9fa62d6fc57ef1c7c296d49a1ca046dc7e116817702df03091f95401e872.p1 (length: 347) - first found in SRR8859643\n",
      "INFO:__main__:  v1_DLS_1ddb12279ff0a56204d4bfb7ecb5f8f4e747677c46f6fe3407593ee09f161df8.p1 (length: 438) - first found in SRR8859643\n",
      "INFO:__main__:  v1_DLS_2943198632a393465ab7f88dbca5692f5b36913401422386fb85c002e01e506b.p1 (length: 629) - first found in SRR8859643\n",
      "INFO:__main__:\n",
      "Duplicates in SRR8859646:\n",
      "INFO:__main__:  v1_DLS_0a97641d6de7be1ace060f4a5e4380a357bec8c8a77e1afa67956b6e70556053.p1 (length: 156) - first found in SRR8859645\n",
      "INFO:__main__:  v1_DLS_33554fb69884a27b70c21a8368253f930676d4505751c6d60d87f3471ecb1f38.p1 (length: 777) - first found in SRR8859645\n",
      "INFO:__main__:  v1_DLS_33554fb69884a27b70c21a8368253f930676d4505751c6d60d87f3471ecb1f38.p2 (length: 323) - first found in SRR8859645\n",
      "INFO:__main__:  v1_DLS_47a15b655b8f4eaef87b35862983eb5d6edd505fe3fe5b7dbae0037799788216.p2 (length: 296) - first found in SRR8859645\n",
      "INFO:__main__:  v1_DLS_47a15b655b8f4eaef87b35862983eb5d6edd505fe3fe5b7dbae0037799788216.p1 (length: 399) - first found in SRR8859645\n",
      "INFO:__main__:\n",
      "Duplicates in SRR8859647:\n",
      "INFO:__main__:  v1_DLS_5e3582bbece820894e18cc19e98edbeaaaa20c5195fe8224d00b454056b76ea0.p1 (length: 100) - first found in SRR8859645\n",
      "INFO:__main__:  v1_DLS_62640764bfb2af2954ebfac87e949b271956cbafab751ee9a6fd7fb723a208c7.p2 (length: 457) - first found in SRR8859645\n",
      "INFO:__main__:  v1_DLS_62640764bfb2af2954ebfac87e949b271956cbafab751ee9a6fd7fb723a208c7.p1 (length: 465) - first found in SRR8859645\n",
      "INFO:__main__:  v1_DLS_7d45d360e5cde22ee872c4effd39b3de9fac99162083f32216441121cb6161ae.p1 (length: 101) - first found in SRR8859644\n",
      "INFO:__main__:  v1_DLS_7f5637d2d665ef8c94afa85662cbf1808293a5327122e739a70dc0a7255b9103.p1 (length: 583) - first found in SRR8859645\n",
      "INFO:__main__:\n",
      "Duplicates in SRR8859648:\n",
      "INFO:__main__:  v1_DLS_0b8362a240a202f40b4b59a043f3560b8d3478693d3e026d864e5628b047ca18.p1 (length: 761) - first found in SRR8859647\n",
      "INFO:__main__:  v1_DLS_0bc33017b5bb16c0b8405a8322ac3f0d7a66547081630db0d735c22778e55e00.p1 (length: 152) - first found in SRR8859647\n",
      "INFO:__main__:  v1_DLS_159d1cf29970b78993d00b0ead7bfb127ef502bb0da481d61b1d7a2797c760a6.p1 (length: 137) - first found in SRR8859647\n",
      "INFO:__main__:  v1_DLS_172d3e51ed5bf2db7ec2c8279459780090cb3aebb1c089d29271bc34d0c31921.p2 (length: 191) - first found in SRR8859647\n",
      "INFO:__main__:  v1_DLS_172d3e51ed5bf2db7ec2c8279459780090cb3aebb1c089d29271bc34d0c31921.p1 (length: 202) - first found in SRR8859647\n"
     ]
    }
   ],
   "source": [
    "base_dir = Path('/mnt/data2/planter_outputs')\n",
    "sample_list = [\n",
    "    'ERR9123871', 'ERR9123872', 'ERR9123874', 'ERR9123875', 'ERR9123876', \n",
    "    'ERR9123877', 'ERR9123878', 'ERR9123879', 'ERR9123880', 'ERR9123881', \n",
    "    'ERR9123882', 'SRR10444679', 'SRR10444680', 'SRR10444681', 'SRR10444682', \n",
    "    'SRR10444683', 'SRR10444684', 'SRR11011255', 'SRR11011256', 'SRR11011257', \n",
    "    'SRR11011258', 'SRR11011259', 'SRR11011260', 'SRR12068547', 'SRR128113', \n",
    "    'SRR128114', 'SRR13765006', 'SRR14292007', 'SRR14292008', 'SRR18070778', \n",
    "    'SRR18070779', 'SRR18070780', 'SRR18070781', 'SRR18070782', 'SRR18070783', \n",
    "    'SRR18070784', 'SRR18070785', 'SRR18070786', 'SRR18070787', 'SRR18070788', \n",
    "    'SRR18070789', 'SRR18070790', 'SRR18070791', 'SRR18070792', 'SRR18070793', \n",
    "    'SRR18070794', 'SRR18070795', 'SRR18735292', 'SRR19034772', 'SRR19034773', \n",
    "    'SRR19619612', 'SRR19619613', 'SRR19619614', 'SRR22271585', 'SRR22271586', \n",
    "    'SRR22271587', 'SRR22271588', 'SRR22271589', 'SRR22904707', 'SRR24974225', \n",
    "    'SRR24974226', 'SRR24974227', 'SRR24974228', 'SRR25582085', 'SRR29366264', \n",
    "    'SRR29366265', 'SRR29366266', 'SRR5489198', 'SRR5992919', 'SRR5992920', \n",
    "    'SRR6048009', 'SRR8859643', 'SRR8859644', 'SRR8859645', \n",
    "    'SRR8859646', 'SRR8859647', 'SRR8859648'\n",
    "]\n",
    "db_path = \"/mnt/data2/planter_outputs/planter.duckdb\"\n",
    "\n",
    "# Build initial database\n",
    "con = build_initial_database(db_path, base_dir, sample_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close the connection to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "from typing import List, Optional, Union\n",
    "import logging\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from typing import List, Optional, Union\n",
    "import logging\n",
    "\n",
    "class SequenceDB:\n",
    "    def __init__(self, db_path: str):\n",
    "        \"\"\"Initialize connection to the sequence database.\"\"\"\n",
    "        self.con = duckdb.connect(db_path)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def add_cluster_tables(self):\n",
    "        \"\"\"Add tables for storing cluster information if they don't exist.\"\"\"\n",
    "        schema_sql = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS clusters (\n",
    "            cluster_id VARCHAR PRIMARY KEY,\n",
    "            representative_seqhash_id VARCHAR NOT NULL,\n",
    "            size INTEGER NOT NULL,\n",
    "            FOREIGN KEY (representative_seqhash_id) REFERENCES sequences(seqhash_id)\n",
    "        );\n",
    "\n",
    "        CREATE TABLE IF NOT EXISTS cluster_members (\n",
    "            seqhash_id VARCHAR NOT NULL,\n",
    "            cluster_id VARCHAR NOT NULL,\n",
    "            PRIMARY KEY (seqhash_id),\n",
    "            FOREIGN KEY (seqhash_id) REFERENCES sequences(seqhash_id),\n",
    "            FOREIGN KEY (cluster_id) REFERENCES clusters(cluster_id)\n",
    "        );\n",
    "        \"\"\"\n",
    "        self.con.execute(schema_sql)\n",
    "    \n",
    "    def load_clusters_from_tsv(self, tsv_path: str):\n",
    "        \"\"\"\n",
    "        Load cluster information from MMseqs2 cluster update TSV file.\n",
    "        Expected format: representative_sequence\\tmember_sequence\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"Loading cluster data from {tsv_path}\")\n",
    "        \n",
    "        # Add cluster tables if they don't exist\n",
    "        self.add_cluster_tables()\n",
    "        \n",
    "        # Create temporary table for the TSV data\n",
    "        self.con.execute(\"\"\"\n",
    "        CREATE TEMP TABLE temp_clusters AS \n",
    "        SELECT \n",
    "            representative as representative_seqhash_id,\n",
    "            member as seqhash_id\n",
    "        FROM read_csv_auto(?, sep='\\t', header=False, \n",
    "                          names=['representative', 'member'])\n",
    "        \"\"\", [tsv_path])\n",
    "        \n",
    "        # Insert clusters and update sequence representatives\n",
    "        self.con.execute(\"\"\"\n",
    "        -- First, insert cluster information\n",
    "        WITH cluster_info AS (\n",
    "            SELECT \n",
    "                representative_seqhash_id,\n",
    "                ROW_NUMBER() OVER (ORDER BY representative_seqhash_id) as cluster_num,\n",
    "                COUNT(*) as size\n",
    "            FROM temp_clusters\n",
    "            GROUP BY representative_seqhash_id\n",
    "        )\n",
    "        INSERT INTO clusters (cluster_id, representative_seqhash_id, size)\n",
    "        SELECT \n",
    "            'CLUSTER_' || cluster_num as cluster_id,\n",
    "            representative_seqhash_id,\n",
    "            size\n",
    "        FROM cluster_info;\n",
    "\n",
    "        -- Then, insert cluster members\n",
    "        INSERT INTO cluster_members (seqhash_id, cluster_id)\n",
    "        SELECT \n",
    "            tc.seqhash_id,\n",
    "            c.cluster_id\n",
    "        FROM temp_clusters tc\n",
    "        JOIN clusters c ON tc.representative_seqhash_id = c.representative_seqhash_id;\n",
    "\n",
    "        -- Update representative status in sequences table\n",
    "        UPDATE sequences\n",
    "        SET is_representative = TRUE\n",
    "        WHERE seqhash_id IN (SELECT representative_seqhash_id FROM clusters);\n",
    "        \"\"\")\n",
    "        \n",
    "        # Clean up\n",
    "        self.con.execute(\"DROP TABLE temp_clusters\")\n",
    "        \n",
    "        # Log summary\n",
    "        cluster_stats = self.get_cluster_stats()\n",
    "        self.logger.info(\"\\nCluster loading complete:\")\n",
    "        self.logger.info(f\"Total clusters: {cluster_stats['total_clusters']}\")\n",
    "        self.logger.info(f\"Total clustered sequences: {cluster_stats['total_clustered_sequences']}\")\n",
    "        self.logger.info(f\"Average cluster size: {cluster_stats['avg_cluster_size']:.2f}\")\n",
    "    \n",
    "    def get_cluster_stats(self) -> dict:\n",
    "        \"\"\"Get summary statistics about clusters.\"\"\"\n",
    "        stats = self.con.execute(\"\"\"\n",
    "        SELECT \n",
    "            COUNT(DISTINCT cluster_id) as total_clusters,\n",
    "            COUNT(DISTINCT cm.seqhash_id) as total_clustered_sequences,\n",
    "            AVG(c.size) as avg_cluster_size,\n",
    "            MIN(c.size) as min_cluster_size,\n",
    "            MAX(c.size) as max_cluster_size\n",
    "        FROM clusters c\n",
    "        JOIN cluster_members cm ON c.cluster_id = cm.cluster_id\n",
    "        \"\"\").fetchone()\n",
    "        \n",
    "        return {\n",
    "            'total_clusters': stats[0],\n",
    "            'total_clustered_sequences': stats[1],\n",
    "            'avg_cluster_size': stats[2],\n",
    "            'min_cluster_size': stats[3],\n",
    "            'max_cluster_size': stats[4]\n",
    "        }\n",
    "    \n",
    "    def get_cluster_info(self, cluster_id: str) -> pd.DataFrame:\n",
    "        \"\"\"Get detailed information about a specific cluster.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            s.seqhash_id,\n",
    "            s.sample_id,\n",
    "            s.length,\n",
    "            s.is_representative,\n",
    "            a.description,\n",
    "            a.preferred_name,\n",
    "            STRING_AGG(DISTINCT g.go_term, '; ') as go_terms,\n",
    "            STRING_AGG(DISTINCT e.ec_number, '; ') as ec_numbers\n",
    "        FROM cluster_members cm\n",
    "        JOIN sequences s ON cm.seqhash_id = s.seqhash_id\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        LEFT JOIN go_terms g ON s.seqhash_id = g.seqhash_id\n",
    "        LEFT JOIN ec_numbers e ON s.seqhash_id = e.seqhash_id\n",
    "        WHERE cm.cluster_id = ?\n",
    "        GROUP BY s.seqhash_id, s.sample_id, s.length, s.is_representative,\n",
    "                 a.description, a.preferred_name\n",
    "        \"\"\"\n",
    "        return self.con.execute(query, [cluster_id]).fetchdf()\n",
    "    \n",
    "    def get_sequence_cluster(self, seqhash_id: str) -> pd.DataFrame:\n",
    "        \"\"\"Get cluster information for a specific sequence.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            c.cluster_id,\n",
    "            c.size as cluster_size,\n",
    "            c.representative_seqhash_id,\n",
    "            s.sample_id as representative_sample,\n",
    "            a.description as representative_description\n",
    "        FROM cluster_members cm\n",
    "        JOIN clusters c ON cm.cluster_id = c.cluster_id\n",
    "        JOIN sequences s ON c.representative_seqhash_id = s.seqhash_id\n",
    "        LEFT JOIN annotations a ON c.representative_seqhash_id = a.seqhash_id\n",
    "        WHERE cm.seqhash_id = ?\n",
    "        \"\"\"\n",
    "        return self.con.execute(query, [seqhash_id]).fetchdf()\n",
    "\n",
    "    def get_sequence_by_id(self, seqhash_id: str) -> dict:\n",
    "        \"\"\"Retrieve complete information for a specific sequence.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            s.*,\n",
    "            a.seed_ortholog,\n",
    "            a.evalue,\n",
    "            a.score,\n",
    "            a.eggnog_ogs,\n",
    "            a.description,\n",
    "            a.preferred_name,\n",
    "            a.cog_category,\n",
    "            STRING_AGG(DISTINCT g.go_term, '; ') as go_terms,\n",
    "            STRING_AGG(DISTINCT e.ec_number, '; ') as ec_numbers,\n",
    "            k.kegg_ko,\n",
    "            k.kegg_pathway,\n",
    "            k.kegg_module\n",
    "        FROM sequences s\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        LEFT JOIN go_terms g ON s.seqhash_id = g.seqhash_id\n",
    "        LEFT JOIN ec_numbers e ON s.seqhash_id = e.seqhash_id\n",
    "        LEFT JOIN kegg_info k ON s.seqhash_id = k.seqhash_id\n",
    "        WHERE s.seqhash_id = ?\n",
    "        GROUP BY s.seqhash_id, s.sequence, s.sample_id, s.assembly_date, \n",
    "                 s.is_representative, s.length, a.seed_ortholog, a.evalue, \n",
    "                 a.score, a.eggnog_ogs, a.description, a.preferred_name,\n",
    "                 a.cog_category, k.kegg_ko, k.kegg_pathway, k.kegg_module\n",
    "        \"\"\"\n",
    "        result = self.con.execute(query, [seqhash_id]).fetchdf()\n",
    "        return result.to_dict('records')[0] if not result.empty else None\n",
    "    \n",
    "    def search_sequences(self, \n",
    "                        sample_id: Optional[str] = None,\n",
    "                        min_length: Optional[int] = None,\n",
    "                        max_length: Optional[int] = None,\n",
    "                        has_annotation: Optional[bool] = None,\n",
    "                        description_contains: Optional[str] = None,\n",
    "                        go_term: Optional[str] = None,\n",
    "                        ec_number: Optional[str] = None,\n",
    "                        limit: int = 100) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Search sequences with multiple criteria.\n",
    "        Returns a DataFrame of matching sequences.\n",
    "        \"\"\"\n",
    "        conditions = [\"1=1\"]  # Always true condition to start\n",
    "        params = []\n",
    "        \n",
    "        if sample_id:\n",
    "            conditions.append(\"s.sample_id = ?\")\n",
    "            params.append(sample_id)\n",
    "            \n",
    "        if min_length:\n",
    "            conditions.append(\"s.length >= ?\")\n",
    "            params.append(min_length)\n",
    "            \n",
    "        if max_length:\n",
    "            conditions.append(\"s.length <= ?\")\n",
    "            params.append(max_length)\n",
    "            \n",
    "        if has_annotation is not None:\n",
    "            if has_annotation:\n",
    "                conditions.append(\"a.seqhash_id IS NOT NULL\")\n",
    "            else:\n",
    "                conditions.append(\"a.seqhash_id IS NULL\")\n",
    "                \n",
    "        if description_contains:\n",
    "            conditions.append(\"LOWER(a.description) LIKE ?\")\n",
    "            params.append(f\"%{description_contains.lower()}%\")\n",
    "            \n",
    "        if go_term:\n",
    "            conditions.append(\"EXISTS (SELECT 1 FROM go_terms g WHERE g.seqhash_id = s.seqhash_id AND g.go_term = ?)\")\n",
    "            params.append(go_term)\n",
    "            \n",
    "        if ec_number:\n",
    "            conditions.append(\"EXISTS (SELECT 1 FROM ec_numbers e WHERE e.seqhash_id = s.seqhash_id AND e.ec_number = ?)\")\n",
    "            params.append(ec_number)\n",
    "            \n",
    "        query = f\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            s.seqhash_id,\n",
    "            s.sample_id,\n",
    "            s.length,\n",
    "            s.is_representative,\n",
    "            a.description,\n",
    "            a.preferred_name,\n",
    "            a.cog_category\n",
    "        FROM sequences s\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        WHERE {' AND '.join(conditions)}\n",
    "        LIMIT ?\n",
    "        \"\"\"\n",
    "        params.append(limit)\n",
    "        \n",
    "        return self.con.execute(query, params).fetchdf()\n",
    "    \n",
    "    def get_sample_stats(self, sample_id: Optional[str] = None) -> pd.DataFrame:\n",
    "        \"\"\"Get statistics for all samples or a specific sample.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            s.sample_id,\n",
    "            COUNT(DISTINCT s.seqhash_id) as total_sequences,\n",
    "            AVG(s.length) as avg_length,\n",
    "            MIN(s.length) as min_length,\n",
    "            MAX(s.length) as max_length,\n",
    "            COUNT(DISTINCT a.seqhash_id) as annotated_sequences,\n",
    "            COUNT(DISTINCT g.seqhash_id) as sequences_with_go,\n",
    "            COUNT(DISTINCT e.seqhash_id) as sequences_with_ec\n",
    "        FROM sequences s\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        LEFT JOIN go_terms g ON s.seqhash_id = g.seqhash_id\n",
    "        LEFT JOIN ec_numbers e ON s.seqhash_id = e.seqhash_id\n",
    "        \"\"\"\n",
    "        if sample_id:\n",
    "            query += \" WHERE s.sample_id = ?\"\n",
    "            return self.con.execute(query + \" GROUP BY s.sample_id\", [sample_id]).fetchdf()\n",
    "        return self.con.execute(query + \" GROUP BY s.sample_id\").fetchdf()\n",
    "    \n",
    "    def get_go_term_summary(self, sample_id: Optional[str] = None, min_sequences: int = 5) -> pd.DataFrame:\n",
    "        \"\"\"Get summary of GO term frequencies.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            g.go_term,\n",
    "            COUNT(DISTINCT s.seqhash_id) as sequence_count\n",
    "        FROM sequences s\n",
    "        JOIN go_terms g ON s.seqhash_id = g.seqhash_id\n",
    "        \"\"\"\n",
    "        if sample_id:\n",
    "            query += \" WHERE s.sample_id = ?\"\n",
    "            params = [sample_id]\n",
    "        else:\n",
    "            params = []\n",
    "            \n",
    "        query += f\" GROUP BY g.go_term HAVING COUNT(DISTINCT s.seqhash_id) >= {min_sequences} ORDER BY sequence_count DESC\"\n",
    "        return self.con.execute(query, params).fetchdf()\n",
    "    \n",
    "    def get_ec_number_summary(self, sample_id: Optional[str] = None, min_sequences: int = 5) -> pd.DataFrame:\n",
    "        \"\"\"Get summary of EC number frequencies.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            e.ec_number,\n",
    "            COUNT(DISTINCT s.seqhash_id) as sequence_count\n",
    "        FROM sequences s\n",
    "        JOIN ec_numbers e ON s.seqhash_id = e.seqhash_id\n",
    "        \"\"\"\n",
    "        if sample_id:\n",
    "            query += \" WHERE s.sample_id = ?\"\n",
    "            params = [sample_id]\n",
    "        else:\n",
    "            params = []\n",
    "            \n",
    "        query += f\" GROUP BY e.ec_number HAVING COUNT(DISTINCT s.seqhash_id) >= {min_sequences} ORDER BY sequence_count DESC\"\n",
    "        return self.con.execute(query, params).fetchdf()\n",
    "        \n",
    "    def search_sequences(self, \n",
    "                        sample_id: Optional[str] = None,\n",
    "                        min_length: Optional[int] = None,\n",
    "                        max_length: Optional[int] = None,\n",
    "                        has_annotation: Optional[bool] = None,\n",
    "                        description_contains: Optional[str] = None,\n",
    "                        go_term: Optional[str] = None,\n",
    "                        ec_number: Optional[str] = None,\n",
    "                        is_representative: Optional[bool] = None,\n",
    "                        min_cluster_size: Optional[int] = None,\n",
    "                        limit: int = 100) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Search sequences with multiple criteria including cluster information.\n",
    "        Returns a DataFrame of matching sequences.\n",
    "        \"\"\"\n",
    "        conditions = [\"1=1\"]\n",
    "        params = []\n",
    "        \n",
    "        if sample_id:\n",
    "            conditions.append(\"s.sample_id = ?\")\n",
    "            params.append(sample_id)\n",
    "            \n",
    "        if min_length:\n",
    "            conditions.append(\"s.length >= ?\")\n",
    "            params.append(min_length)\n",
    "            \n",
    "        if max_length:\n",
    "            conditions.append(\"s.length <= ?\")\n",
    "            params.append(max_length)\n",
    "            \n",
    "        if has_annotation is not None:\n",
    "            if has_annotation:\n",
    "                conditions.append(\"a.seqhash_id IS NOT NULL\")\n",
    "            else:\n",
    "                conditions.append(\"a.seqhash_id IS NULL\")\n",
    "                \n",
    "        if description_contains:\n",
    "            conditions.append(\"LOWER(a.description) LIKE ?\")\n",
    "            params.append(f\"%{description_contains.lower()}%\")\n",
    "            \n",
    "        if go_term:\n",
    "            conditions.append(\"EXISTS (SELECT 1 FROM go_terms g WHERE g.seqhash_id = s.seqhash_id AND g.go_term = ?)\")\n",
    "            params.append(go_term)\n",
    "            \n",
    "        if ec_number:\n",
    "            conditions.append(\"EXISTS (SELECT 1 FROM ec_numbers e WHERE e.seqhash_id = s.seqhash_id AND e.ec_number = ?)\")\n",
    "            params.append(ec_number)\n",
    "            \n",
    "        if is_representative is not None:\n",
    "            conditions.append(\"s.is_representative = ?\")\n",
    "            params.append(is_representative)\n",
    "            \n",
    "        if min_cluster_size is not None:\n",
    "            conditions.append(\"\"\"\n",
    "                EXISTS (\n",
    "                    SELECT 1 FROM clusters c \n",
    "                    WHERE c.representative_seqhash_id = s.seqhash_id \n",
    "                    AND c.size >= ?\n",
    "                )\n",
    "            \"\"\")\n",
    "            params.append(min_cluster_size)\n",
    "            \n",
    "        query = f\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            s.seqhash_id,\n",
    "            s.sample_id,\n",
    "            s.length,\n",
    "            s.is_representative,\n",
    "            a.description,\n",
    "            a.preferred_name,\n",
    "            a.cog_category,\n",
    "            c.cluster_id,\n",
    "            c.size as cluster_size\n",
    "        FROM sequences s\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        LEFT JOIN cluster_members cm ON s.seqhash_id = cm.seqhash_id\n",
    "        LEFT JOIN clusters c ON cm.cluster_id = c.cluster_id\n",
    "        WHERE {' AND '.join(conditions)}\n",
    "        LIMIT ?\n",
    "        \"\"\"\n",
    "        params.append(limit)\n",
    "        \n",
    "        return self.con.execute(query, params).fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the database interface\n",
    "db_path = \"/mnt/data2/planter_outputs/planter.duckdb\"\n",
    "db = SequenceDB(db_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading cluster data from /mnt/data2/planter_outputs/repseq/update_SRR8859648/newClusterDB.tsv\n"
     ]
    },
    {
     "ename": "ConstraintException",
     "evalue": "Constraint Error: Violates foreign key constraint because key \"seqhash_id: v1_DLS_0004b18321ae94c2f6e95187309a28d05a8cb180c2123f332889dc8d3f246b82.p1\" does not exist in the referenced table",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConstraintException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load cluster information from MMseqs2 TSV file\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_clusters_from_tsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/mnt/data2/planter_outputs/repseq/update_SRR8859648/newClusterDB.tsv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Get overall cluster statistics\u001b[39;00m\n\u001b[1;32m      5\u001b[0m stats \u001b[38;5;241m=\u001b[39m db\u001b[38;5;241m.\u001b[39mget_cluster_stats()\n",
      "Cell \u001b[0;32mIn[8], line 58\u001b[0m, in \u001b[0;36mSequenceDB.load_clusters_from_tsv\u001b[0;34m(self, tsv_path)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcon\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124mCREATE TEMP TABLE temp_clusters AS \u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124mSELECT \u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124m                  names=[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepresentative\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmember\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m])\u001b[39m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m, [tsv_path])\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Insert clusters and update sequence representatives\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;43m-- First, insert cluster information\u001b[39;49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;43mWITH cluster_info AS (\u001b[39;49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;43m    SELECT \u001b[39;49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;43m        representative_seqhash_id,\u001b[39;49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;43m        ROW_NUMBER() OVER (ORDER BY representative_seqhash_id) as cluster_num,\u001b[39;49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;43m        COUNT(*) as size\u001b[39;49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;43m    FROM temp_clusters\u001b[39;49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;43m    GROUP BY representative_seqhash_id\u001b[39;49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;43m)\u001b[39;49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;43mINSERT INTO clusters (cluster_id, representative_seqhash_id, size)\u001b[39;49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;43mSELECT \u001b[39;49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCLUSTER_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m || cluster_num as cluster_id,\u001b[39;49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;43m    representative_seqhash_id,\u001b[39;49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;43m    size\u001b[39;49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;43mFROM cluster_info;\u001b[39;49m\n\u001b[1;32m     74\u001b[0m \n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;43m-- Then, insert cluster members\u001b[39;49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;43mINSERT INTO cluster_members (seqhash_id, cluster_id)\u001b[39;49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;43mSELECT \u001b[39;49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;43m    tc.seqhash_id,\u001b[39;49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;43m    c.cluster_id\u001b[39;49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;43mFROM temp_clusters tc\u001b[39;49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;43mJOIN clusters c ON tc.representative_seqhash_id = c.representative_seqhash_id;\u001b[39;49m\n\u001b[1;32m     82\u001b[0m \n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;43m-- Update representative status in sequences table\u001b[39;49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;43mUPDATE sequences\u001b[39;49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;43mSET is_representative = TRUE\u001b[39;49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;43mWHERE seqhash_id IN (SELECT representative_seqhash_id FROM clusters);\u001b[39;49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;43m\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Clean up\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcon\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDROP TABLE temp_clusters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mConstraintException\u001b[0m: Constraint Error: Violates foreign key constraint because key \"seqhash_id: v1_DLS_0004b18321ae94c2f6e95187309a28d05a8cb180c2123f332889dc8d3f246b82.p1\" does not exist in the referenced table"
     ]
    }
   ],
   "source": [
    "# Load cluster information from MMseqs2 TSV file\n",
    "db.load_clusters_from_tsv(\"/mnt/data2/planter_outputs/repseq/update_SRR8859648/newClusterDB.tsv\")\n",
    "\n",
    "# Get overall cluster statistics\n",
    "stats = db.get_cluster_stats()\n",
    "print(\"Cluster statistics:\", stats)\n",
    "\n",
    "# Get information about a specific cluster\n",
    "cluster_info = db.get_cluster_info(\"CLUSTER_1\")\n",
    "print(\"\\nCluster members:\", cluster_info)\n",
    "\n",
    "# Get cluster information for a specific sequence\n",
    "seq_cluster = db.get_sequence_cluster(\"your_sequence_id\")\n",
    "print(\"\\nSequence cluster info:\", seq_cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>total_sequences</th>\n",
       "      <th>avg_length</th>\n",
       "      <th>min_length</th>\n",
       "      <th>max_length</th>\n",
       "      <th>annotated_sequences</th>\n",
       "      <th>sequences_with_go</th>\n",
       "      <th>sequences_with_ec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ERR9123877</td>\n",
       "      <td>27560</td>\n",
       "      <td>451.145814</td>\n",
       "      <td>100</td>\n",
       "      <td>2762</td>\n",
       "      <td>25693</td>\n",
       "      <td>14075</td>\n",
       "      <td>6115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ERR9123879</td>\n",
       "      <td>28766</td>\n",
       "      <td>450.366135</td>\n",
       "      <td>100</td>\n",
       "      <td>3456</td>\n",
       "      <td>26726</td>\n",
       "      <td>14547</td>\n",
       "      <td>6364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRR10444683</td>\n",
       "      <td>23882</td>\n",
       "      <td>488.507425</td>\n",
       "      <td>100</td>\n",
       "      <td>4727</td>\n",
       "      <td>17507</td>\n",
       "      <td>7997</td>\n",
       "      <td>3915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRR11011260</td>\n",
       "      <td>41927</td>\n",
       "      <td>421.588747</td>\n",
       "      <td>100</td>\n",
       "      <td>5069</td>\n",
       "      <td>38566</td>\n",
       "      <td>21438</td>\n",
       "      <td>9320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRR128114</td>\n",
       "      <td>21608</td>\n",
       "      <td>291.993758</td>\n",
       "      <td>100</td>\n",
       "      <td>965</td>\n",
       "      <td>19342</td>\n",
       "      <td>11212</td>\n",
       "      <td>4915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>SRR29366265</td>\n",
       "      <td>33502</td>\n",
       "      <td>467.670111</td>\n",
       "      <td>100</td>\n",
       "      <td>4812</td>\n",
       "      <td>26471</td>\n",
       "      <td>8561</td>\n",
       "      <td>6567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>SRR22271586</td>\n",
       "      <td>19862</td>\n",
       "      <td>494.236919</td>\n",
       "      <td>100</td>\n",
       "      <td>2480</td>\n",
       "      <td>15637</td>\n",
       "      <td>6565</td>\n",
       "      <td>3245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>SRR18070789</td>\n",
       "      <td>9846</td>\n",
       "      <td>423.257129</td>\n",
       "      <td>100</td>\n",
       "      <td>2419</td>\n",
       "      <td>7541</td>\n",
       "      <td>3657</td>\n",
       "      <td>1763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>SRR8859648</td>\n",
       "      <td>36454</td>\n",
       "      <td>462.970037</td>\n",
       "      <td>100</td>\n",
       "      <td>5234</td>\n",
       "      <td>26065</td>\n",
       "      <td>7777</td>\n",
       "      <td>6146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>SRR8859647</td>\n",
       "      <td>37443</td>\n",
       "      <td>474.376303</td>\n",
       "      <td>100</td>\n",
       "      <td>5834</td>\n",
       "      <td>28010</td>\n",
       "      <td>8949</td>\n",
       "      <td>6572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sample_id  total_sequences  avg_length  min_length  max_length  \\\n",
       "0    ERR9123877            27560  451.145814         100        2762   \n",
       "1    ERR9123879            28766  450.366135         100        3456   \n",
       "2   SRR10444683            23882  488.507425         100        4727   \n",
       "3   SRR11011260            41927  421.588747         100        5069   \n",
       "4     SRR128114            21608  291.993758         100         965   \n",
       "..          ...              ...         ...         ...         ...   \n",
       "72  SRR29366265            33502  467.670111         100        4812   \n",
       "73  SRR22271586            19862  494.236919         100        2480   \n",
       "74  SRR18070789             9846  423.257129         100        2419   \n",
       "75   SRR8859648            36454  462.970037         100        5234   \n",
       "76   SRR8859647            37443  474.376303         100        5834   \n",
       "\n",
       "    annotated_sequences  sequences_with_go  sequences_with_ec  \n",
       "0                 25693              14075               6115  \n",
       "1                 26726              14547               6364  \n",
       "2                 17507               7997               3915  \n",
       "3                 38566              21438               9320  \n",
       "4                 19342              11212               4915  \n",
       "..                  ...                ...                ...  \n",
       "72                26471               8561               6567  \n",
       "73                15637               6565               3245  \n",
       "74                 7541               3657               1763  \n",
       "75                26065               7777               6146  \n",
       "76                28010               8949               6572  \n",
       "\n",
       "[77 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found sequences:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqhash_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>length</th>\n",
       "      <th>is_representative</th>\n",
       "      <th>description</th>\n",
       "      <th>preferred_name</th>\n",
       "      <th>cog_category</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>cluster_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v1_DLS_029cd8067614e2680843f522b1997df7afc9879...</td>\n",
       "      <td>SRR18070787</td>\n",
       "      <td>1947</td>\n",
       "      <td>False</td>\n",
       "      <td>Belongs to the PI3 PI4-kinase family</td>\n",
       "      <td>STT4</td>\n",
       "      <td>T</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v1_DLS_033a5e3a653914b9f212d9db0c0c9fc73b3a01e...</td>\n",
       "      <td>SRR18070787</td>\n",
       "      <td>209</td>\n",
       "      <td>False</td>\n",
       "      <td>Riboflavin kinase</td>\n",
       "      <td>FMN1</td>\n",
       "      <td>H</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v1_DLS_1275325847514a04bd06dfccf2490552cd5d8b6...</td>\n",
       "      <td>SRR18070787</td>\n",
       "      <td>658</td>\n",
       "      <td>False</td>\n",
       "      <td>Protein tyrosine kinase</td>\n",
       "      <td>ppk32</td>\n",
       "      <td>T</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v1_DLS_153edc097bff0caacc961a0830446d12c259b02...</td>\n",
       "      <td>SRR18070787</td>\n",
       "      <td>901</td>\n",
       "      <td>False</td>\n",
       "      <td>Protein tyrosine kinase</td>\n",
       "      <td>-</td>\n",
       "      <td>T</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v1_DLS_1caa68af96db857c54df23d36dd8050eac9d98a...</td>\n",
       "      <td>SRR18070787</td>\n",
       "      <td>455</td>\n",
       "      <td>False</td>\n",
       "      <td>Ribose-phosphate pyrophosphokinase</td>\n",
       "      <td>PRS5</td>\n",
       "      <td>EF</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>v1_DLS_1f563cbf008c905ac0478b0b1f3cfe6d08dabef...</td>\n",
       "      <td>SRR18070787</td>\n",
       "      <td>620</td>\n",
       "      <td>False</td>\n",
       "      <td>Protein kinase C conserved region 2 (CalB)</td>\n",
       "      <td>-</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>v1_DLS_2c62c833a7448c1d2f0b0e1964057cffc1bcdf6...</td>\n",
       "      <td>SRR18070787</td>\n",
       "      <td>341</td>\n",
       "      <td>False</td>\n",
       "      <td>Fructosamine kinase</td>\n",
       "      <td>-</td>\n",
       "      <td>G</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>v1_DLS_2eee5cce5a507d151d38c9cc0e66375659cee7c...</td>\n",
       "      <td>SRR18070787</td>\n",
       "      <td>358</td>\n",
       "      <td>False</td>\n",
       "      <td>Belongs to the phosphoglycerate kinase family</td>\n",
       "      <td>PGK1</td>\n",
       "      <td>G</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>v1_DLS_34b33903ac7116b0dc138f6837ed5d07f203368...</td>\n",
       "      <td>SRR18070787</td>\n",
       "      <td>1054</td>\n",
       "      <td>False</td>\n",
       "      <td>Serine threonine protein kinase</td>\n",
       "      <td>CDC5</td>\n",
       "      <td>D</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>v1_DLS_3e166aacd860ecdbefd1955179e994c879e4a87...</td>\n",
       "      <td>SRR18070787</td>\n",
       "      <td>437</td>\n",
       "      <td>False</td>\n",
       "      <td>Mitochondrial NADH kinase</td>\n",
       "      <td>POS5</td>\n",
       "      <td>G</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          seqhash_id    sample_id  length  \\\n",
       "0  v1_DLS_029cd8067614e2680843f522b1997df7afc9879...  SRR18070787    1947   \n",
       "1  v1_DLS_033a5e3a653914b9f212d9db0c0c9fc73b3a01e...  SRR18070787     209   \n",
       "2  v1_DLS_1275325847514a04bd06dfccf2490552cd5d8b6...  SRR18070787     658   \n",
       "3  v1_DLS_153edc097bff0caacc961a0830446d12c259b02...  SRR18070787     901   \n",
       "4  v1_DLS_1caa68af96db857c54df23d36dd8050eac9d98a...  SRR18070787     455   \n",
       "5  v1_DLS_1f563cbf008c905ac0478b0b1f3cfe6d08dabef...  SRR18070787     620   \n",
       "6  v1_DLS_2c62c833a7448c1d2f0b0e1964057cffc1bcdf6...  SRR18070787     341   \n",
       "7  v1_DLS_2eee5cce5a507d151d38c9cc0e66375659cee7c...  SRR18070787     358   \n",
       "8  v1_DLS_34b33903ac7116b0dc138f6837ed5d07f203368...  SRR18070787    1054   \n",
       "9  v1_DLS_3e166aacd860ecdbefd1955179e994c879e4a87...  SRR18070787     437   \n",
       "\n",
       "   is_representative                                    description  \\\n",
       "0              False           Belongs to the PI3 PI4-kinase family   \n",
       "1              False                              Riboflavin kinase   \n",
       "2              False                        Protein tyrosine kinase   \n",
       "3              False                        Protein tyrosine kinase   \n",
       "4              False             Ribose-phosphate pyrophosphokinase   \n",
       "5              False     Protein kinase C conserved region 2 (CalB)   \n",
       "6              False                            Fructosamine kinase   \n",
       "7              False  Belongs to the phosphoglycerate kinase family   \n",
       "8              False                Serine threonine protein kinase   \n",
       "9              False                      Mitochondrial NADH kinase   \n",
       "\n",
       "  preferred_name cog_category cluster_id  cluster_size  \n",
       "0           STT4            T       None           NaN  \n",
       "1           FMN1            H       None           NaN  \n",
       "2          ppk32            T       None           NaN  \n",
       "3              -            T       None           NaN  \n",
       "4           PRS5           EF       None           NaN  \n",
       "5              -            S       None           NaN  \n",
       "6              -            G       None           NaN  \n",
       "7           PGK1            G       None           NaN  \n",
       "8           CDC5            D       None           NaN  \n",
       "9           POS5            G       None           NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sequence details:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most common GO terms:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>go_term</th>\n",
       "      <th>sequence_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GO:0005575</td>\n",
       "      <td>709636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GO:0008150</td>\n",
       "      <td>708355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GO:0005623</td>\n",
       "      <td>697434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GO:0044464</td>\n",
       "      <td>697427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GO:0005622</td>\n",
       "      <td>650290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20993</th>\n",
       "      <td>GO:0098730</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20994</th>\n",
       "      <td>GO:0007147</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20995</th>\n",
       "      <td>GO:2000564</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20996</th>\n",
       "      <td>GO:0071623</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20997</th>\n",
       "      <td>GO:0001743</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20998 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          go_term  sequence_count\n",
       "0      GO:0005575          709636\n",
       "1      GO:0008150          708355\n",
       "2      GO:0005623          697434\n",
       "3      GO:0044464          697427\n",
       "4      GO:0005622          650290\n",
       "...           ...             ...\n",
       "20993  GO:0098730              10\n",
       "20994  GO:0007147              10\n",
       "20995  GO:2000564              10\n",
       "20996  GO:0071623              10\n",
       "20997  GO:0001743              10\n",
       "\n",
       "[20998 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Get statistics for all samples\n",
    "stats = db.get_sample_stats()\n",
    "print(\"Sample Statistics:\")\n",
    "display(stats)\n",
    "\n",
    "# Search for sequences with specific criteria\n",
    "results = db.search_sequences(\n",
    "    sample_id=\"SRR18070787\",\n",
    "    min_length=200,\n",
    "    description_contains=\"kinase\",\n",
    "    limit=10\n",
    ")\n",
    "print(\"\\nFound sequences:\")\n",
    "display(results)\n",
    "\n",
    "# Get detailed information for a specific sequence\n",
    "seq_info = db.get_sequence_by_id(\"v1_DLS_0004b18321ae94c2f6e95187309a28d05a8cb180c2123f332889dc8d3f246b82.p1\")\n",
    "print(\"\\nSequence details:\")\n",
    "display(seq_info)\n",
    "\n",
    "# Get GO term summary\n",
    "go_summary = db.get_go_term_summary(min_sequences=10)\n",
    "print(\"\\nMost common GO terms:\")\n",
    "display(go_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing sequences:\n",
      "                                          seqhash_id   status\n",
      "0  v1_DLS_cf6975b0be8ea4fd95c090f9d99c5b4c8c18405...  Missing\n",
      "1  v1_DLS_655c1d0533a8d838371bb7e39245f51a9990ef4...  Missing\n",
      "2  v1_DLS_33b8cc988ae22437a6340b3d956529161e7af32...  Missing\n",
      "3  v1_DLS_81eec195ff7c18e3da3515e7e28e778ce675851...  Missing\n",
      "4  v1_DLS_737fb5387adb86ef62214b690181129ff12c7f2...  Missing\n",
      "5  v1_DLS_cb2577ba4b9a0b63ed0c151b4cdd25eb1f8f393...  Missing\n",
      "6  v1_DLS_bb4a9733a2d0ab0010de0e80a82247d2a7229a9...  Missing\n",
      "7  v1_DLS_f42739564a917b895dc496b0868d35fa1ec40ba...  Missing\n",
      "8  v1_DLS_9beb6405a65587a82847554af33c3bd68a3decb...  Missing\n",
      "9  v1_DLS_aa46c90b09cda0e4414ae2ded24ecf33fd42b48...  Missing\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic query to check sequences\n",
    "tsv_path = \"/mnt/data2/planter_outputs/repseq/update_SRR8859648/newClusterDB.tsv\"\n",
    "missing_seqs = db.con.execute(\"\"\"\n",
    "WITH cluster_seqs AS (\n",
    "    SELECT representative as seqhash_id FROM read_csv_auto(?, sep='\\t', header=False, names=['representative', 'member'])\n",
    "    UNION\n",
    "    SELECT member FROM read_csv_auto(?, sep='\\t', header=False, names=['representative', 'member'])\n",
    ")\n",
    "SELECT \n",
    "    cs.seqhash_id,\n",
    "    CASE WHEN s.seqhash_id IS NULL THEN 'Missing' ELSE 'Present' END as status\n",
    "FROM cluster_seqs cs\n",
    "LEFT JOIN sequences s ON cs.seqhash_id = s.seqhash_id\n",
    "WHERE s.seqhash_id IS NULL\n",
    "LIMIT 10\n",
    "\"\"\", [tsv_path, tsv_path]).fetchdf()\n",
    "print(\"Missing sequences:\")\n",
    "print(missing_seqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from Bio import SeqIO\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize DuckDB\n",
    "db_path = \"demo_sequences.duckdb\"\n",
    "con = duckdb.connect(db_path)\n",
    "\n",
    "# First, let's verify our schema\n",
    "def print_schema():\n",
    "    \"\"\"Print the current schema of all tables\"\"\"\n",
    "    tables = con.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'main'\").df()\n",
    "    for table in tables['table_name']:\n",
    "        columns = con.execute(f\"SELECT * FROM information_schema.columns WHERE table_name = '{table}'\").df()\n",
    "        print(f\"\\nTable: {table}\")\n",
    "        print(columns[['column_name', 'data_type', 'is_nullable']])\n",
    "\n",
    "# Clean everything up first\n",
    "def clean_database():\n",
    "    \"\"\"Drop all existing tables\"\"\"\n",
    "    con.execute(\"DROP TABLE IF EXISTS cluster_members\")\n",
    "    con.execute(\"DROP TABLE IF EXISTS clusters\")\n",
    "    con.execute(\"DROP TABLE IF EXISTS sequences\")\n",
    "    con.execute(\"DROP TABLE IF EXISTS annotations\")\n",
    "    con.execute(\"DROP TABLE IF EXISTS go_terms\")\n",
    "    con.execute(\"DROP TABLE IF EXISTS ec_numbers\")\n",
    "    con.execute(\"DROP TABLE IF EXISTS kegg_info\")\n",
    "    con.execute(\"DROP TABLE IF EXISTS temp_clusters\")\n",
    "\n",
    "# Create schema\n",
    "schema_sql = \"\"\"\n",
    "CREATE TABLE sequences (\n",
    "    seqhash_id VARCHAR PRIMARY KEY,\n",
    "    sequence VARCHAR NOT NULL,\n",
    "    sra_id VARCHAR NOT NULL,\n",
    "    assembly_date TIMESTAMP NOT NULL,\n",
    "    is_representative BOOLEAN NOT NULL DEFAULT FALSE,\n",
    "    length INTEGER NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE clusters (\n",
    "    representative_seqhash VARCHAR PRIMARY KEY,\n",
    "    created_date TIMESTAMP NOT NULL,\n",
    "    member_count INTEGER NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE cluster_members (\n",
    "    representative_seqhash VARCHAR NOT NULL,\n",
    "    member_seqhash VARCHAR NOT NULL,\n",
    "    PRIMARY KEY (representative_seqhash, member_seqhash)\n",
    ");\n",
    "\n",
    "CREATE TABLE annotations (\n",
    "    seqhash_id VARCHAR PRIMARY KEY,\n",
    "    seed_ortholog VARCHAR,\n",
    "    evalue DOUBLE,\n",
    "    score DOUBLE,\n",
    "    eggnog_ogs VARCHAR,\n",
    "    max_annot_lvl VARCHAR,\n",
    "    cog_category VARCHAR,\n",
    "    description VARCHAR,\n",
    "    preferred_name VARCHAR\n",
    ");\n",
    "\n",
    "CREATE TABLE go_terms (\n",
    "    seqhash_id VARCHAR NOT NULL,\n",
    "    go_term VARCHAR NOT NULL,\n",
    "    PRIMARY KEY (seqhash_id, go_term)\n",
    ");\n",
    "\n",
    "CREATE TABLE ec_numbers (\n",
    "    seqhash_id VARCHAR NOT NULL,\n",
    "    ec_number VARCHAR NOT NULL,\n",
    "    PRIMARY KEY (seqhash_id, ec_number)\n",
    ");\n",
    "\n",
    "CREATE TABLE kegg_info (\n",
    "    seqhash_id VARCHAR NOT NULL,\n",
    "    kegg_ko VARCHAR,\n",
    "    kegg_pathway VARCHAR,\n",
    "    kegg_module VARCHAR,\n",
    "    kegg_reaction VARCHAR,\n",
    "    kegg_rclass VARCHAR,\n",
    "    PRIMARY KEY (seqhash_id)\n",
    ");\n",
    "\n",
    "-- Create indexes for common queries\n",
    "CREATE INDEX IF NOT EXISTS idx_sequences_sra ON sequences(sra_id);\n",
    "CREATE INDEX IF NOT EXISTS idx_annotations_cog ON annotations(cog_category);\n",
    "CREATE INDEX IF NOT EXISTS idx_go_terms ON go_terms(go_term);\n",
    "\"\"\"\n",
    "\n",
    "def init_database():\n",
    "    \"\"\"Initialize database with schema.\"\"\"\n",
    "    con.execute(schema_sql)\n",
    "    logger.info(\"Database initialized\")\n",
    "\n",
    "def load_sequences(fasta_path: str, sra_id: str):\n",
    "    \"\"\"Load sequences from FASTA file into database.\"\"\"\n",
    "    logger.info(f\"Loading sequences from {fasta_path}\")\n",
    "    \n",
    "    # Create a list to store sequence data\n",
    "    sequences = []\n",
    "    for record in SeqIO.parse(fasta_path, \"fasta\"):\n",
    "        seqhash_id = record.id.split()[0]  # Handle TransDecoder headers\n",
    "        sequences.append({\n",
    "            'seqhash_id': seqhash_id,\n",
    "            'sequence': str(record.seq),\n",
    "            'sra_id': sra_id,\n",
    "            'assembly_date': datetime.now(),\n",
    "            'is_representative': False,\n",
    "            'length': len(record.seq)\n",
    "        })\n",
    "        \n",
    "        if len(sequences) % 1000 == 0:\n",
    "            logger.info(f\"Read {len(sequences)} sequences...\")\n",
    "    \n",
    "    # Convert to DataFrame and load into DuckDB\n",
    "    df = pd.DataFrame(sequences)\n",
    "    con.execute(\"DELETE FROM sequences WHERE sra_id = ?\", [sra_id])\n",
    "    con.execute(\"INSERT INTO sequences SELECT * FROM df\")\n",
    "    \n",
    "    logger.info(f\"Successfully loaded {len(sequences)} sequences\")\n",
    "\n",
    "def load_annotations(annot_path: str):\n",
    "    \"\"\"Load eggNOG-mapper annotations into database.\"\"\"\n",
    "    logger.info(f\"Loading annotations from {annot_path}\")\n",
    "    \n",
    "    # Clean up any existing temporary tables first\n",
    "    logger.info(\"Cleaning up any existing temporary tables...\")\n",
    "    con.execute(\"DROP TABLE IF EXISTS temp_annotations\")\n",
    "    con.execute(\"DROP TABLE IF EXISTS temp_go\")\n",
    "    con.execute(\"DROP TABLE IF EXISTS temp_ec\")\n",
    "    \n",
    "    # Define the expected column names\n",
    "    column_names = [\n",
    "        'query', 'seed_ortholog', 'evalue', 'score', 'eggNOG_OGs', \n",
    "        'max_annot_lvl', 'COG_category', 'Description', 'Preferred_name',\n",
    "        'GOs', 'EC', 'KEGG_ko', 'KEGG_Pathway', 'KEGG_Module', \n",
    "        'KEGG_Reaction', 'KEGG_rclass', 'BRITE', 'KEGG_TC', 'CAZy',\n",
    "        'BiGG_Reaction', 'PFAMs'\n",
    "    ]\n",
    "    \n",
    "    # Create temporary table with defined columns\n",
    "    columns_def = \", \".join([f'\"{name}\" VARCHAR' for name in column_names])\n",
    "    con.execute(f\"\"\"\n",
    "        CREATE TABLE temp_annotations ({columns_def})\n",
    "    \"\"\")\n",
    "    \n",
    "    # Load data directly with column names\n",
    "    con.execute(f\"\"\"\n",
    "        INSERT INTO temp_annotations\n",
    "        SELECT * FROM read_csv_auto(\n",
    "            ?,\n",
    "            sep='\\t',\n",
    "            header=False,\n",
    "            comment='#',\n",
    "            names=[{','.join(f\"'{name}'\" for name in column_names)}]\n",
    "        )\n",
    "    \"\"\", [str(annot_path)])\n",
    "    \n",
    "    # Verify the data loading\n",
    "    count = con.execute(\"SELECT COUNT(*) FROM temp_annotations\").fetchone()[0]\n",
    "    logger.info(f\"Loaded {count} rows into temporary table\")\n",
    "    \n",
    "    # Let's look at a sample of the data\n",
    "    logger.info(\"Sample of loaded data:\")\n",
    "    sample = con.execute(\"SELECT * FROM temp_annotations LIMIT 3\").df()\n",
    "    logger.info(f\"\\n{sample}\")\n",
    "    \n",
    "    # Check for duplicate IDs\n",
    "    logger.info(\"Checking for duplicate IDs...\")\n",
    "    duplicates = con.execute(\"\"\"\n",
    "        SELECT query, COUNT(*) as count\n",
    "        FROM temp_annotations\n",
    "        GROUP BY query\n",
    "        HAVING COUNT(*) > 1\n",
    "    \"\"\").df()\n",
    "    \n",
    "    if not duplicates.empty:\n",
    "        logger.warning(f\"Found duplicate IDs:\\n{duplicates}\")\n",
    "    \n",
    "    try:\n",
    "        # Process main annotations\n",
    "        con.execute(\"\"\"\n",
    "            INSERT INTO annotations \n",
    "            SELECT DISTINCT\n",
    "                query as seqhash_id,\n",
    "                seed_ortholog,\n",
    "                TRY_CAST(evalue AS DOUBLE) as evalue,\n",
    "                TRY_CAST(score AS DOUBLE) as score,\n",
    "                \"eggNOG_OGs\" as eggnog_ogs,\n",
    "                max_annot_lvl,\n",
    "                \"COG_category\" as cog_category,\n",
    "                \"Description\" as description,\n",
    "                \"Preferred_name\" as preferred_name\n",
    "            FROM temp_annotations\n",
    "        \"\"\")\n",
    "        \n",
    "        annotation_count = con.execute(\"SELECT COUNT(*) FROM annotations\").fetchone()[0]\n",
    "        logger.info(f\"Inserted {annotation_count} annotations\")\n",
    "        \n",
    "        # Process GO terms\n",
    "        con.execute(\"\"\"\n",
    "            CREATE TABLE temp_go AS\n",
    "            SELECT \n",
    "                query as seqhash_id,\n",
    "                unnest(string_split(COALESCE(\"GOs\", ''), ',')) as go_term\n",
    "            FROM temp_annotations\n",
    "            WHERE \"GOs\" IS NOT NULL AND \"GOs\" != '' AND \"GOs\" != '-'\n",
    "        \"\"\")\n",
    "        \n",
    "        con.execute(\"\"\"\n",
    "            INSERT INTO go_terms\n",
    "            SELECT DISTINCT seqhash_id, trim(go_term)\n",
    "            FROM temp_go\n",
    "            WHERE trim(go_term) != ''\n",
    "        \"\"\")\n",
    "        \n",
    "        go_count = con.execute(\"SELECT COUNT(*) FROM go_terms\").fetchone()[0]\n",
    "        logger.info(f\"Loaded {go_count} GO term associations\")\n",
    "        \n",
    "        # Process EC numbers if present\n",
    "        con.execute(\"\"\"\n",
    "            CREATE TABLE temp_ec AS\n",
    "            SELECT \n",
    "                query as seqhash_id,\n",
    "                unnest(string_split(COALESCE(\"EC\", ''), ',')) as ec_number\n",
    "            FROM temp_annotations\n",
    "            WHERE \"EC\" IS NOT NULL AND \"EC\" != '' AND \"EC\" != '-'\n",
    "        \"\"\")\n",
    "        \n",
    "        con.execute(\"\"\"\n",
    "            INSERT INTO ec_numbers\n",
    "            SELECT DISTINCT seqhash_id, trim(ec_number)\n",
    "            FROM temp_ec\n",
    "            WHERE trim(ec_number) != ''\n",
    "        \"\"\")\n",
    "        \n",
    "        ec_count = con.execute(\"SELECT COUNT(*) FROM ec_numbers\").fetchone()[0]\n",
    "        logger.info(f\"Loaded {ec_count} EC number associations\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing annotations: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        # Clean up temporary tables\n",
    "        con.execute(\"DROP TABLE IF EXISTS temp_annotations\")\n",
    "        con.execute(\"DROP TABLE IF EXISTS temp_go\")\n",
    "        con.execute(\"DROP TABLE IF EXISTS temp_ec\")\n",
    "    \n",
    "    logger.info(\"Successfully completed annotation loading\")\n",
    "\n",
    "def load_clusters(cluster_path: str):\n",
    "    \"\"\"Load MMseqs clustering results into database.\"\"\"\n",
    "    logger.info(f\"Loading clusters from {cluster_path}\")\n",
    "    \n",
    "    # Clean up any existing temporary tables\n",
    "    con.execute(\"DROP TABLE IF EXISTS temp_clusters\")\n",
    "    \n",
    "    # Create temporary table\n",
    "    con.execute(\"\"\"\n",
    "        CREATE TABLE temp_clusters (\n",
    "            representative_seqhash VARCHAR,\n",
    "            member_seqhash VARCHAR\n",
    "        )\n",
    "    \"\"\")\n",
    "    \n",
    "    # Load clustering results\n",
    "    con.execute(\"\"\"\n",
    "        INSERT INTO temp_clusters\n",
    "        SELECT * FROM read_csv_auto(\n",
    "            ?,\n",
    "            sep='\\t',\n",
    "            header=False,\n",
    "            names=['representative_seqhash', 'member_seqhash']\n",
    "        )\n",
    "    \"\"\", [str(cluster_path)])\n",
    "    \n",
    "    try:\n",
    "        # Get count of loaded clusters\n",
    "        loaded_count = con.execute(\"\"\"\n",
    "            SELECT COUNT(DISTINCT representative_seqhash) \n",
    "            FROM temp_clusters\n",
    "        \"\"\").fetchone()[0]\n",
    "        logger.info(f\"Loaded {loaded_count} unique clusters\")\n",
    "        \n",
    "        # Create clusters with all required columns\n",
    "        con.execute(\"\"\"\n",
    "            INSERT INTO clusters (representative_seqhash, created_date, member_count)\n",
    "            SELECT \n",
    "                representative_seqhash,\n",
    "                CURRENT_TIMESTAMP,\n",
    "                COUNT(*) as member_count\n",
    "            FROM temp_clusters\n",
    "            GROUP BY representative_seqhash\n",
    "        \"\"\")\n",
    "        \n",
    "        # Add cluster members\n",
    "        con.execute(\"\"\"\n",
    "            INSERT INTO cluster_members (representative_seqhash, member_seqhash)\n",
    "            SELECT DISTINCT\n",
    "                representative_seqhash,\n",
    "                member_seqhash\n",
    "            FROM temp_clusters\n",
    "        \"\"\")\n",
    "        \n",
    "        # Mark representative sequences\n",
    "        con.execute(\"\"\"\n",
    "            UPDATE sequences\n",
    "            SET is_representative = FALSE\n",
    "        \"\"\")\n",
    "        \n",
    "        con.execute(\"\"\"\n",
    "            UPDATE sequences\n",
    "            SET is_representative = TRUE\n",
    "            WHERE seqhash_id IN (\n",
    "                SELECT DISTINCT representative_seqhash\n",
    "                FROM clusters\n",
    "            )\n",
    "        \"\"\")\n",
    "        \n",
    "        # Log statistics\n",
    "        cluster_count = con.execute(\"SELECT COUNT(*) FROM clusters\").fetchone()[0]\n",
    "        member_count = con.execute(\"SELECT COUNT(*) FROM cluster_members\").fetchone()[0]\n",
    "        rep_count = con.execute(\"SELECT COUNT(*) FROM sequences WHERE is_representative\").fetchone()[0]\n",
    "        \n",
    "        logger.info(f\"Loaded {cluster_count} clusters with {member_count} total members\")\n",
    "        logger.info(f\"Marked {rep_count} sequences as representatives\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing clusters: {e}\")\n",
    "        logger.error(\"Current schema:\")\n",
    "        print_schema()\n",
    "        raise\n",
    "    finally:\n",
    "        con.execute(\"DROP TABLE IF EXISTS temp_clusters\")\n",
    "    \n",
    "    logger.info(\"Successfully completed cluster loading\")\n",
    "\n",
    "# Function to get cluster members\n",
    "def get_cluster_members(representative_seqhash: str) -> pd.DataFrame:\n",
    "    \"\"\"Get detailed information about all members of a cluster.\"\"\"\n",
    "    return con.execute(\"\"\"\n",
    "        SELECT \n",
    "            s.seqhash_id,\n",
    "            s.length,\n",
    "            s.is_representative,\n",
    "            a.description,\n",
    "            a.cog_category,\n",
    "            c.member_count as total_cluster_size\n",
    "        FROM cluster_members cm\n",
    "        JOIN sequences s ON cm.member_seqhash = s.seqhash_id\n",
    "        JOIN clusters c ON cm.representative_seqhash = c.representative_seqhash\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        WHERE cm.representative_seqhash = ?\n",
    "        ORDER BY s.length DESC\n",
    "    \"\"\", [representative_seqhash]).df()\n",
    "\n",
    "# Function to get cluster statistics\n",
    "def get_cluster_stats():\n",
    "    \"\"\"Get summary statistics about clusters.\"\"\"\n",
    "    return con.execute(\"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total_clusters,\n",
    "            ROUND(AVG(member_count), 2) as avg_cluster_size,\n",
    "            MIN(member_count) as min_cluster_size,\n",
    "            MAX(member_count) as max_cluster_size,\n",
    "            COUNT(DISTINCT cm.member_seqhash) as total_members\n",
    "        FROM clusters c\n",
    "        JOIN cluster_members cm ON c.representative_seqhash = cm.representative_seqhash\n",
    "    \"\"\").df()\n",
    "\n",
    "# Example query functions\n",
    "def query_by_annotation(annotation_type: str, value: str) -> pd.DataFrame:\n",
    "    \"\"\"Query sequences by annotation criteria.\"\"\"\n",
    "    if annotation_type == \"cog\":\n",
    "        return con.execute(\"\"\"\n",
    "            SELECT s.seqhash_id, s.sequence, a.cog_category, a.description\n",
    "            FROM sequences s\n",
    "            JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "            WHERE a.cog_category = ?\n",
    "            AND s.is_representative = TRUE\n",
    "        \"\"\", [value]).df()\n",
    "    elif annotation_type == \"go\":\n",
    "        return con.execute(\"\"\"\n",
    "            SELECT DISTINCT s.seqhash_id, s.sequence, g.go_term\n",
    "            FROM sequences s\n",
    "            JOIN go_terms g ON s.seqhash_id = g.seqhash_id\n",
    "            WHERE g.go_term = ?\n",
    "            AND s.is_representative = TRUE\n",
    "        \"\"\", [value]).df()\n",
    "\n",
    "def get_cluster_members(representative_seqhash: str) -> pd.DataFrame:\n",
    "    \"\"\"Get all members of a cluster.\"\"\"\n",
    "    return con.execute(\"\"\"\n",
    "        SELECT s.*\n",
    "        FROM sequences s\n",
    "        JOIN cluster_members m ON s.seqhash_id = m.member_seqhash\n",
    "        JOIN clusters c ON m.cluster_id = c.cluster_id\n",
    "        WHERE c.representative_seqhash = ?\n",
    "    \"\"\", [representative_seqhash]).df()\n",
    "\n",
    "# Define the official COG mapping\n",
    "cog_mapping = {\n",
    "    'J': 'TRANSLATION, RIBOSOMAL STRUCTURE AND BIOGENESIS',\n",
    "    'A': 'RNA PROCESSING AND MODIFICATION',\n",
    "    'K': 'TRANSCRIPTION',\n",
    "    'L': 'REPLICATION, RECOMBINATION AND REPAIR',\n",
    "    'B': 'CHROMATIN STRUCTURE AND DYNAMICS',\n",
    "    'D': 'CELL CYCLE CONTROL, CELL DIVISION, CHROMOSOME PARTITIONING',\n",
    "    'Y': 'NUCLEAR STRUCTURE',\n",
    "    'V': 'DEFENSE MECHANISMS',\n",
    "    'T': 'SIGNAL TRANSDUCTION MECHANISMS',\n",
    "    'M': 'CELL WALL/MEMBRANE/ENVELOPE BIOGENESIS',\n",
    "    'N': 'CELL MOTILITY',\n",
    "    'Z': 'CYTOSKELETON',\n",
    "    'W': 'EXTRACELLULAR STRUCTURES',\n",
    "    'U': 'INTRACELLULAR TRAFFICKING, SECRETION, AND VESICULAR TRANSPORT',\n",
    "    'O': 'POSTTRANSLATIONAL MODIFICATION, PROTEIN TURNOVER, CHAPERONES',\n",
    "    'X': 'MOBILOME: PROPHAGES, TRANSPOSONS',\n",
    "    'C': 'ENERGY PRODUCTION AND CONVERSION',\n",
    "    'G': 'CARBOHYDRATE TRANSPORT AND METABOLISM',\n",
    "    'E': 'AMINO ACID TRANSPORT AND METABOLISM',\n",
    "    'F': 'NUCLEOTIDE TRANSPORT AND METABOLISM',\n",
    "    'H': 'COENZYME TRANSPORT AND METABOLISM',\n",
    "    'I': 'LIPID TRANSPORT AND METABOLISM',\n",
    "    'P': 'INORGANIC ION TRANSPORT AND METABOLISM',\n",
    "    'Q': 'SECONDARY METABOLITES BIOSYNTHESIS, TRANSPORT AND CATABOLISM',\n",
    "    'R': 'GENERAL FUNCTION PREDICTION ONLY',\n",
    "    'S': 'FUNCTION UNKNOWN'\n",
    "}\n",
    "\n",
    "def explore_cog_categories(include_descriptions=True):\n",
    "    \"\"\"\n",
    "    Analyze COG category distribution with support for multiple categories per sequence.\n",
    "    \n",
    "    Args:\n",
    "        include_descriptions: If True, includes full COG category descriptions\n",
    "    \"\"\"\n",
    "    logger.info(\"\\nAnalyzing COG category distribution...\")\n",
    "    \n",
    "    # Create temporary table with split COG categories\n",
    "    con.execute(\"DROP TABLE IF EXISTS temp_cog_categories\")\n",
    "    con.execute(\"\"\"\n",
    "        CREATE TABLE temp_cog_categories AS\n",
    "        WITH RECURSIVE chars AS (\n",
    "            SELECT \n",
    "                seqhash_id,\n",
    "                cog_category,\n",
    "                1 as position\n",
    "            FROM annotations\n",
    "            WHERE cog_category IS NOT NULL\n",
    "            \n",
    "            UNION ALL\n",
    "            \n",
    "            SELECT \n",
    "                seqhash_id,\n",
    "                cog_category,\n",
    "                position + 1\n",
    "            FROM chars\n",
    "            WHERE position < LENGTH(cog_category)\n",
    "        )\n",
    "        SELECT \n",
    "            seqhash_id,\n",
    "            SUBSTRING(cog_category, position, 1) as single_cog\n",
    "        FROM chars\n",
    "        WHERE SUBSTRING(cog_category, position, 1) != ''\n",
    "          AND SUBSTRING(cog_category, position, 1) != '-'\n",
    "    \"\"\")\n",
    "    \n",
    "    # Get basic distribution\n",
    "    cog_stats = con.execute(\"\"\"\n",
    "        WITH cog_counts AS (\n",
    "            SELECT \n",
    "                single_cog as cog_category,\n",
    "                COUNT(DISTINCT c.seqhash_id) as sequence_count,\n",
    "                COUNT(DISTINCT CASE WHEN s.is_representative THEN s.seqhash_id END) as representative_count,\n",
    "                COUNT(DISTINCT cl.cluster_id) as cluster_count\n",
    "            FROM temp_cog_categories c\n",
    "            JOIN sequences s ON c.seqhash_id = s.seqhash_id\n",
    "            LEFT JOIN clusters cl ON s.seqhash_id = cl.representative_seqhash\n",
    "            GROUP BY single_cog\n",
    "        )\n",
    "        SELECT \n",
    "            cog_category,\n",
    "            sequence_count,\n",
    "            representative_count,\n",
    "            cluster_count,\n",
    "            ROUND(sequence_count * 100.0 / (SELECT COUNT(DISTINCT seqhash_id) FROM annotations WHERE cog_category IS NOT NULL), 2) as percentage\n",
    "        FROM cog_counts\n",
    "        ORDER BY sequence_count DESC\n",
    "    \"\"\").df()\n",
    "    \n",
    "    # Add descriptions if requested\n",
    "    if include_descriptions:\n",
    "        cog_stats['description'] = cog_stats['cog_category'].map(cog_mapping)\n",
    "    \n",
    "    con.execute(\"DROP TABLE IF EXISTS temp_cog_categories\")\n",
    "    \n",
    "    return cog_stats\n",
    "\n",
    "def analyze_cog_combinations(top_n=20):\n",
    "    \"\"\"\n",
    "    Analyze common combinations of COG categories.\n",
    "    \n",
    "    Args:\n",
    "        top_n: Number of top combinations to return\n",
    "    \"\"\"\n",
    "    logger.info(\"\\nAnalyzing COG category combinations...\")\n",
    "    \n",
    "    combos = con.execute(\"\"\"\n",
    "        SELECT \n",
    "            a.cog_category,\n",
    "            COUNT(*) as frequency,\n",
    "            ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM annotations WHERE cog_category IS NOT NULL), 2) as percentage,\n",
    "            STRING_AGG(DISTINCT s.seqhash_id, ',' LIMIT 3) as example_sequences\n",
    "        FROM annotations a\n",
    "        JOIN sequences s ON a.seqhash_id = s.seqhash_id\n",
    "        WHERE a.cog_category IS NOT NULL\n",
    "        GROUP BY a.cog_category\n",
    "        HAVING LENGTH(a.cog_category) > 1\n",
    "        ORDER BY frequency DESC\n",
    "        LIMIT ?\n",
    "    \"\"\", [top_n]).df()\n",
    "    \n",
    "    # Add decoded combinations\n",
    "    def decode_combination(combo):\n",
    "        return \" + \".join([f\"{c} ({cog_mapping.get(c, 'Unknown')})\" for c in combo])\n",
    "    \n",
    "    combos['decoded_combination'] = combos['cog_category'].apply(decode_combination)\n",
    "    \n",
    "    return combos\n",
    "\n",
    "def get_cog_category_summary():\n",
    "    \"\"\"Get summary statistics about COG categories.\"\"\"\n",
    "    summary = con.execute(\"\"\"\n",
    "        SELECT \n",
    "            COUNT(DISTINCT seqhash_id) as total_annotated_sequences,\n",
    "            COUNT(DISTINCT CASE WHEN LENGTH(cog_category) > 1 THEN seqhash_id END) as multi_cog_sequences,\n",
    "            ROUND(AVG(LENGTH(cog_category)), 2) as avg_cogs_per_sequence,\n",
    "            COUNT(DISTINCT cog_category) as unique_combinations\n",
    "        FROM annotations \n",
    "        WHERE cog_category IS NOT NULL\n",
    "    \"\"\").df()\n",
    "    \n",
    "    # Add category counts by functional group\n",
    "    metabolism_cogs = ['C', 'G', 'E', 'F', 'H', 'I', 'P', 'Q']\n",
    "    information_cogs = ['J', 'A', 'K', 'L', 'B']\n",
    "    cellular_cogs = ['D', 'Y', 'V', 'T', 'M', 'N', 'Z', 'W', 'U', 'O']\n",
    "    poorly_characterized = ['R', 'S']\n",
    "    \n",
    "    category_counts = con.execute(\"\"\"\n",
    "        WITH RECURSIVE chars AS (\n",
    "            SELECT seqhash_id, cog_category, 1 as position\n",
    "            FROM annotations\n",
    "            WHERE cog_category IS NOT NULL\n",
    "            \n",
    "            UNION ALL\n",
    "            \n",
    "            SELECT seqhash_id, cog_category, position + 1\n",
    "            FROM chars\n",
    "            WHERE position < LENGTH(cog_category)\n",
    "        )\n",
    "        SELECT \n",
    "            SUBSTRING(cog_category, position, 1) as single_cog,\n",
    "            COUNT(DISTINCT seqhash_id) as seq_count\n",
    "        FROM chars\n",
    "        WHERE SUBSTRING(cog_category, position, 1) != ''\n",
    "          AND SUBSTRING(cog_category, position, 1) != '-'\n",
    "        GROUP BY SUBSTRING(cog_category, position, 1)\n",
    "    \"\"\").df()\n",
    "    \n",
    "    # Calculate counts for each functional group\n",
    "    metabolism_count = category_counts[category_counts['single_cog'].isin(metabolism_cogs)]['seq_count'].sum()\n",
    "    information_count = category_counts[category_counts['single_cog'].isin(information_cogs)]['seq_count'].sum()\n",
    "    cellular_count = category_counts[category_counts['single_cog'].isin(cellular_cogs)]['seq_count'].sum()\n",
    "    poorly_characterized_count = category_counts[category_counts['single_cog'].isin(poorly_characterized)]['seq_count'].sum()\n",
    "    \n",
    "    functional_groups = pd.DataFrame({\n",
    "        'functional_group': ['Metabolism', 'Information Storage and Processing', \n",
    "                           'Cellular Processes and Signaling', 'Poorly Characterized'],\n",
    "        'sequence_count': [metabolism_count, information_count, \n",
    "                         cellular_count, poorly_characterized_count]\n",
    "    })\n",
    "    \n",
    "    return summary, functional_groups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7be9d5e6cbb0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7be9d5e6cbb0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7be9d5e6cbb0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7be9d5e6cbb0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7be9d5e6cbb0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading sequences from /mnt/data2/planter_outputs/SRR14292008/transdecoder/SRR14292008.pep\n",
      "INFO:__main__:Read 1000 sequences...\n",
      "INFO:__main__:Read 2000 sequences...\n",
      "INFO:__main__:Read 3000 sequences...\n",
      "INFO:__main__:Read 4000 sequences...\n",
      "INFO:__main__:Read 5000 sequences...\n",
      "INFO:__main__:Read 6000 sequences...\n",
      "INFO:__main__:Read 7000 sequences...\n",
      "INFO:__main__:Read 8000 sequences...\n",
      "INFO:__main__:Read 9000 sequences...\n",
      "INFO:__main__:Read 10000 sequences...\n",
      "INFO:__main__:Read 11000 sequences...\n",
      "INFO:__main__:Read 12000 sequences...\n",
      "INFO:__main__:Read 13000 sequences...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial schema:\n",
      "\n",
      "Table: annotations\n",
      "      column_name data_type is_nullable\n",
      "0      seqhash_id   VARCHAR          NO\n",
      "1   seed_ortholog   VARCHAR         YES\n",
      "2          evalue    DOUBLE         YES\n",
      "3           score    DOUBLE         YES\n",
      "4      eggnog_ogs   VARCHAR         YES\n",
      "5   max_annot_lvl   VARCHAR         YES\n",
      "6    cog_category   VARCHAR         YES\n",
      "7     description   VARCHAR         YES\n",
      "8  preferred_name   VARCHAR         YES\n",
      "\n",
      "Table: clusters\n",
      "              column_name  data_type is_nullable\n",
      "0  representative_seqhash    VARCHAR          NO\n",
      "1            created_date  TIMESTAMP          NO\n",
      "2            member_count    INTEGER          NO\n",
      "\n",
      "Table: cluster_members\n",
      "              column_name data_type is_nullable\n",
      "0  representative_seqhash   VARCHAR          NO\n",
      "1          member_seqhash   VARCHAR          NO\n",
      "\n",
      "Table: ec_numbers\n",
      "  column_name data_type is_nullable\n",
      "0  seqhash_id   VARCHAR          NO\n",
      "1   ec_number   VARCHAR          NO\n",
      "\n",
      "Table: go_terms\n",
      "  column_name data_type is_nullable\n",
      "0  seqhash_id   VARCHAR          NO\n",
      "1     go_term   VARCHAR          NO\n",
      "\n",
      "Table: kegg_info\n",
      "     column_name data_type is_nullable\n",
      "0     seqhash_id   VARCHAR          NO\n",
      "1        kegg_ko   VARCHAR         YES\n",
      "2   kegg_pathway   VARCHAR         YES\n",
      "3    kegg_module   VARCHAR         YES\n",
      "4  kegg_reaction   VARCHAR         YES\n",
      "5    kegg_rclass   VARCHAR         YES\n",
      "\n",
      "Table: sequences\n",
      "         column_name  data_type is_nullable\n",
      "0         seqhash_id    VARCHAR          NO\n",
      "1           sequence    VARCHAR          NO\n",
      "2             sra_id    VARCHAR          NO\n",
      "3      assembly_date  TIMESTAMP          NO\n",
      "4  is_representative    BOOLEAN          NO\n",
      "5             length    INTEGER          NO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Read 14000 sequences...\n",
      "INFO:__main__:Read 15000 sequences...\n",
      "INFO:__main__:Read 16000 sequences...\n",
      "INFO:__main__:Read 17000 sequences...\n",
      "INFO:__main__:Successfully loaded 17947 sequences\n",
      "INFO:__main__:Loading annotations from /mnt/data2/planter_outputs/SRR14292008/eggnog/SRR14292008.emapper.annotations\n",
      "INFO:__main__:Cleaning up any existing temporary tables...\n",
      "INFO:__main__:Loaded 14337 rows into temporary table\n",
      "INFO:__main__:Sample of loaded data:\n",
      "INFO:__main__:\n",
      "                                               query          seed_ortholog  \\\n",
      "0  v1_DLS_00048542b2614e34db583d1e78f0cd5d7895791...  310453.XP_007587614.1   \n",
      "1  v1_DLS_00048542b2614e34db583d1e78f0cd5d7895791...  698440.XP_007289890.1   \n",
      "2  v1_DLS_00048542b2614e34db583d1e78f0cd5d7895791...   93612.XP_008025513.1   \n",
      "\n",
      "      evalue  score                                         eggNOG_OGs  \\\n",
      "0   1.32e-88  263.0  COG0636@1|root,KOG0233@2759|Eukaryota,38C5K@33...   \n",
      "1  3.02e-155  459.0  COG0303@1|root,KOG2371@2759|Eukaryota,38FK6@33...   \n",
      "2    6.5e-70  230.0  COG0303@1|root,KOG2371@2759|Eukaryota,38FK6@33...   \n",
      "\n",
      "  max_annot_lvl COG_category  \\\n",
      "0    4751|Fungi            P   \n",
      "1    4751|Fungi            H   \n",
      "2    4751|Fungi            H   \n",
      "\n",
      "                                         Description Preferred_name  \\\n",
      "0  Belongs to the V-ATPase proteolipid subunit fa...          vma16   \n",
      "1           MoeA N-terminal region (domain I and II)              -   \n",
      "2  Belongs to the V-ATPase proteolipid subunit fa...              -   \n",
      "\n",
      "                                                 GOs  ...  \\\n",
      "0  GO:0000220,GO:0000322,GO:0000323,GO:0000324,GO...  ...   \n",
      "1                                                  -  ...   \n",
      "2                                                  -  ...   \n",
      "\n",
      "               KEGG_ko                                       KEGG_Pathway  \\\n",
      "0            ko:K03661  ko00190,ko01100,ko04142,ko04145,ko04721,ko0511...   \n",
      "1  ko:K03750,ko:K15376  ko00790,ko01100,ko04727,map00790,map01100,map0...   \n",
      "2  ko:K03750,ko:K15376  ko00790,ko01100,ko04727,map00790,map01100,map0...   \n",
      "\n",
      "  KEGG_Module  KEGG_Reaction      KEGG_rclass                    BRITE  \\\n",
      "0      M00160              -                -  ko00000,ko00001,ko00002   \n",
      "1           -  R09726,R09735  RC00002,RC03462  ko00000,ko00001,ko01000   \n",
      "2           -  R09726,R09735  RC00002,RC03462  ko00000,ko00001,ko01000   \n",
      "\n",
      "   KEGG_TC CAZy BiGG_Reaction                        PFAMs  \n",
      "0  3.A.2.2    -             -                   ATP-synt_C  \n",
      "1        -    -             -  MoCF_biosynth,MoeA_C,MoeA_N  \n",
      "2        -    -             -  MoCF_biosynth,MoeA_C,MoeA_N  \n",
      "\n",
      "[3 rows x 21 columns]\n",
      "INFO:__main__:Checking for duplicate IDs...\n",
      "INFO:__main__:Inserted 14337 annotations\n",
      "INFO:__main__:Loaded 544969 GO term associations\n",
      "INFO:__main__:Loaded 3423 EC number associations\n",
      "INFO:__main__:Successfully completed annotation loading\n",
      "INFO:__main__:Loading clusters from /mnt/data2/planter_outputs/repseq/update_SRR14292008/newClusterDB.tsv\n",
      "INFO:__main__:Loaded 77779 unique clusters\n",
      "INFO:__main__:Loaded 77779 clusters with 95346 total members\n",
      "INFO:__main__:Marked 386 sequences as representatives\n",
      "INFO:__main__:Successfully completed cluster loading\n"
     ]
    }
   ],
   "source": [
    "# Reset our tables before loading\n",
    "con.execute(\"DROP TABLE IF EXISTS annotations\")\n",
    "con.execute(\"DROP TABLE IF EXISTS go_terms\")\n",
    "con.execute(\"DROP TABLE IF EXISTS ec_numbers\")\n",
    "con.execute(\"DROP TABLE IF EXISTS kegg_info\")\n",
    "\n",
    "# Clean and reinitialize\n",
    "clean_database()\n",
    "con.execute(schema_sql)\n",
    "\n",
    "# Verify schema before loading\n",
    "print(\"Initial schema:\")\n",
    "print_schema()\n",
    "\n",
    "# Now load your data\n",
    "base_dir = Path('/mnt/data2/planter_outputs')\n",
    "sample = 'SRR14292008'\n",
    "load_sequences(base_dir / sample / f'transdecoder/{sample}.pep', sample)\n",
    "load_annotations(base_dir / sample / f'eggnog/{sample}.emapper.annotations')\n",
    "load_clusters('/mnt/data2/planter_outputs/repseq/update_SRR14292008/newClusterDB.tsv')\n",
    "# Example usage:\n",
    "# Get sequences with specific COG category\n",
    "# cog_seqs = query_by_annotation(\"cog\", \"F\")\n",
    "# print(f\"Found {len(cog_seqs)} sequences in COG category F\")\n",
    "\n",
    "# Get cluster members for a representative sequence\n",
    "# members = get_cluster_members(\"your_seqhash_id\")\n",
    "# print(f\"Found {len(members)} cluster members\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Largest Clusters ===\n",
      "\n",
      "Full sequence IDs for largest clusters:\n",
      "\n",
      "Cluster 1:\n",
      "Representative: v1_DLS_31c8f6bb7af515ec897d4dc97dcf1c5b23b06f51326fa027676061e35737fb69.p1\n",
      "Members: 6\n",
      "COG: None\n",
      "Description: None\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Cluster 2:\n",
      "Representative: v1_DLS_2f5f97c028c943c8ea6dfb26c9b8a9b473ed71bb504e7e94a2da88dc4582d159.p6\n",
      "Members: 5\n",
      "COG: None\n",
      "Description: None\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Cluster 3:\n",
      "Representative: v1_DLS_107112bb223beca181620a5fa96cb5ea148efc5af8f0f981f04bc070055b515d.p2\n",
      "Members: 4\n",
      "COG: None\n",
      "Description: None\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Cluster 4:\n",
      "Representative: v1_DLS_0fa1029048bdfd19c3085285f8c512d572e81f459768765c01db7dff95cd4f8f.p2\n",
      "Members: 4\n",
      "COG: None\n",
      "Description: None\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Cluster 5:\n",
      "Representative: v1_DLS_2e28f15e38800ff98c9925f2fcebe2c81e3891391e55ddef006097808f36b8ff.p7\n",
      "Members: 3\n",
      "COG: None\n",
      "Description: None\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "=== Example Sequence Search ===\n",
      "\n",
      "Result 1:\n",
      "Sequence ID: v1_DLS_cf334033c6df3cdd250c5a6f6a0093b82425693aca97a490e2151c85bf3c6b7b.p1\n",
      "Length: 3814\n",
      "COG: BDLT\n",
      "Description: Belongs to the PI3 PI4-kinase family\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Result 2:\n",
      "Sequence ID: v1_DLS_4ffab629e601f733960e5a4a788be07b3a4145c7690b77a0c6067435df13489b.p1\n",
      "Length: 2544\n",
      "COG: T\n",
      "Description: 1-phosphatidylinositol-3-phosphate 5-kinase (Fab1)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Result 3:\n",
      "Sequence ID: v1_DLS_b1efedec238b47b585bdd99cabe1a0a7ece08fb04181ceba71b1e668881c26cc.p1\n",
      "Length: 2477\n",
      "COG: BDLT\n",
      "Description: UVSB PI-3 kinase\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "=== Example Sequence Details ===\n",
      "\n",
      "Sequence Details for: v1_DLS_31c8f6bb7af515ec897d4dc97dcf1c5b23b06f51326fa027676061e35737fb69.p1\n",
      "--------------------------------------------------------------------------------\n",
      "Length: 286\n",
      "Is Representative: True\n",
      "COG Category: None\n",
      "Description: None\n",
      "E-value: nan\n",
      "Seed Ortholog: None\n",
      "\n",
      "Cluster Size: 6 members\n"
     ]
    }
   ],
   "source": [
    "# Demo queries to explore the database\n",
    "# Set pandas display options\n",
    "pd.set_option('display.max_colwidth', None)  # Don't truncate column contents\n",
    "pd.set_option('display.max_columns', None)   # Show all columns\n",
    "pd.set_option('display.width', None)         # Don't wrap wide displays\n",
    "\n",
    "def show_largest_clusters(n=10):\n",
    "    \"\"\"Show the n largest clusters with their annotations.\"\"\"\n",
    "    logger.info(f\"\\nTop {n} largest clusters:\")\n",
    "    return con.execute(\"\"\"\n",
    "        SELECT \n",
    "            c.representative_seqhash,\n",
    "            c.member_count,\n",
    "            s.length as rep_length,\n",
    "            a.cog_category,\n",
    "            a.description,\n",
    "            COUNT(DISTINCT g.go_term) as go_term_count\n",
    "        FROM clusters c\n",
    "        JOIN sequences s ON c.representative_seqhash = s.seqhash_id\n",
    "        LEFT JOIN annotations a ON c.representative_seqhash = a.seqhash_id\n",
    "        LEFT JOIN go_terms g ON c.representative_seqhash = g.seqhash_id\n",
    "        GROUP BY c.representative_seqhash, c.member_count, s.length, a.cog_category, a.description\n",
    "        ORDER BY c.member_count DESC\n",
    "        LIMIT ?\n",
    "    \"\"\", [n]).df()\n",
    "\n",
    "def analyze_cog_distribution():\n",
    "    \"\"\"Analyze the distribution of COG categories.\"\"\"\n",
    "    logger.info(\"\\nCOG category distribution:\")\n",
    "    return con.execute(\"\"\"\n",
    "        WITH RECURSIVE chars AS (\n",
    "            SELECT \n",
    "                seqhash_id,\n",
    "                cog_category,\n",
    "                1 as position\n",
    "            FROM annotations\n",
    "            WHERE cog_category IS NOT NULL\n",
    "            \n",
    "            UNION ALL\n",
    "            \n",
    "            SELECT \n",
    "                seqhash_id,\n",
    "                cog_category,\n",
    "                position + 1\n",
    "            FROM chars\n",
    "            WHERE position < LENGTH(cog_category)\n",
    "        )\n",
    "        SELECT \n",
    "            SUBSTRING(cog_category, position, 1) as cog,\n",
    "            COUNT(*) as sequence_count,\n",
    "            ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM annotations), 2) as percentage\n",
    "        FROM chars\n",
    "        WHERE SUBSTRING(cog_category, position, 1) != ''\n",
    "        GROUP BY SUBSTRING(cog_category, position, 1)\n",
    "        ORDER BY sequence_count DESC\n",
    "    \"\"\").df()\n",
    "\n",
    "def find_interesting_sequences(min_cluster_size=5, min_length=500):\n",
    "    \"\"\"Find potentially interesting sequences based on various criteria.\"\"\"\n",
    "    logger.info(\"\\nInteresting sequences (long, well-annotated, in large clusters):\")\n",
    "    return con.execute(\"\"\"\n",
    "        SELECT \n",
    "            s.seqhash_id,\n",
    "            s.length,\n",
    "            c.member_count as cluster_size,\n",
    "            a.cog_category,\n",
    "            a.description,\n",
    "            COUNT(DISTINCT g.go_term) as go_term_count,\n",
    "            COUNT(DISTINCT e.ec_number) as ec_number_count\n",
    "        FROM sequences s\n",
    "        JOIN clusters c ON s.seqhash_id = c.representative_seqhash\n",
    "        JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        LEFT JOIN go_terms g ON s.seqhash_id = g.seqhash_id\n",
    "        LEFT JOIN ec_numbers e ON s.seqhash_id = e.seqhash_id\n",
    "        WHERE c.member_count >= ?\n",
    "          AND s.length >= ?\n",
    "        GROUP BY s.seqhash_id, s.length, c.member_count, a.cog_category, a.description\n",
    "        ORDER BY c.member_count DESC, s.length DESC\n",
    "        LIMIT 20\n",
    "    \"\"\", [min_cluster_size, min_length]).df()\n",
    "\n",
    "def sequence_length_distribution():\n",
    "    \"\"\"Analyze the distribution of sequence lengths.\"\"\"\n",
    "    logger.info(\"\\nSequence length distribution:\")\n",
    "    return con.execute(\"\"\"\n",
    "        WITH bins AS (\n",
    "            SELECT \n",
    "                CASE \n",
    "                    WHEN length < 100 THEN '<100'\n",
    "                    WHEN length < 200 THEN '100-200'\n",
    "                    WHEN length < 500 THEN '200-500'\n",
    "                    WHEN length < 1000 THEN '500-1000'\n",
    "                    ELSE '>1000'\n",
    "                END as length_bin,\n",
    "                COUNT(*) as count,\n",
    "                COUNT(CASE WHEN is_representative THEN 1 END) as rep_count\n",
    "            FROM sequences\n",
    "            GROUP BY \n",
    "                CASE \n",
    "                    WHEN length < 100 THEN '<100'\n",
    "                    WHEN length < 200 THEN '100-200'\n",
    "                    WHEN length < 500 THEN '200-500'\n",
    "                    WHEN length < 1000 THEN '500-1000'\n",
    "                    ELSE '>1000'\n",
    "                END\n",
    "        )\n",
    "        SELECT \n",
    "            length_bin,\n",
    "            count as total_sequences,\n",
    "            rep_count as representative_sequences,\n",
    "            ROUND(count * 100.0 / (SELECT SUM(count) FROM bins), 2) as percentage\n",
    "        FROM bins\n",
    "        ORDER BY \n",
    "            CASE length_bin\n",
    "                WHEN '<100' THEN 1\n",
    "                WHEN '100-200' THEN 2\n",
    "                WHEN '200-500' THEN 3\n",
    "                WHEN '500-1000' THEN 4\n",
    "                ELSE 5\n",
    "            END\n",
    "    \"\"\").df()\n",
    "\n",
    "def search_by_function(search_term):\n",
    "    \"\"\"Search for sequences by functional description.\"\"\"\n",
    "    logger.info(f\"\\nSearching for sequences related to '{search_term}':\")\n",
    "    return con.execute(\"\"\"\n",
    "        SELECT \n",
    "            s.seqhash_id,\n",
    "            s.length,\n",
    "            s.is_representative,\n",
    "            a.description,\n",
    "            a.cog_category,\n",
    "            CASE \n",
    "                WHEN c.member_count IS NOT NULL THEN c.member_count\n",
    "                ELSE 0\n",
    "            END as cluster_size\n",
    "        FROM sequences s\n",
    "        JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        LEFT JOIN clusters c ON s.seqhash_id = c.representative_seqhash\n",
    "        WHERE a.description ILIKE ?\n",
    "        ORDER BY s.length DESC\n",
    "    \"\"\", [f'%{search_term}%']).df()\n",
    "\n",
    "def cluster_member_analysis(representative_seqhash):\n",
    "    \"\"\"Analyze members of a specific cluster.\"\"\"\n",
    "    logger.info(f\"\\nAnalyzing cluster members for {representative_seqhash}:\")\n",
    "    return con.execute(\"\"\"\n",
    "        SELECT \n",
    "            s.seqhash_id,\n",
    "            s.length,\n",
    "            s.sra_id,\n",
    "            a.description,\n",
    "            a.cog_category\n",
    "        FROM cluster_members cm\n",
    "        JOIN sequences s ON cm.member_seqhash = s.seqhash_id\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        WHERE cm.representative_seqhash = ?\n",
    "        ORDER BY s.length DESC\n",
    "    \"\"\", [representative_seqhash]).df()\n",
    "\n",
    "def show_largest_clusters(n=10, display_full=True):\n",
    "    \"\"\"\n",
    "    Show the n largest clusters with their annotations.\n",
    "    \n",
    "    Args:\n",
    "        n: Number of clusters to show\n",
    "        display_full: If True, prints full seqhash IDs separately\n",
    "    \"\"\"\n",
    "    query_result = con.execute(\"\"\"\n",
    "        SELECT \n",
    "            c.representative_seqhash,\n",
    "            c.member_count,\n",
    "            s.length as rep_length,\n",
    "            a.cog_category,\n",
    "            a.description,\n",
    "            COUNT(DISTINCT g.go_term) as go_term_count\n",
    "        FROM clusters c\n",
    "        JOIN sequences s ON c.representative_seqhash = s.seqhash_id\n",
    "        LEFT JOIN annotations a ON c.representative_seqhash = a.seqhash_id\n",
    "        LEFT JOIN go_terms g ON c.representative_seqhash = g.seqhash_id\n",
    "        GROUP BY c.representative_seqhash, c.member_count, s.length, \n",
    "                 a.cog_category, a.description\n",
    "        ORDER BY c.member_count DESC\n",
    "        LIMIT ?\n",
    "    \"\"\", [n]).df()\n",
    "    \n",
    "    if display_full:\n",
    "        print(\"\\nFull sequence IDs for largest clusters:\")\n",
    "        for idx, row in query_result.iterrows():\n",
    "            print(f\"\\nCluster {idx+1}:\")\n",
    "            print(f\"Representative: {row['representative_seqhash']}\")\n",
    "            print(f\"Members: {row['member_count']}\")\n",
    "            print(f\"COG: {row['cog_category']}\")\n",
    "            print(f\"Description: {row['description']}\")\n",
    "            print(\"-\" * 80)\n",
    "    \n",
    "    return query_result\n",
    "\n",
    "def examine_sequence(seqhash_id):\n",
    "    \"\"\"\n",
    "    Get detailed information about a specific sequence.\n",
    "    \n",
    "    Args:\n",
    "        seqhash_id: Full sequence hash ID\n",
    "    \"\"\"\n",
    "    # Get basic sequence info\n",
    "    seq_info = con.execute(\"\"\"\n",
    "        SELECT \n",
    "            s.seqhash_id,\n",
    "            s.length,\n",
    "            s.is_representative,\n",
    "            a.cog_category,\n",
    "            a.description,\n",
    "            a.evalue,\n",
    "            a.seed_ortholog\n",
    "        FROM sequences s\n",
    "        LEFT JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        WHERE s.seqhash_id = ?\n",
    "    \"\"\", [seqhash_id]).df()\n",
    "    \n",
    "    # Get GO terms\n",
    "    go_terms = con.execute(\"\"\"\n",
    "        SELECT go_term\n",
    "        FROM go_terms\n",
    "        WHERE seqhash_id = ?\n",
    "        ORDER BY go_term\n",
    "    \"\"\", [seqhash_id]).df()\n",
    "    \n",
    "    # Get cluster info if it's a representative\n",
    "    cluster_info = con.execute(\"\"\"\n",
    "        SELECT member_count\n",
    "        FROM clusters\n",
    "        WHERE representative_seqhash = ?\n",
    "    \"\"\", [seqhash_id]).df()\n",
    "    \n",
    "    print(f\"\\nSequence Details for: {seqhash_id}\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Length: {seq_info['length'].iloc[0]}\")\n",
    "    print(f\"Is Representative: {seq_info['is_representative'].iloc[0]}\")\n",
    "    print(f\"COG Category: {seq_info['cog_category'].iloc[0]}\")\n",
    "    print(f\"Description: {seq_info['description'].iloc[0]}\")\n",
    "    print(f\"E-value: {seq_info['evalue'].iloc[0]}\")\n",
    "    print(f\"Seed Ortholog: {seq_info['seed_ortholog'].iloc[0]}\")\n",
    "    \n",
    "    if not go_terms.empty:\n",
    "        print(\"\\nGO Terms:\")\n",
    "        for term in go_terms['go_term']:\n",
    "            print(f\"  {term}\")\n",
    "    \n",
    "    if not cluster_info.empty:\n",
    "        print(f\"\\nCluster Size: {cluster_info['member_count'].iloc[0]} members\")\n",
    "\n",
    "def search_sequences(term, limit=10):\n",
    "    \"\"\"\n",
    "    Search for sequences by annotation description.\n",
    "    \n",
    "    Args:\n",
    "        term: Search term\n",
    "        limit: Maximum number of results to return\n",
    "    \"\"\"\n",
    "    results = con.execute(\"\"\"\n",
    "        SELECT \n",
    "            s.seqhash_id,\n",
    "            s.length,\n",
    "            s.is_representative,\n",
    "            a.cog_category,\n",
    "            a.description,\n",
    "            CASE \n",
    "                WHEN c.member_count IS NOT NULL THEN c.member_count\n",
    "                ELSE 0 \n",
    "            END as cluster_size\n",
    "        FROM sequences s\n",
    "        JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "        LEFT JOIN clusters c ON s.seqhash_id = c.representative_seqhash\n",
    "        WHERE a.description ILIKE ?\n",
    "        ORDER BY s.length DESC\n",
    "        LIMIT ?\n",
    "    \"\"\", [f'%{term}%', limit]).df()\n",
    "    \n",
    "    for idx, row in results.iterrows():\n",
    "        print(f\"\\nResult {idx+1}:\")\n",
    "        print(f\"Sequence ID: {row['seqhash_id']}\")\n",
    "        print(f\"Length: {row['length']}\")\n",
    "        print(f\"COG: {row['cog_category']}\")\n",
    "        print(f\"Description: {row['description']}\")\n",
    "        if row['cluster_size'] > 0:\n",
    "            print(f\"Cluster Size: {row['cluster_size']}\")\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "print(\"=== Largest Clusters ===\")\n",
    "clusters = show_largest_clusters(5)\n",
    "\n",
    "print(\"\\n=== Example Sequence Search ===\")\n",
    "search_results = search_sequences(\"kinase\", limit=3)\n",
    "\n",
    "# To examine a specific sequence:\n",
    "if not clusters.empty:\n",
    "    example_seq = clusters.iloc[0]['representative_seqhash']\n",
    "    print(\"\\n=== Example Sequence Details ===\")\n",
    "    examine_sequence(example_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# print(\"\\n=== COG Analysis ===\")\n",
    "# print(\"\\nCOG Category Distribution:\")\n",
    "# cog_dist = explore_cog_categories()\n",
    "# print(cog_dist)\n",
    "\n",
    "# print(\"\\nCommon COG Combinations:\")\n",
    "# combos = analyze_cog_combinations(top_n=10)\n",
    "# print(combos)\n",
    "\n",
    "# print(\"\\nCOG Category Summary:\")\n",
    "# summary, functional_groups = get_cog_category_summary()\n",
    "# print(\"\\nOverall Statistics:\")\n",
    "# print(summary)\n",
    "# print(\"\\nFunctional Group Distribution:\")\n",
    "# print(functional_groups)\n",
    "\n",
    "# # Helper function to get sequences by COG category\n",
    "# def get_sequences_by_cog(cog_category):\n",
    "#     \"\"\"Get sequences annotated with a specific COG category.\"\"\"\n",
    "#     return con.execute(\"\"\"\n",
    "#         WITH RECURSIVE chars AS (\n",
    "#             SELECT seqhash_id, cog_category, 1 as position\n",
    "#             FROM annotations\n",
    "#             WHERE cog_category IS NOT NULL\n",
    "            \n",
    "#             UNION ALL\n",
    "            \n",
    "#             SELECT seqhash_id, cog_category, position + 1\n",
    "#             FROM chars\n",
    "#             WHERE position < LENGTH(cog_category)\n",
    "#         )\n",
    "#         SELECT \n",
    "#             s.seqhash_id,\n",
    "#             s.length,\n",
    "#             a.description,\n",
    "#             a.cog_category as full_cog_categories,\n",
    "#             s.is_representative,\n",
    "#             CASE \n",
    "#                 WHEN c.cluster_id IS NOT NULL THEN \n",
    "#                     (SELECT COUNT(*) FROM cluster_members cm WHERE cm.cluster_id = c.cluster_id)\n",
    "#                 ELSE 0 \n",
    "#             END as cluster_size\n",
    "#         FROM chars ch\n",
    "#         JOIN sequences s ON ch.seqhash_id = s.seqhash_id\n",
    "#         JOIN annotations a ON s.seqhash_id = a.seqhash_id\n",
    "#         LEFT JOIN clusters c ON s.seqhash_id = c.representative_seqhash\n",
    "#         WHERE SUBSTRING(ch.cog_category, ch.position, 1) = ?\n",
    "#         ORDER BY s.length DESC\n",
    "#     \"\"\", [cog_category]).df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "eggnog_test = pd.read_csv(base_dir / sample / f'eggnog/{sample}.emapper.annotations', sep='\\t', comment='#', header=None)\n",
    "\n",
    "duplicate_header = 'v1_DLS_00048542b2614e34db583d1e78f0cd5d7895791164d212c3863b184d2d248322.p3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v1_DLS_55fa16b80e2adc2e0b3738aa3183d18521a8dd2...</td>\n",
       "      <td>v1_DLS_55fa16b80e2adc2e0b3738aa3183d18521a8dd2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v1_DLS_940b7f3fa867500048ec213a7b36cdaab2f9888...</td>\n",
       "      <td>v1_DLS_940b7f3fa867500048ec213a7b36cdaab2f9888...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v1_DLS_cdf02843a9f4e7aaf19cc4fcdaf71aa10fdd7dd...</td>\n",
       "      <td>v1_DLS_cdf02843a9f4e7aaf19cc4fcdaf71aa10fdd7dd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v1_DLS_e0c60bba4d61a3591cf8f2db164c6eee3be0527...</td>\n",
       "      <td>v1_DLS_e0c60bba4d61a3591cf8f2db164c6eee3be0527...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v1_DLS_8f976d2134ab73bb9e2ae3e71570e98bc2debd6...</td>\n",
       "      <td>v1_DLS_8f976d2134ab73bb9e2ae3e71570e98bc2debd6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95344</th>\n",
       "      <td>v1_DLS_e4abf268b58d90b0395df33bd2dc6e847a4e4e7...</td>\n",
       "      <td>v1_DLS_e4abf268b58d90b0395df33bd2dc6e847a4e4e7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95345</th>\n",
       "      <td>v1_DLS_e4c48624757dfc0ee10c8d9efc810e461bcdf69...</td>\n",
       "      <td>v1_DLS_e4c48624757dfc0ee10c8d9efc810e461bcdf69...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95346</th>\n",
       "      <td>v1_DLS_e5531a7c4ab1350a6f2adf8d07502a0f3e659e7...</td>\n",
       "      <td>v1_DLS_e5531a7c4ab1350a6f2adf8d07502a0f3e659e7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95347</th>\n",
       "      <td>v1_DLS_e5531a7c4ab1350a6f2adf8d07502a0f3e659e7...</td>\n",
       "      <td>v1_DLS_1244d609c6b688d16255e9e3a7cea7400eb652d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95348</th>\n",
       "      <td>v1_DLS_e6bbf38268622a4f55a750418f59e1396757929...</td>\n",
       "      <td>v1_DLS_e6bbf38268622a4f55a750418f59e1396757929...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95349 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0  \\\n",
       "0      v1_DLS_55fa16b80e2adc2e0b3738aa3183d18521a8dd2...   \n",
       "1      v1_DLS_940b7f3fa867500048ec213a7b36cdaab2f9888...   \n",
       "2      v1_DLS_cdf02843a9f4e7aaf19cc4fcdaf71aa10fdd7dd...   \n",
       "3      v1_DLS_e0c60bba4d61a3591cf8f2db164c6eee3be0527...   \n",
       "4      v1_DLS_8f976d2134ab73bb9e2ae3e71570e98bc2debd6...   \n",
       "...                                                  ...   \n",
       "95344  v1_DLS_e4abf268b58d90b0395df33bd2dc6e847a4e4e7...   \n",
       "95345  v1_DLS_e4c48624757dfc0ee10c8d9efc810e461bcdf69...   \n",
       "95346  v1_DLS_e5531a7c4ab1350a6f2adf8d07502a0f3e659e7...   \n",
       "95347  v1_DLS_e5531a7c4ab1350a6f2adf8d07502a0f3e659e7...   \n",
       "95348  v1_DLS_e6bbf38268622a4f55a750418f59e1396757929...   \n",
       "\n",
       "                                                       1  \n",
       "0      v1_DLS_55fa16b80e2adc2e0b3738aa3183d18521a8dd2...  \n",
       "1      v1_DLS_940b7f3fa867500048ec213a7b36cdaab2f9888...  \n",
       "2      v1_DLS_cdf02843a9f4e7aaf19cc4fcdaf71aa10fdd7dd...  \n",
       "3      v1_DLS_e0c60bba4d61a3591cf8f2db164c6eee3be0527...  \n",
       "4      v1_DLS_8f976d2134ab73bb9e2ae3e71570e98bc2debd6...  \n",
       "...                                                  ...  \n",
       "95344  v1_DLS_e4abf268b58d90b0395df33bd2dc6e847a4e4e7...  \n",
       "95345  v1_DLS_e4c48624757dfc0ee10c8d9efc810e461bcdf69...  \n",
       "95346  v1_DLS_e5531a7c4ab1350a6f2adf8d07502a0f3e659e7...  \n",
       "95347  v1_DLS_1244d609c6b688d16255e9e3a7cea7400eb652d...  \n",
       "95348  v1_DLS_e6bbf38268622a4f55a750418f59e1396757929...  \n",
       "\n",
       "[95349 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newClusterDB_path = '/mnt/data2/planter_outputs/repseq/update_SRR14292008/newClusterDB.tsv'\n",
    "pd.read_csv(newClusterDB_path, delimiter='\\t', header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
